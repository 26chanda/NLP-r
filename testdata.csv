
Name,Languages spoken,Indian experience,Role,Company,job description,University,Course,Work experience,Work experience in the U.S,Industry,Previous industry type,Location,Location from India,
1. Swathi Sridhar ,"English, kannada",,Data Analyst Intern,Bunge,"Developing a model to calculate a 'savviness score,' enhancing customer segmentation by analyzing market knowledge, to improve margins through targeted marketing strategies",UTD,MSBA,3.5 years,1 month,Food and Beverage Manufacturing,Edtech,"Chesterfield, Missouri,",Bangalore,
2. Alexa Sturrock,English,,Data Analyst,Toyota,"· AP Volume Optimization: Organized effort to create a Tableau analytics tool in support of the Annual Plan (AP) process. The tool allowed you to change volume & incentive spend between different series or grades & see resulting net revenue, contribution margin (CM) per unit, & market share. 

· Automated QA: Created Alteryx workflow to automatically perform tests to identify numbers not matching expectation. Organized holistic list of QA items, prioritized them by impact to stakeholders & difficulty to resolve, & put them in Jira. Then tracked progress, identified tradeoffs of doing QA vs. building new functionality/UI, & mobilized my team. 

· Supporting Stakeholders: Led team calls with key stakeholders, developed relationships, uncovered information about business processes, pain-points, & use cases, & created a list of features which allowed the team to understand & address stakeholder needs. Promoted engagement for the project via stakeholder communication

· Project Management: Organized team’s design & implementation strategy by identifying key dates, creating a deliverables roadmap, setting priorities based on stakeholder-defined value of features, collaborating with team to organize features into specific user stories & sub-tasks, & maintained accountability through daily standups & weekly sprint reviews (i.e., presented wins, progress, challenges, & risks)",university of chicago,"Bachelor, Major eco,Minor CS",4 years 9 mon,US citizen,Motor Vehicle Manufacturing,Motor Vehicle Manufacturing,"Plano, texas",,
3. Rupali Saxena ,"English, hindi, Marathi",,Senior Executive Data Analyst ,EXL,"- Spearheaded migration projects by conducting meticulous source-to-target mapping and data profiling, enhancing data flow understanding and facilitating seamless transitions.
- Collaborated closely with Dev teams to ensure data accuracy through comprehensive data reconciliation analyses, implementing robust validation procedures that ensured standards compliance.
- Transformed technical insights into actionable business strategies, contributing to the development of a comprehensive technical Runbook for effective communication across cross-functional teams.
- Streamlined cloud data migration by analyzing and optimizing DB2 stored procedures, resulting in significant reductions in run times and improved operational efficiency.
- Proactive member in PI planning - Epic, feature and story creation along with Backlog refinement process.",UTD,MSBA,9 yrs,2 years,IT Services and IT Consulting ,Food and Beverage Manufacturing,"Phoenix, Arizona",,
,,,Data analyst intern,EXL,"-Cleansed and organized the Food waste dataset, mapping it to a new schema to facilitate comprehensive analysis. Utilized Jupyter Notebook, Tableau, and Excel to study the impact of Food waste and food commodities on Carbon footprint, providing valuable insights for sustainability initiatives.

-Collaborated with cross-functional teams to analyze airlines and flight datasets, employing SQLAlchemy and Jupyter Notebook to design and develop reports that addressed key business questions and informed decision-making processes.

-Ingested the NYC Yellow Taxi dataset via S3 bucket into Snowflake, conducting statistical analyses to derive actionable insights. Presented findings through interactive Tableau dashboards, including identification of Yellow Taxi trip patterns, distance to fare ratio, and revenue calculation trends, contributing to business problem resolution.

-Developed data formatting and cleansing criteria and guidelines for various data sources, ensuring data integrity and consistency across projects.

-Integrated multiple complex data sources to design and develop SQL/Advanced SQL-based reports that addressed business inquiries, coordinating and prioritizing analytic projects while effectively communicating with clients and stakeholders to identify operational process flow improvements.",,,,,IT Services and IT Consulting ,,,,
,,Yes,Senior Business analyst,Food corporation of India,"- Led data preparation, validation, and mapping efforts, ensuring accuracy and consistency in reporting by utilizing SQL and Excel.
- Identified and resolved data inconsistencies through complex SQL queries, aligning data outputs with user requirements and maintaining high quality control standards.
- Implemented effective strategies to uphold product quality across 20 warehouses, optimizing storage processes and minimizing quality discrepancies.
- Mentored and trained a team of 25 Quality Control Analysts, fostering a culture of continuous improvement and achieving business goals through collaborative efforts.",,,,,,,,,
"4. Sudhanshu Jha
","English, hindi, telugu",,Data Analyst,Coders Data,"• Developed interactive Power BI dashboards for retail clients, analyzing KPI
data to drive strategic decision-making, resulting in a 20% increase in sales
and a 15% improvement in customer retention.
• Improved retail client support operations by integrating AWS and JIRA
systems with Python API to automate ticket creation, resulting in a 50%
decrease in resolution time.
• Pioneered ETL workflow development using AWS Glue to automate
inventory data extraction, improving data processing speed by 35% and saving
the team 40 hours of manual work per month.",University of Maryland Baltimore County," MS, Information system ",4 years 9 months,1.5 years,IT Services and IT Consulting,Professional Training and Coaching,"Wyoming, United States",,
,,Yes,Business Data Analyst,Kinetic Potential,"• Leveraged Jira, SharePoint, and custom JavaScript web scraping to collect
detailed job requirement data for the DRHA (Danville Redevelopment Housing
Society), supporting low-income individuals' employment. Mapped over 2,000
job roles to candidate profiles, enhancing recruitment strategy precision and
candidate-job alignment.
• Built-in algorithm for keyword matching across government sites, pairing
700-800 candidates with relevant positions, achieving a 100% match rate in an
ongoing project.
• Refined talent acquisition process using SQL(SSIS) for querying databases,
foregoing Tableau, to systematically match job roles to candidate knowledge,
skills and abilities, thereby improving the strategic fit between candidate
qualifications and job requirements.",,,,,,,,,
5. Gautam Iyer,"English, hindi, malyali",,Data Analyst,Richemont,"- Actively collaborating with a frontline leader to gain deep insights into their
reporting needs and subsequently constructing a tailored dashboard based on
the manager's specific requirements.
- Developed acquisition model in SAP Analytics Cloud using SAP Datasphere
for ETL to identify growth opportunities; incorporated additional KPIs into
dashboards to improve visibility into performance.
- Engaged in creating powerful forecasting models using Excel and Python,
continuously researching, and analyzing factors that drive future sales
predictions",UTD,MSBA,~4 years,2 years,Retail Luxury Goods and Jewelry,,"Dallas, texas",,
6. Sanyam kakkar,"English, hindi",,Data Analyst,Lands'​ End,,,,,,,,,,
,,,Data science intern,Delta Airlines,"• Aggregated and Data Engineered to segregate different customer satisfaction KPIs to build a Tableau dashboard from multiple data source
• Forecasted Net Promoter score for different customer types with MAPE 3% using attribution technique
• Optimized the ETL data pipeline from 16 hours to 5 hours by multi-threaded code (distributed computing)
• Deployed a multi-label classification model to segment customers using AWS before starting their journey which was used for marketing campaigns resulted in increase in 10 % conversion rate
• Used Grainger Causal test and hypothesis test to explain which feature are affecting Net promotor score","University of Wisconsin, Madison",INDUSTRIAL SYSTEM & ANALYTICS,4.5 years,2 years,Retail Apparel and Fashion,Airline,WFH,,
7. Rohan Sirsilla,"English, telugu",,Data analyst(analytics engineer),State Farm,"• Orchestrated seamless data collection for a 5TB dataset on AWS S3 using
Glue and Athena.
• Architected and deployed AWS Glue ETL pipelines and Pyspark to extract,
transform, and load data from multiple sources into Amazon S3.
• Revived Quick Sight-powered data fostering company-wide data-driven
decision-making.
• Designed and remodeled AWS Redshift data warehouse architecture,
incorporating best practices for data modelling and schema design.
• Conducted in-depth data analysis using the SAS framework, uncovering
insights.",University of Alabama at Birmingham,MS-data science,4 years 7 months,2.5 years,Insurance,,"Atlanta, Georgia",,
,,,"
Marketing Data Analyst",Swio - One Stop Solution,"• Designed data models to integrate with business data, optimizing data analysis and reporting processes.
• Leveraged data analytics tools to analyze website traffic and user behaviour, informing marketing strategies.
• Managed and expanded 30+ customer databases, acquiring new data sources for analysis, and employed SQL and Python for data manipulation and transformation in alignment with data warehousing best practices.
• Communicated over 50 actionable insights to business stakeholders through compelling visualizations created with Power BI, facilitating data-driven decision-making and strategic planning.",,,,,,,INDIA,,
8. Niyati Kothari,"English, hindi, Marathi",,Data Analyst,Siemens Healthineers,"Developed R scripts to transform data for clinical study and medical devices
data per Electronic Data Capture (EDC) system
• Conducted validation, reviewing, cleaning, and querying of data using SQL to
identify data discrepancies, missing values, and outliers
• Created diagrammatic visualization of processflows in Microsoft Visio and
maintained documentation standards
• Designed Power BI dashboards and LOINC code search feature in
collaboration with project managers to optimize operations and standardize
data
• Automated reviewing of instrument data received from clinical sites in Python,
reducing team’s effort from 3-4 hours to less than 10 minutes daily
• Collaborated with clinical affairs and biostatistics team to build database
based on CDISC standards for clinical study in Electronic Data Capture (EDC)
system
• Drafted clinical study-specific Data Management Plans as per the clinical trial
protocol",Northeastern ,MS-Health Informatics ·,6 years ,~2.5 years,Healthcare,,WFH,,
,,,Data analyst intern,Siemens Healthineers,"• Worked in collaboration with clinical affairs and biostatistics team to build the database for the clinical study in Electronic Data Capture (EDC) system
• Developed clinical study-specific data management plans that address workflow processes, reporting, transfer data, and database locks
• Prepared and maintained standardization documents of processes along with diagrammatic visualization of process flows in Microsoft Visio
• Conducted data validation, reviewing, cleaning, and querying to analyze the data and identify patterns and trends in a clinical study
• Created Power BI dashboards and LOINC code search capability in collaboration with project managers to optimize operations and standardize data",,,,,,,,,
9. Amish Vyas,"English, hindi",,Data Analyst,American Airlines,"• Develop and maintain Dispatch, Crew Scheduling and Central Load Planning staffing models to analyze workforce requirements and provide accurate staffing forecasts.

• Identify, analyze, and recommend solutions to workforce planning issues and develop strategies to optimize staffing.

• Automate and improve reporting and other day-to-day processes of the IOC Administration team.

• Oversee time-sensitive improvement projects from inception to completion in various areas like workforce sourcing, changing industry regulations, labor agreements, and transformation initiatives.

• Leverage advanced analytics to forecast, optimize, track, report, and manage IOC business variables for 6,700 daily flights and over 1,000 total Dispatchers, Crew Schedulers and Central Load Planners.",UTD,MSBA,~11 years,~2 years,Airlines,,"Dallas, texas",,
10. Diksha Nikumbh,"English, Marathi",,Product data analyst,Copart,"• Orchestrated agile scrum meetings to ensure alignment within the functional and technical team resulting in a 30% reduction in time-to-market for new product features
• Crafted product strategies for maintaining and prioritizing product backlogs, resulting in a 25% increase in alignment with strategic objectives. Specify epics and stories with sufficient discussion and acceptance criteria
• Fostered close collaboration with finance and accounting stakeholders, resulting in a 40% improvement in understanding of requirements to meet business objectives, managing competing priorities
• Managed the review, quality assurance testing, and implementation of multiple FinTech products and operations to ensure successful product delivery resulting in a 95% success rate.",UTD,MSITM,~2 years,~1 year ,Motor Vehicle Manufacturing,Internet Publishing ,"Dallas, texas",,
,,,Data analyst intern,Equinix,"• Spearheaded the development and implementation of a comprehensive product process life cycle on Jira and created a robust Confluence space for the Finance Analytics team, resulting in a 49% reduction in documentation-related errors and a 20% improvement in cross-functional collaboration.
• Integrated JIRA and Tableau resulting in a 25% increase in project success rates and a 30% reduction in project costs through KPI monitoring. Automated reporting procedures saved 40% of manual efforts and allowed asynchronous work, dashboard generation reduced time expenditure by an average of 9 hours per week.
• Leveraged business intelligence insights to identify impactful trends, contributing to a 15% increase in overall project efficiency and accountability",,,,,,,,,
11. Shirin Sehgal,"English, hindi",,Data Analyst ,Vistra Corp,N/A,,,,,,,,,
,,,Data Science Intern,Mary Kay global,"> Analyzed the Product line data to build a Time series Model in R- a statistical programming tool and detected outliers to find out the cannibalization effect on existing products and visualized the results in Tableau
> Built an ensemble model that aggregated predictions from artificial neural network, regression tree and a linear regression model in R studio which forecasted the effect of cannibalization every quarter when a new product is launched in the market and helped the forecasting team manage the product life cycle
> Presented ideas to the legal department to curb unauthorized sales using a forecasting model approach as a part of the intern contest",UTD,MSBA,~2 years,~1.5 years,Utilities,Personal Care Product Manufacturing,"Irving, texas",Delhi,
12. Ralish Routray,"English, Odia",,Data Analyst intern,Zonestra Technologies LLC,"• Played a vital role in the successful migration of data into Snowflake,
reducing data transfer time by 30% through meticulous optimization of ETL
process automation, leveraging expertise in SQL and Python. Used advanced
data analytics tools.
• Collaborated effectively with cross-functional teams to develop and maintain
databases, utilizing Agile Scrum methodology, Snowflake, and AWS services,
resulting in a 25% increase in data accessibility and usability for end-users.
• Actively participated in implementing Agile Scrum methodology, utilizing
tools like data analysis, data science, Jira for project management, facilitating
streamlined communication and task prioritization, leading to a 20% increase
in project efficiency and timely delivery of milestones.",UTD,MSBA,3 years,5 months,Staffing and Recruiting,,"Austin, texas",,
13. Jainish Patel,"English, Gujarathi",,Data Analyst ,CBRE,"• Coordinated with cross-functional teams and internal stakeholders to elicit project requirements into the roadmap and performed feasibility analysis to boost productivity by 60%.
• Automated and streamlined bonus and payroll processing workflows using Alteryx, MS Access, and SQL, resulting in increased efficiency by 25% and reduced processing time by 20%.
• Developed and implemented data integration solutions to consolidate and cleanse data from disparate sources for bonus and payroll calculations, ensuring data accuracy and integrity.
• Acted as a Subject Matter Expert (SME) on automation tools and processes, collaborating with cross-functional teams to identify opportunities for improvement and implement data-driven solutions in the operational accounting division.
• Computed SQL queries to analyze complex extracted data as part of a migration project and reduced the number of production defects by 32% compared to the previous release.",Campbellsville University,MSITM,~8 years,5 years,Real Estate,Hospitals and Health Care,"Dallas, texas",,
,,,Business Analyst,CBRE,"• Automated visualization of the current sales pipeline using data visualization and SQL on multiple datasets with over 160k rows, which reduced the time spent manually creating dashboards by 94%.
• Utilized MS Access to design and build relational databases to manage and analyze bonus and payroll data for the operational accounting team, resulting in increased efficiency by 60%.
• Implemented a new system to migrate all control table data to the SQL server backend using the .net technology to create a front-end interface.
• Excellent communication and collaboration skills, working effectively with cross-functional teams to ensure the successful implementation of data-driven solutions.",,,,,,,,,
,,,Data analyst,BCBS,"• Gathered data from the clients and converted them into actionable insights by predicting and modeling future outcomes.
• Worked on a 12000 set of documentation to update and validate confidential information.
• Garnered a 30% rate increase and improved the online reputation for new healthcare clients by applying analytics to identify reasons for customer satisfaction or dissatisfaction.
• Developed and documented standard operating procedures and technical documentation in a shared repository.",,,,,,,,,
14. Pooja Vaishnavi Penmetsa,"English, telugu",,Data analyst,LexisNexis Risk Solutions,"• Data cleaning, transformation, and loading from SQL Server, ensuring data accuracy and reliability.
. Ensured effective communication between business stakeholders and development teams, bridging the gap between technical capabilities and business objectives.
• SQL query writing and complex data operations for extracting specific data and achieving desired outcomes.
• Designing comprehensive data models, generating reports, and conducting trend analysis on revenue and sales data to
drive strategic decision-making.
. Implementing trend analysis using python code to determine patterns as per the business requirements. ",Georgia State University,MS-DSA,~2 years,1 year,Data Infrastructure and Analytics,Software Development,N/A,,
,,,,,"• Profiled data in the sources prior to defining the data cleaning rules. Performed Data Mining to analyze the patterns of the data sets, analyzing the data and generating reports using OpenText Magellan BI.
• Implemented Data Science pipeline process to predict Employee Attrition using AI by using python. 
. Skilled in Python, Hadoop, Spark, AWS, and data warehousing; adept at designing scalable data pipelines and ensuring data quality. learning and deep learning. Developed Model to provide the attrition of the employees in the company.
. Collaborated with cross-functional teams, troubleshoot data bottlenecks, and implement continuous improvements for efficient data processing and storage.",,,,,,,,,
15. Yukyung Cha,English,,Data analyst/CRM Data analyst intern,Extreme Networks,"- Conducted customer journey analysis using Python and visualized them into a Tableau dashboard for further strategy
- Actively showcased database management skills using MySQL and accomplished a company database cleaning/building project
- Automated data reconciliation process using Python to minimize the data discrepancy between Tableau and Salesforce",UTD,MSBA,3 years,~1 year and 3 months,Software Development,,"Dallas, texas",,
16. Manihaas Pasula,"English, telugu, hindi",,Data science intern,Alcon,,UTD,MSBA,~2 years,3 months,Medical Equipment Manufacturing,Internet Marketplace Platforms,"Dallas, texas",Hyderabad,
,,Yes,Data analyst ,Uber,"• Built and maintains automated tools for gathering, organising and visualising support
performance data and generating dashboards and reports using SQL, Python and the Google API.
• Built dynamic dashboards and self-serve analytical tools with Tableau for repetitive analyses.
• Perform analyses into specific KPIs using SQL and create visuals for monthly and quarterly business reviews with senior leadership and C-level executives.
• Maintained a data table that centralized efforts to create a source of truth for aggregated customer support data.
• Improved a business critical process for customer support operations by cutting the end-to-end time down by 50% on an weekly and monthly basis.",,,,,,,,,
17. Shukla Shanthakumara,"English, Kannada",,Business System Analyst,NVIDIA,,UTD,MSBA,~9 years,~10 months,Computer Hardware Manufacturing,IT Services and IT Consulting,"Santa Clara County, California",Bangalore,
,,,"
Global Engagement Management Intern ",HCLTech,,,,,,,,,,
,,,Data Analyst,AMD,• Achieved a 90% reduction in backlog maintenance time by developing an interactive business intelligence dashboard in ServiceNow that supports advanced analytics. Collaborated with stakeholders for feedback and successfully implemented it into a real-time working environment • Analyzed over 1200+ key figures to provide recommendations regarding the importance of KF on BU using Excel and Knime to improve the master data quality • Designed the SharePoint page for the SAP IBP team and created animated process mapping documents • Configured around 1000 KF for data harmonization,,,,,Semiconductor Manufacturing,"Appliances, Electrical, and Electronics Manufacturing",,,
,,Yes,Senior Product Documentation Analyst,National Instruments,"• Managed the product documentation life cycle across multiple products and releases while increasing efficiency by 10%
• Managed delivery of documentation of product working cross-functionally with developers and executives to ensure product was released ahead of time
• Enhanced README automation tools to reduce the rework by 10 – 12% per release
• Revamped the company-wide SharePoint pages to help 250+ employees",,,,,"Appliances, Electrical, and Electronics Manufacturing",,,,
18. Disha Sirsat,"English, Hindi, Marathi",,Data analyst,United Healthcare Group,"• Collaborated within Agile teams, fostering iterative analysis and adapting to evolving project needs for agile-driven data solutions. • Executed complex queries, data extraction, and manipulation using SQL, ensuring efficient database management for analysis and reporting, resulting in a 20% increase in data processing speed. • Created visual representations, graphs, and statistical plots using Matplotlib, Seaborn, ggplot2, Scipy, and Plotly to convey complex data insights, enhancing stakeholder understanding and decision-making by 30%. • Established ETL packages to extract data from different sources, clean the data, and load data into SQL Server databases, enhancing data accuracy and reducing processing time by 25%. • Developed interactive dashboards in Tableau, providing a view of key performance indicators and data trends. • Migrated a legacy on-premises application to AWS, reducing infrastructure costs by 20%.",UTD,MSBA,~7 years 7 months,~14 months,Healthcare,Healthcare,"Dallas, Texas",Mumbai,
,,,Business Intelligence Intern,Orthofix ,"• Implemented ETL process in Azure Data Factory to automate Merger Data flow and deliver departmental KPIs resulting in a 40% reduction in manual data processing time.
• Analyzed and visualized large datasets to uncover key insights, resulting in a revenue increase for the company.
• Shaped thematic maps using ArcGIS to visually represent spatial data, and to display business data geographically, enhancing data-driven decision-making and integrated maps within Power BI, leading to a 25% increase in operational efficiency.
• Designed dashboards visualizing sales, marketing, and customer data insights to identify trends and anomalies, providing actionable insights to the management team.",,,,,,,,,
,,Yes,Software engineer,TCS,"• Coordinated with cross-functional teams to digitize various application processes for Barclays Mobile Banking application to improve customer experience and increase operational efficiency by 15% across departments.
• Enhanced existing reporting frameworks and settled new KPI metrics using Tableau to drive business conclusions, ensuring clients had access to timely and accurate data for informed decision-making.
• Established data pipelines and succeeded data flows through SAS Visual Analytics, resulting in a 20% increase in report generation speed.
• Applied complex methods like Logistic Regression, Decision Trees, and Random Forests to increase the accuracy of the results and enhance the model by 20%.
• Employed MySQL for data manipulation tasks, such as data cleaning, transformation, and aggregation, to prepare data for analysis, reducing data processing time by 20%.
• Employed NumPy and Pandas to clean, preprocess, and transform raw data into structured formats suitable for analysis and modeling, resulting in a 30% increase in data accuracy and reliability.
• Conducted data cleaning and wrangling procedures, resulting in a 15% increase in data accuracy.",,,,,Consulting,,,,
19. Namrata Verma,"English, ",,Data analyst,Latent View Analytics,"• Responsible for migrating 20+ pricing reports from Qlik to PowerBI 
• Designed a data model in Powerbi with over 15+ tables to support migration
• Utilized advanced PowerBI features such as drill through, hierarchy, and parameter creation to ease user adaptability
• Created complex calculated measures such as YTD sales, trailing 4 weeks average price, etc. using DAX functions to support advanced analytics and business logic
• Designed 10+ complex views in Snowflake using SQL window functions to serve as the data source for the model
• Optimized performance by minimizing the model size from 10 GB to 7 GB by eliminating redundant tables and data columns. Identified less-used data tables and replaced them with an alternative source to converse dataset size. Performed query optimization
• Reduced visual rendering time in the report by 33% as compared to the reports in the legacy system
• Minimized dataset refresh duration by 50% as compared to the legacy system
• Configured role-based security and role-level security (RLS) in 7 of the 20 reports",UTD,MSBA,~5 years 7 months,~2 years 3 months,Business Consulting and Services,Software Development,N/A,N/A,
,,,Data analyst intern,Tyler Technologies,,,,,,,,,,
,,yes,Data analyst 2,JIO,"Handled consumer analysis of 300Mn application users using web analytics tool (Google analytics and Adobe analytics), responsible for creating dashboards, reporting campaign performance, providing actionable insights and drafting end campaign marketing reports to be presented to the clients.
Determined key performance indicators to be highlighted to various stakeholders for ultimate product success
Conducted product reviews with brands to deliver insights on user behavior, evaluating the of impact of marketing campaigns and identified potential reasons of user drop off.",,,,,Telecommunication,,,,
,,yes,,,"Developed a MySQL database by converting Excel Sheets to meet business needs resulting in 30% efficiency increase
Utilized SQL to fulfill ad hoc requests for data extraction and analysis for multiple departments
Designed dashboards in Tableau using advance features to monitor campaigns and minimize user drop offs",,,,,,,,,
20. Angel Velazquez III,English,,Data analyst,Air BNB,"- Provide ad hoc reporting and analysis for compliance business partners - Assist in the design of queries, metrics and dashboards for key business partners - Developed and automated scheduled reporting - Created a data pipeline to merge data from 4 sources and feed a new compliance dashboard to help track agent performance using Airlfow, Hive, and Python",Texas Tech University,MSDS,~6 years,ALL in the US,"Software Development, hospitality",Financial Services,"Dallas, Texas",US,
,,,Senior Data analyst,JP morgan chase & Co.,"- Sr Analyst for the Wholesale Profitability Team
- Automated the data manipulation for a new dashboard to give executive leadership a quick and easy way to see JP Morgans top performing clients and make strategic decisionsusing alteryx and python
- Streamline and revamp current manual analysis into automated processes reducing time spent on average 40%",,,,,,,,,
,,,Financial Analyst- Insights & Reporting,Essilor group,"- Used SQL to pull data into Excel and Forecast Monthly revenue for over 100 production labs.
- Created and maintained a QLIK Dashboard to help BA team track KPIs for over 100 production labs. 
- Performed analysis of productivity data to help identify issues in underperforming labs. This helped 
 specific labs generate about 30K more revenue byincreasing lab efficiency.
- Created and maintained a QLIK dashboard for lab managers to get a visualization for the Daily Sales of 
 their lab. 
- Created reusable SQL scripts for ad-hoc analysis and monthly data pulls",,,,,,,,,
,,,Accounting analyst,"All Web Leads, Inc. ","-Used Excel Pivot Tables to analyze company revenue and import revenue per customer to NetSuite.
-Prepared journal entries, analyses, and account reconciliations to assist with monthly close processes.
-Reviewing general ledger accounts, preparing and adjusting journal entries.
-Cash recording and application.
-Responded to information requests and assisted with audits.
-Compared revenue actuals against forecast to research and explain variances
 (mainly using excel VLOOKUP and Pivot Tables)",,,,,,,,,
21. Karmen O.,English,,Data Analyst,Curana Health ,"Manage data migration and mapping project across multiple applications (EZCAP, QNXT, Salesforce, MS Dynamics 365), extracting data and converting to appropriate modules, fields, and formats.

Analyze and cleanse large datasets from various sources (i.e. claims, contracting, credentialing) to transform raw data into valuable insights, increasing quality, productivity, and data integrity.

Analyze and interpret contracts to configure to custom fee schedules, carve-outs, sequestration, and capitation agreements, ensuring accurate reimbursement methodologies. 

Perform UAT to ensure accurate contract implementation and claims pricing prior to being used in PROD environment.

Perform root-cause analysis of 837P/837I claim edit errors in regard to contract/configuration gaps and demographic errors, in support of resolution and/or re-adjudication in EZCAP and QNXT systems.

Audit health plan data and monitor service level agreements (SLAs) with vendors to ensure compliance with CMS and other regulatory agencies.",Northwestern state university,B.S in psychology,~8 years,~8 years,Healthcare,Healthcare,,USA,
,,,Provider Data analyst,United Healthcare,"Tracked, analyzed, and interpreted trends in provider data errors, increasing operational efficiency and data integrity across applications. 

Configured contract builds for Medicare Advantage (HMO, HMO-SNP, PPO), Medicaid, and Commercial lines of business (LOBs) and testing pricing and validation in production.

Analyzed and interpreted specific state/federal benefits and terms and converted to claims set-up parameters.

Analyzed and cleansed large provider roster datasets to convert raw data into network builds, increasing quality, productivity, and turnaround times.

Performed root-cause analysis of claim errors, payment holds, and configuration gaps in support of resolution and/or re-adjudication in COSMOS and UNET claim systems.",,,,,,,,,
22. Harsha Vardhan Mulaguri,"English, telugu",,Data Analyst,"
Sunmerge Systems ","Conducting comprehensive data analysis using Python, R, and SQL to extract insights from large datasets, contributing to strategic decision-making processes for clients across various industries
● Implementing data visualization solutions using Tableau and Excel, resulting in a 20% increase in client satisfaction through improved data presentation and interpretation
● Proficient in cleaning and preprocessing raw data to ensure accuracy and consistency, utilizing techniques such as handling missing values, outlier detection, and data imputation
● Designing and implementing data integration and orchestration workflows using Azure Data Factory, ensuring seamless data movement and transformation between various sources and destinations
● Conducting thorough data cleaning and preprocessing tasks, reducing data errors by 15% and improving the accuracy and reliability of analytical models
● Experienced in version control using Git and GitHub, ensuring collaboration and tracking changes effectively.",UTD,MSBA,~ 3 years 9 months,~1 year 7 months,IT Services and IT Consulting,Advertising Services,"Dallas, texas",Hyderabad,
,,,Data Analytics and Strategy, IZEA ,"
Established campaign strategies based on regression analysis and machine learning techniques in Python for identifying KPIs of required metrics which resulted in a 40% increase in the compensation price
• Examined intricate multi-dimensional campaign data sets and created 20+ interactive dashboards in Power BI for KPI reporting
• Cleaned, preprocessed, visualized, and modeling social media metrics using machine learning models such as random forest, SVM, XGBoost etc
• Extracted data from data warehouse by developing SQL queries using stored-procedures, common table expressions (CTEs) to report building
• Analyzed data and performed necessary pre-processing techniques using Python such as matching salesforce data with data from internal APIs to combine industry names with their respective marketers
• Conducted in-depth statistical analysis, data exploration of campaign datasets using SQL, Python, Excel to identify trends, patterns, and opportunities for optimization, generating 30% increase in click-through rates by providing valuable insights, data-driven marketing strategies",,,,,,,,,
,,yes,Business data analyst,Byju's,"Operated with multiple clients for 100+ business requirement analysis and converted them into technical specifications, leading to the deployment of data solutions that satisfied business demands and boosted productivity by 25%
• Built ETL pipelines using Python, SQL to extract data from all sources into centralized warehouse for quality checks, improved data processing
• Utilized AWS data technologies like Redshift, S3, DynamoDB, EC2, Oracle and internal platforms to boost data processing efficiency by 25%
• Used Excel functions like pivot tables, VLOOKUP, Index & Match to analyze, visualize data, reduced 25% data preparation process
• Developed and executed sophisticated SQL data models, utilizing MySQL's query optimization techniques such as stored procedures, views
• Created statistical models, executed hypothesis testing, A/B testing and Analyzed user behavior data using data mining techniques like clustering, decision trees to find trends that drove product development strategies resulting in a 20% increase in user engagement
• Designed and Developed 20+ interactive and impactful dashboards in Tableau to identify Key Performance Indicators (KPIs), monitor trends and deviations and provided insights to business leaders to make data-driven decisions",,,,,,,,,
23. Ashish Goel,"English, hindi",,Digital analyst,Genpact,"• Developed and implemented data manipulation strategy improving revenue forecasting accuracy by 27%.
• Analyzed key performance indicators (KPIs) influencing revenue changes and collected relevant data.
• Leveraged data analysis to identify potential market opportunity, pinpointed key competitors, and recommended acquiring smaller player for immediate market entry.",UTD,MSBA,~3 years,3 months,Business Consulting and Services,Mills,"Dallas, texas (WFH)",Delhi,
,,yes,Data analyst,Rice mills,"• Reduced electricity load by 30kW and labor costs by 40%, achieving cost savings of 500k INR annually through data-driven machinery upgrades and automation.
• Boosted product efficiency by identifying 10% yield increase through data analysis and visualization.
• Mentored 9 interns on SAP, inventory management, analyzing market trends and quality checking.
• Increased acceptance of rice by 10% by identifying key trends and providing actionable insights to sales team.
• Developed customer segmentation model that identified new market opportunities, potentially leading to 50% growth.
• Employed Excel Solver to analyze and optimize process efficiency, enhancing operational efficiency by 30%.",,,,,,,,,
,,yes,Data analyst,Wipro,"• Reduced ticket resolution time by 50% and improved server monitoring efficiency by 40% through proactive updates, monitoring, and real-time tableau dashboards.
• Performed application support, maintenance, deployment for 20+ applications using AGILE SCRUM methodologies achieving 95% on-time project delivery rate.
• Analyzed transaction data for 100,000+ transactions to identify spending patterns, geographic trends, and unusual spending times, enabling fraud detection model development.",,,,,,,,,
24. Harshitha A. ,"English, Telugu",,Data Analyst ,QuarterHill Inc.,,UTD,MSBA,~4 years 1 month,1 year 4 months,IT Services and IT Consulting,IT Services and IT Consulting,"Dallas, texas",Hyderabad,
,,,Business analyst intern,ETC (Electronic Transaction Consultants),"• Led a project at ETC to consolidate data from separate security tools into a ""Golden Asset Listing"" for improved asset governance and inventory reconciliation.
• Developed a comprehensive exception report using MS PowerBI to provide stakeholders with insights and analysis on asset compliance.
• Completed the project within a five-month timeframe, ensuring 100% governance of electronic assets and minimizing downtime and potential financial losses.
• Proposed future enhancements, including real-time data ingestion and on-demand exception reporting, to further strengthen asset management and alignment with organizational policies.
• Demonstrated strong project management skills, effective collaboration with stakeholders, and the ability to make informed decisions to enhance asset governance and security.",,,,,,,,,
25. Atharva Bendre,"English, marathi",,Data analyst,TCS,,,,,,,,,,
,,,Data anlayst intern,Tech mahindra,"•Developed and orchestrated ETL pipelines on raw data using Python to support a variety of marketing initiatives
•Performed data mining by implementing web scraping techniques and transformed data into insights to drive business recommendations by applying machine learning algorithms that reduced overall processing time by 20%
•Applied Hierarchical clustering and Logistic Regression in R to enable operational strategies to target customers thus minimizing overall churn increasing business by 22%
•Designed, automated, and maintained interactive drill-down Power BI dashboards to view sales trends across the USA
•Revamped bi-weekly reports utilizing advanced MS Excel and Power BI to provide detailed performance summary",UTD,ITM,~6.5 years,~4 years,IT Services and IT Consulting,IT Services and IT Consulting,"Dallas, texas",Maharashtra,
26. Pavan Vamsi Tadikonda,"English, telugu",,Data analyst,AMD,"- Developing and maintained data engineering pipelines
- Created and maintained data models for the revenue models
- Created models for forecasting supply and demand
- Development of dashboards for leadership
- Enhancing processes using automation to increase operational efficiency",UTD,MSBA,~2 years,1 year 2 months,Semiconductor Manufacturing,Bank,"Austin, texas",Hyderabad,
,,,Data Scientist,Crescent Bank,"- Created customer segmentation models predicting key performance indicators using credit bureau data
- Performed hands-on data analysis of large data sets to create customer profiles for over a million customers. Used various data mining techniques such as clustering and decision trees.
- Established risk equivalency between two kinds of credit scores (FICO and Vantage3) using the scores of 5 million customers
- Developed and implemented data pipelines that curated data from various sources (such as csv, xml, and SQL) to create a data warehouse
- Transferred data dependency from two bureau data sources while ensuring existing risk scoring models do not lose predictive accuracy
- Developed dashboards and reports enabling senior leadership to make informed pricing strategy decisions",,,,,,,,,
27. Radhika Chauhan,"English, hindi",,Data analyst,TCS,"• Led the deployment and management of data solutions on Microsoft Azure, ensuring seamless integration and optimal performance.
• Investigated and resolved incidents related to pipeline failures, employing troubleshooting skills and collaborating with relevant teams.
• Conducted root cause analysis for pipeline failures, providing comprehensive reports to facilitate continuous improvement.
•Designed and implemented efficient stored procedures to support data extraction, transformation, and loading (ETL) processes within data pipelines.
• Conducted user training sessions and provided ongoing support for ServiceNow users.",UTD,MSBA,~6 years 9 months,~2 years 11 months,IT Services and IT Consulting,,,,
28. Adam Duncan,English,,Data analyst manager,Sedgwick,,,,,,,,,,
,,,Sr Data analyst,Sedgwick,"• Assists in efficient and effective program management; identifies poor work quality and cost 
 effectiveness trends; and works with appropriate staff in analyzing and compiling data from 
 technical reviews, as applicable
• Provides training and coaching on processing and procedures issues
• Provides analysis and reporting of trends
• Ensures data integrity; develops and produces reports utilized in measuring data accuracy
• Assists in the completion of appropriate client set-up and maintenance (parameter) forms
• Extracts data and analyzes information based on plan and jurisdictional requirements
• Gathers and prepares statistical data for reporting; makes recommendations to management for 
 training needs
• Analyzes data for cause and effect ratios, return-to-work and accommodations trending, disability 
 durations, injury by job type analysis, disability diagnosis trending, etc.
• Presents results to client and/or management",,,,,,,,,
,,,Analytic specialist,Wells Fargo Insurance services,"• Provided analysis to Commercial P&C and Benefits segments regarding claim reserves, loss development, loss trends and impact on business planning and pricing
• Analyzed trends within claim payments to quickly assess areas for improvement and growth
• Coordinated research and analysis pertaining to marketing activities for Commercial P&C and Benefits
• Supported the preparation of insurance renewal applications and specifications, including the collection, compilation and analysis of exposure information
• Developed and maintained an automated quarterly financial reporting process for REIT clients via Excel
• Evaluated results in monthly/quarterly loss runs and conducted ad hoc research, identified trends, and developed forecasts and models as needed
• Managed quarterly accounting for trade credit program
• Worked with management to evaluate and implement best practices for data input; modified procedures to ensure complete and accurate reporting
• Prepared Workers’ Compensation experience modification analysis and presentation for clients
• Reviewed quarterly tax documentation to ensure strict adherence to state, national and international compliance standards",,,~13 years,All US,Insurance,Insurance,"Dallas, texas",USA,
29. Asit Kandpal,"English, hindi",,Project manager and visualization Intern,Task Impetus Inc.," Boosted sales team productivity by enhancing project delivery speed by 20% with Jira.
• Drove a 10% improvement in marketing metrics via Excel-driven performance analysis.
• Delivered actionable insights for sales strategy using Tableau for reports and dashboards.
• Enhanced project outcomes and team cohesion, fostering better sales and marketing alignment through Jira
• Led a retail analysis project for the tech team, leveraging ETL, SQL, and Power Query to streamline data insights and reporting",UTD,MBA,~3 years,1 year,Staffing,Department store company,Louisiana,~Delhi ,
,,,"
Management and analytics Intern",Kohl's,"• Supervise store operations including employee scheduling, task assignment, and performance 
 monitoring. Ensure an efficient workforce through recruitment, onboarding, and training. Also, manage 
 budgeting, expense analysis, and implement corrective actions as needed.
• Understand customer needs through relationship building with potential and existing clients, while 
 ensuring product and service availability through contract approval and inventory management.
• Develop pricing strategies by evaluating merchandising initiatives, identifying opportunities for sales 
 promotions, authorizing clearance sales, and conducting trend and market basket analysis. 
• Market products by examining advertising, sales promotion, and display plans, while analyzing 
 operational and financial statements to assess profitability ratios.
• Maintain operations by enforcing policies and procedures, while managing inventory through strategic 
 purchasing plans and vendor communication.",,,,,,,,,
30. Shahzer Khan,English,,Data analyst,The home depot,"**Developed and maintained over 20 interactive dashboards using Power BI to track key supply chain metrics, improving data visibility by 30%. 
**Utilized SQL and Python with libraries like Pandas and SQL Alchemy to extract, transform, and load (ETL) data from various sources, reducing data processing time by 40%. 
**Collaborated with cross-functional teams to gather requirements and create custom reports, fulfilling over 50 ad-hoc data requests monthly. 
**Implemented data validation checks in SQL, ensuring data accuracy and consistency, which decreased data errors by 25%. 
**Performed root cause analysis on supply chain issues using advanced Excel functions, contributing to an improvement in operational efficiency. 
**Leveraged machine learning algorithms to analyze shipping patterns, optimizing delivery routes and reducing transportation costs by 12%. 
**Designed and implemented A/B testing frameworks to evaluate process changes, providing actionable insights for continuous improvement. 
**Applied data mining techniques using Python libraries like Scikit-learn and Pandas to uncover actionable insights from complex datasets, leading to a 10% increase in process efficiency. 
**Conducted a detailed cohort analysis to understand customer behavior over time, using Python and Pandas, which informed strategic marketing decisions. 
**Deployed data processing and analytical workflows on AWS, leveraging services like Redshift, S3, and Lambda to enhance scalability and reduce costs by 20%.",Westcliff University,"M.E, Engineering/Industrial Management ·",~4 years,1 year 7 months,Retail,Healthcare,California,Mumbai,
"31. John Jagmin
",English,,Data analyst,Surus,"Constructed SQL and Python based ETL pipelines to clean and provide core data to client CRMs

Implemented Databricks based ETL process that reduced data transformation processing times by 96%

Led development of Tableau and PowerBI based dashboards provided to internal and external users. 

Coordinated rollout of training programs designed to ensure client adoption of delivered products",Quinlan school of business,"MBA, Information systems",,,Political Organizations,,,,
32. Surya Keesara,English,,Data analyst,HCA Healthcare,"• Using Python's Pandas library to extract and preprocess data from Electronic Health Records (EHR) and Clinical Trial Databases, resulting in a 25% improvement in predictive accuracy through rigorous data preprocessing and modeling.
• Applying advanced analytics techniques to analyze clinical trial data, achieving a 25% accuracy enhancement in patient demographics, treatment outcomes, and adverse event predictions. This analysis contributed to better-informed decision-making in clinical research. 
• Developing and implementing data pipelines using Azure Data Factory, leading to a 50% reduction in processing time for establishing seamless data flows between various data storage systems which enhanced data integration and operational efficiency. 
• Creating interactive visualizations using Tableau, including geo maps, Gantt charts, Pareto charts, and scatter plots. These multidimensional views facilitated a 15% increase in informed decision-making by providing clear insights into complex data sets. 
• Implementing machine learning algorithms within Apache Spark to develop predictive models for patient outcomes, treatment efficacy, and adverse event predictions. 
• Optimizing data transfer operations using SQL Server Integration Services (SSIS) and Data Transformation Services (DTS) Packages, reducing transfer times by 20% by effectively integrating heterogeneous databases into a centralized PostgreSQL repository database. 
• Conducting extensive research across multiple information sources and performed root cause analysis on production and performance issues, which led to a 19% reduction in operational costs by identifying and addressing inefficiencies proactively.
• Executing Scrum methodology with regular sprint cycles, daily stand-up meetings, and sprint planning sessions to maintain focus on project goals and priorities.",UNT,Advanced Data analytics,~4 years 2 months,1 year 2 months,healthcare,IT services and consulting,"Dallas, texas",,
,,Yes,Data analyst,Capgemini,"• Utilized SQL and Python for extracting and cleaning financial data from diverse sources including market databases, financial APIs, and internal systems.
• Utilize BI tools (e.g., Power BI, Tableau, Qlik) to build interactive dashboards and self-service analytics solutions for clients.
• Develop predictive models and machine learning algorithms to forecast trends and support data-driven decision-making for clients.
• Applied segmentation techniques to categorize assets into different groups based on their historical performance, volatility, and correlation with market indices.
• Implement tools and methodologies to enhance data governance, documentation, and version control across client projects.
• Developed interactive dashboards using Tableau to visualize portfolio composition, asset performance, and allocation strategies.
• Achieved a 15% improvement in data visualization efficiency, aiding in better decision-making processes.
• Implemented ETL pipeline using Apache NiFi for seamless integration, transformation, and loading of financial data into a centralized data warehouse.
• Wrote complex SQL queries for data extraction, transformation, and aggregation in databases like MySQL to prepare data for analysis and modeling.
• Utilized Excel and advanced functions for ad-hoc analysis, enabling quick assessment of portfolio performance and strategy adjustments.",,,,,,,,,
33. Chaitanya Raghu Sai E.,"English, telugu",,data analyst,Elite exceed,"*Streamlined weekly data collection and analysis processes using Python and SQL, improving data accuracy by 20%. Utilized Alteryx 
for efficient data blending, which sped up data preparation for retail sales analysis by 25%. 
*Developed and maintained interactive retail performance dashboards in Power BI and Tableau, enhancing the visibility of sales trends 
and inventory levels. This contributed to a 10% increase in decision-making efficiency for the marketing and sales teams. 
*Assisted in predictive modeling efforts to forecast seasonal demand and optimize inventory distribution in retail settings using 
Dataiku, helping reduce overstock by 15% and ensuring better product availability.",UTD,MSBA,3 years 10 months,1 year 3 months,IT Services and IT Consulting,SEO/GOOgle,,,
34. Aralyn T. ,English,,Data analyst,Fat bear,"- Leveraged advanced predictive analytics to refine and elevate our customer acquisition strategies.
- Developed automation solutions to streamline data collection through web scraping, seamlessly updating the databases for enhanced analytics and optimized data accuracy.",UTD,MSBA,1 year 3 months ,All in US,N/A,,"Dallas, Texas",USA,
35. Ekansh Gupta,"English, hindi",,Data Analyst ,Core-Mark International,,,,,,,,,,
,,,Data Analyst,"Infodat
","
• Extracting data from PostgreSQL and Oracle to perform analysis and
prediction for inventory, and sales for the upcoming quarter
• Creating views using complex SQL queries against real-time data, result in
reducing analysis time by 40% for stakeholders
• Designed and constructed an ETL pipeline for third party data providers using
Airflow DAG to store insightful data
• Designed and automated the process for updating the latest drug price for
every quarter using Airflow DAG",UTD,MSBA,~5.5 years,2 years,Wholesale,IT Services and IT Consulting,"Houston, Texas, United States",North India,
36. Nishanth Muralidhar ,"Marathi, english",,Data analyst,SAP,"Marketing Data Analyst: Working with SAP Marketing Analytics and Insights - Strategy Team.

Data Analysis: Analyzed large marketing datasets from various sources to perform gap analysis of user personas and presented data-driven recommendations to senior leadership for better targeting; Resulting in 10% increase in engagement QoQ.

Root Cause Analysis: Conducted comprehensive marketing funnel analysis to determine the diminishing ROI trends within a specific region, pinpointing the root cause of the issue. Formulated recommendations resulting in potential savings exceeding $100K USD.

Cross-functional Collaboration: Collaborated cross-functionally with marketers, analysts, and sales team to perform risk analysis for SMB's net new logos. Presented data-driven recommendations to reduce risks and improve increase retention.


Product Manager (Job Shadowing): Collaboratively working with a team on a Generative AI initiative aimed at optimizing operational efficiency.",UTD,MSITM,~4.5 years,~1 year 4 months,Software Development,Automation Machinery Manufacturing,USA,,
37. Hrishika Reddy Vadde,"English, telugu",,Data analyst intern,Btree solutions,"• Proficiently creating robust data architectures using SQL(Views and Stored Procedures) and AWS 'big data' technologies(Apache Spark, AWS GLue), including Interactive Analytic tools like Power BI, to accelerate optimal data extraction, transformation, loading processes and DirectQuery to connect across miscellaneous data sources.
• Addressing both functional and non-functional business requirements, Assembling complex datasets, incorporating advanced data mining methodologies such as clustering, regression analysis and time series analysis to result in actionable insights. Collaborate keenly with analytics specialists to perpetually intensify the functionality of data systems.
• Utilizing Talend for parallel processing and scalability to develop data pipelines, prioritizing data quality and consistency through in-depth quality assurance, and driving dynamic enhancements for advanced performance and efficiency.",UTD,MSBA,~3 years 1 month,7 months,IT Services and IT Consulting,IT Services and IT Consulting,"Virginia, USA",Hyderabad,
38. Rushi Pravin Attarde,"English, Marathi",,Student Consultant/Data analyst,Zennero,"• Constructed an ERD using Python for 8 datasets, resulting in a 40% reduction in data redundancies, enhanced storage efficiency, and accelerated query performance, leading to faster data retrieval and analysis.
• Developed and refined ML models, including ARIMA and ETS, achieving a 95% accuracy rate in forecasting ESG performance metrics driving strategic initiatives for business optimization.
• Engineered and deployed 4 ML model APIs, facilitating real-time ESG data analysis and recommendations, directly contributing to a 15% increase in stakeholder engagement.",UTD,MSITM,~1 year 1 month,5 months,Software Development,,"Dallas, texas",Maharashtra,
39. Preetham Sai Kandimalla,English,,Data Analyst,"UnitedHealth Group 
","• Utilized SQL to clean, transform, and normalize raw data, ensuring high data quality and consistency.
• Developed, tested, and optimized SQL queries and stored procedures in SQL server to analyze data from multiple
sources.
• Created and managed relational database schemas in Snowflake and AWS Redshift ensuring optimal data
organization and storage.
• Designed and implemented database tables, indexes, and relationships in snowflake to support efficient data
retrieval and analysis.
• Created SQL views to Analyze data from various tables, and to utilize them for data reporting.
• Imported data from multiple sources into Tableau to develop dashboards.
• Created comprehensive and visually appealing dashboards and reports in Tableau based on in-depth data
analysis, effectively presenting critical insights.
• Actively participated as a member of Agile development teams, contributing to daily stand-up meetings, sprint
planning, and retrospectives, while learning to work effectively within Agile frameworks.
• Actively participated in continuous improvement initiatives,contributing data-driven insights to enhance overall
workflow and data management practices.",DePaul University,MS-CS,~2 years 3 months,All in US,Healthcare,N/A,"Frisco, Texas",USA,
40. Tarun I,"English, Madrasi",,Data analyst,CVS pharmacy,"• Developed sophisticated data models using libraries like Scikit-Learn and TensorFlow, integrating machine learning algorithms for predictive analytics, resulting in a 20% improvement in accuracy over baseline models.
• Engineered and implemented sophisticated ETL processes using SQL, reducing data processing time by 40% and ensuring the availability of accurate, up-to-date information for decision-making.
• Applied PySpark for big data processing, resulting in a 25% reduction in processing time and enabling the analysis of large datasets with improved scalability.
• Created customized data visualizations using Matplotlib and Seaborn in Python, enhancing data storytelling and contributing to a 25% improvement in stakeholder comprehension.
• Implemented advanced data modeling techniques in Power BI, resulting in a 25% reduction in data complexity and a 30% improvement in report generation speed.
• Utilized Power Query for complex ETL processes, resulting in a 25% reduction in data transformation time and ensuring timely availability of clean and enriched data.
• Executed data partitioning and sharding strategies in PostgreSQL, contributing to a 30% improvement in database scalability and handling of large datasets.
• Efficiently processed data by storing it securely in AWS S3 and AWS Redshift using AWS EC2 instances, and using PySpark and Pandas for complex calculations and analysis of stocks in the data warehouse.",Texas A&M-commerce,MSBA,~4 years 3 months,~8 months,Healthcare,Electronics and appliances,"Dallas, texas",Hyderabad,
,,YES,Data analyst,Philips,"• Applied advanced feature engineering techniques and conducted feature selection with Scikit-Learn, resulting in a 20% reduction in model dimensionality and improved model interpretability.
• Generated periodic and ad hoc reports, conducted deep-dive analyses for C-level management, and provided insights on key business metrics.
• Designed and optimized intricate SQL queries, improving database performance by 30% and reducing query execution time, resulting in enhanced real-time data access for stakeholders.
• Conducted business analysis using statistical methods, resulting in a 15% increase in traffic and conversions. Optimized data pipelines using SQL and Python for Tableau and Quick Sight Dashboards.
• Developed and implemented advanced interactive dashboards in Tableau, resulting in a 25% improvement in user engagement and a 30% increase in the accessibility of key performance indicators.
• Automated ETL pipelines using AWS Lambda functions, resulting in a 30% reduction in manual intervention and ensuring timely availability of cleansed and transformed data.
• Developed advanced NoSQL data models in MongoDB, accommodating complex data structures and relationships, resulting in a 20% improvement in flexibility and scalability.
• Implemented alerts for stakeholders to detect anomalies in KPIs, taking quick measures to mitigate fraud risks.
• Utilized Snowflake's data sharing capabilities for collaborative analysis, contributing to a 25% improvement in data-driven decision-making across departments.
• Leveraged Athena for serverless SQL querying on data stored in Amazon S3, resulting in a 30% reduction in query response times and improved agility in ad-hoc analysis.",,,,,,,,,
41. Vatsal Shah,"English, Gujarati",,Data analyst,Fortress Investment group,"● Used Excel VBA to expedite the extraction of critical worksheets from extensive datasets, 
 enhancing data accessibility for analysis.
● Reduced upload time by implementing Power Automate flow to transfer large Excel files into Data 
 Warehouse through APIs and optimized JSON scipts.
● Developed a performance metrics dashboard on Power BI, utilizing power query for efficient data 
 manipulation and employing DAX formulas to enhance data modeling and calculations.
● Improved data storage and retrieval efficiency by creating pipelines and generating reports for 
 stakeholders using Quickbase.",UTD,MSBA,~1 year and 8 months,6 months,Financial Services,Business Consulting and Services,"Dallas, texas",Gujarat,
,,,Analyst,Realms,"● Actively engaged with clients to understand their business needs and objectives, while also providing solution recommendations, preparing required documentation, and executing technical tasks to ensure project success.
● Leveraged VLOOKUP, INDEX MATCH functions, and Pivot Tables in Excel to effectively sort client’s complex property datasets.
● Optimized data transfer process via SQL stored procedures for ETL operations from Yardi Voyager to Data Warehouse.
● Improved data visibility and decision-making by developing a strategic PowerBI dashboard to track vital metrics such as revenue, project timelines, and resource allocation.
● Used Power Automate to securely back up files from SharePoint to OneDrive on daily basis.
● Developed Power App enabling employees to log billable hours on projects through their phones, improving tracking of hours data for billing.",,,,,,,,,
42. Yinka O,English,,Data analyst,Teksystems LLC,"• Understands clinical data from multiple systems, including Electronical Medical Record Systems (EMR), Practice Management Systems (PMS), and Pharmacy Dispensing Systems (PDS)
• Participates on a delivery team with Engineers, Product Owners, Iteration Managers, and others.
• Preparation of monthly information to support the Group CEO
• Preparation and maintenance of group summary of cross divisional benchmarking metrics for sales, operational and development expenditures
• Analysis of different business segments and competitive landscape
• Respond to SDL Executives on key pieces of analysis and present and discuss conclusions reached.
• Produce and investigate performance variances and casual trend analysis.
• Support the senior management team in the preparation of data analysis for operational purposes.
• Provide analytical, research, and technical data support on challenging regulatory/business-oriented processes for Encounter Data Operations. Recommend improvements and efficiencies to existing processes and best practices.
• Research and document data requirements for regulatory data submissions. Responsible for the analysis of encounter file and data requirements, the research and facilitation of error correction and file resubmission, and the development of file and data quality improvement solutions to maintain service levels for encounter reporting.
• Interprets data results using a variety of techniques, ranging from simple data aggregation via statistical analysis to complex data mining.
• Designs, develops, implements, and maintains business solutions.
• Design and develop data entry and storage modules.
• Compile and generate summarized data to include analysis of data.
• Review data and summarized results and prepare progress reports.
• Coordinate dissemination of data to investigators
• Assist in developing data collection, validation, and analysis tools to meet requirements of project.",N/A,N/A,~8 years,All in US,IT services and Business consulting,IT services and Business consulting,"Austin, texas",USA,
,,,Data analyst,Halo Soft Penni,"• Experience with supporting various tenets of enterprise data management, including data acquisition, data discovery, data profiling, data validation, data quality, or data cleansing.
• Analytical work experience in a professional setting
• Intermediate to advanced computer skills including MS Office with advanced skills in Excel (knowledge of spreadsheet functionality: v-look-up, pivot tables, charts, graphing and macros)
• Experience as a data management analyst for large–scale business system development projects
• Experience with team leadership for technical or functional IT and data analysts
• Experience with supporting US Air Force logistics business information system projects enterprise data management in at least one of the following areas: data acquisition, data discovery, data profiling, data validation, data quality, or data cleansing
• Interpret data results using a variety of techniques, ranging from simple data collection to sophisticated data mining.
• Maintain and enhance existing clinical dashboards and operational tools (using SQL). Maintain business solutions including data visualization in dashboards and reports.
• Design and implement dashboards, applications and reports.",,,,,,,,,
,,,Data analyst,Thanos consulting LLC,"• Timely completion of monthly and quarterly corporate requirements including
• Make full use of available data within and outside the HR reporting platform to address reporting needs and rationalize new data requirements to avoid data/reports duplication
• Work with large data volumes efficiently, reconcile data gaps and contradictions and establish standards around data model and data dictionary
• Create compelling and accurate HR reports and dashboards
• Interpret results and communicate insights through reports / dashboards
• Encourage the HR community to leverage the self-serve capabilities, to adopt available reports and to apply new insights to various area of the organization
• Actively support (lead where required) the department’s annual update of global market data and related annual situation assessment of global market conditions. This includes market analysis, assessments, and related data depictions
• Serve as the primary contact to provide market intelligence guidance for select businesses, industries, and geography’s during the annual update and throughout the year
• Manage all source-to-pay processes of department’s Software-as-a-Service (SAAS) contracts, spend, and renewal process for external information service providers (IHS, Hoovers, Moody’s, EBSCO, etc.). Recommend if/when to redirect spending to ensure optimal use of budgeted resources",,,,,,,,,
43. Eli (Haoyuan) Hu,English,,Data analyst,ClubCorp,"• Led a cross-functional team to construct financial KPI dashboards using Tableau and Alteryx, empowering 400+ regional managers to track KPIs with in-depth insights and resulting in a 70% efficiency increase of performance evaluation.
• Secured a robust, high-uptime enterprise reporting environment by managing 1700+ users and collaborating with IT to maintain the Tableau server on AWS, which led to the effective implementation of company-wide security policies like row-level security.
• Facilitated seamless data transfer and timely budget forecasts by leveraging Python libraries, Pandas and NumPy, to extract and transform a 100 million row budget dataset into desired budget files, accurately mirroring the finance system in the Azure SQL database.
• Steered a 4-member BI team in transition from Tableau to Power BI, recreating 23 key dashboards in 3 months, resulting in an annual cost savings of $100,000 via reduced licensing fees.
• Created a web scraping workflow using UiPath to collect contact information of 450,000 former members for the Sales team and increased member retention rate by 30%. Automated the update process of member master file using Alteryx, resolving 40% of previously uncollectible bad debt.
• Unveiled actionable insights into member behaviors and consumer trends through the generation of ad-hoc reports using complex SQL queries, resulting in top-tier member retention and a 35% increase in membership sales.
• Enhanced operational stability by maintaining and troubleshooting 16 ETL pipelines for Tableau data sources and weekly reports, leading to zero disruptions in data flow and timely insights.
• Expedited the migration process from Tableau to Power BI by 30% through collaborating with the data engineering team to convert legacy Oracle SQL queries to MS SQL Server, providing critical support and facilitating a smoother transition for BI developers.",UTD,MSITM,5 years 5 months,~5 years,Hospitality,Food and Beverage Services,"Dallas, Texas",China,
44. Syed Mustafa Hassan,English,,Data analyst,CHRISTUS Health,"• Led my Master's capstone project with a team of five at Christus Health, utilizing Python for scripting and SQL for data manipulation to automate the financial discrepancy review process, ensuring compliance with data governance standards. This initiative reduced the need for human intervention by 90% in the preprocessing phase.
• Focused on optimizing data management for Latin American hospitals, utilizing data integration tools such as Talend Data Integration, this automation initiative streamlined data synchronization, leading to significant efficiency gains and improved data accuracy, ultimately enhancing financial processes.
• Analyzed and reconciled 66,000+ item records purchased across Chile, Colombia, and Mexico, leveraging Oracle, SAP, and Informatica databases, thereby drastically reducing manual workload.
• Developed a data visualization tool using Tableau for swift identification and resolution of internal hospital item number and spending discrepancies, improving data accuracy, reporting, and supporting ongoing project success, leading to measurable cost savings and financial efficiency.","UT, Arlington",MSBA,~2 years 4 months,~10 months,Healthcare,Performing arts,"Irving, texas",Pakistan,
,,,Data analyst,Jubilee theatre,"• Utilized data analysis techniques, including tools such as SQL, Python, and Power BI, to evaluate the effectiveness of existing job descriptions for Jubilee Theatre, identifying areas for optimization and refinement.
• Conducted quantitative assessments by analyzing key metrics; application rates increased by 35%, conversion rates improved by 20%, and time-to-fill reduced by 15 days, providing data-driven insights on job description performance.
• Leveraged keyword analysis to optimize job descriptions, increasing qualified candidate attraction by 25%, and led A/B testing for data-driven refinements.",,,,,,,,,
45. Harsha Vardhan,"English, Hindi",,Data analyst,Blue Cross Blue Shield of Texas,"• Involved in various stages of Software Development Life Cycle (SDLC) implementing Waterfall, Agile & Scrum.
• Created reports on predictive analytics using Python and Data Studio, including visualizing model performance and prediction results. Proficient in using Pandas, NumPy, MapReduce, and Matplotlib.
• Expertise in writing SQL Queries, Dynamic-queries, sub-queries and complex joins for generating Complex Stored Procedures, Triggers, User-defined Functions, Views and Cursors.
• Designed and implemented complex ETL workflows using ADLA's extensible scripting capabilities, orchestrating data movement, transformation, and loading operations.
• Optimized data wrangling processes to handle large datasets efficiently, reducing processing times and resource usage.
• Developed complex SQL queries, utilizing MySQL's query optimization techniques such as indexing, query caching, and EXPLAIN analysis, resulting in significant improvements in query performance and database efficiency
• Utilized Power BI's custom visualizations feature to design tailored charts, graphs, and visuals that address specific business needs and enhance data representation.
• Designed and implemented end-to-end Extract, Transform, Load (ETL) processes using AWS Glue, Data Pipeline, or Lambda functions, enabling efficient data extraction, transformation, and loading.
• Proficient in R programming for data analysis and statistical modeling, leveraging libraries such as ggplot2 and dplyr to visualize and manipulate data effectively.
• Designed and implemented data models and schemas in MySQL to organize and structure data for optimal analysis, incorporating normalization techniques where necessary.
• Assisted Supply chain analysts with automating reporting functionality using Power BI tools Power BI reporting, Dashboards & Scorecards (KPI) and MySQL & Data warehouse data sources.
• Utilized Power Query in Power BI to perform data transformations, including data cleansing, data merging.","UT, Arlington","MS, Information systems",~3 years,~1 year 8 months,healthcare,hospital and heathcare,texas,North India,
,,,Data analyst,McKesson ,"• Executed SQL queries from R/Python on complex table configurations
• Involved in publishing various kinds of live, interactive data visualizations, dashboards, reports, and workbooks from Tableau Desktop to Tableau servers.
• Utilized Power Query in Power BI to perform data transformations, including data cleansing, data merging, and data modeling, ensuring data accuracy and consistency.
• Involved in analysis, design, and documentation of business requirements and data specifications, supported data warehousing extraction programs, end-user reports, and queries
• Created reports on predictive analytics using Python and Data Studio, including visualizing model performance and prediction results. Proficient in using Pandas, NumPy, Map Reduce, and Matplotlib.
• Retrieving data from the database through SQL as per business requirements
• Worked with large structured and unstructured datasets, performed data validation, predictive modeling, and data visualization 10%",,,,,,,,,
46. Vinay Mandala,"English, Tamil",,Data analyst,Southwest Airlines,"
•Conducted in-depth data analysis on key metrics in the aviation industry, including flight schedules, passenger traffic, aircraft maintenance records, fuel consumption, and safety incidents, utilizing Python.
•Integrated weather information, airspace restrictions, and airport congestion data with internal aviation data using Apache Spark and Apache Kafka to augment situational awareness.
•Employed the AWS Lambda server less computing platform to develop event-driven microservices for real-time data processing, integrating third-party APIs within the aviation sector.
•Utilized machine learning algorithms, specifically Random Forest Regression and Gradient Boosting models, on historical aviation data to predict flight demand and optimize pricing structures.
•Developed and managed MySQL databases to facilitate the storage, organization, and retrieval of critical aviation data, including flight schedules, passenger information, and aircraft details.","UT, Arlington",MSDS,~2 years 4 months,~1 year 1 month,Aviation,Edtech,WFH,Chennai,
47. Utkarsh Mishra,"English, hindi",,IT project Intern,University of texas System,"• Successfully oversaw project management initiatives across 50+ projects, ensuring adherence to requirements, standards,
schedules, and documentation protocols.
• Developed predictive models, providing an allowable range for deficit work hours, to proactively address the upward trend.
• Conducted real-time analysis of dashboards to inform managerial decisions.
• Created and delivered over 10 advanced data analytics reports using Power BI, enhancing data-driven decision-making
processes.",UTD,MSBA,~4 years ,~2 months,Ed-tech,Software ,"Dallas, texas",Indore,
"48. Lahari Prathapagiri
 ","English, telugu",,Data analyst,Torque technologies LLC," Developed and maintained Power BI dashboards and reports, visualizing key performance indicators (KPIs) and metrics, enhancing business decision-making for stakeholders by 20%.
 Designed and implemented data models in Power BI Desktop, improving data analysis efficiency by 30%.
 Leveraged Azure cloud services, including Azure SQL Database and Azure Data Lake Storage, to manage large data volumes for Power BI reporting, increasing data accessibility by 25%.
 Conducted data analysis using SQL queries to extract, transform, and load (ETL) data from Azure SQL Database, streamlining reporting processes and reducing query time by 15%.
 Cleaned and transformed data in Power BI using Power Query Editor, implementing steps such as data type conversion, removing duplicates, handling missing values, and merging tables, resulting in a 25% improvement in data quality.
 Utilized DAX (Data Analysis Expressions) in Power BI to create calculated columns and measures, enabling dynamic and complex data visualizations.
 Developed and maintained SSIS packages for ETL processes, ensuring accurate and timely data integration across multiple systems, enhancing data accuracy by 20%.
 Implemented error handling and logging mechanisms in SSIS packages, improving data quality and traceability by 30%.",UNC,MSIT,5 years 7 months,1 year 10 months,IT Services and IT Consulting,Food and Beverage Services,Charlotte Metro,Hyderabad,
,,,Data analyst intern,Chartwells Higher Education Dining Services," Created dashboards, reports, and visualizations in Python, Power BI, and SQL to gain insights into student preferences.
 Implemented data-driven pricing strategies, resulting in a 7% revenue increase.
 Analyzed over 10,000 student transactions, unveiling on-campus food trends that led to a 15% sales boost.
 Integrated predictive models into Power BI dashboards.
 Conducted A/B testing and hypothesis testing using Python.
 Designed predictive models using scikit-learn and TensorFlow.
 Utilized SQL queries for complex data manipulations and aggregations.
 Developed Python scripts for automated data extraction and preprocessing.",,,,,,,,,
49. anmol  Atamaram,"english , Gujarti",,Data analyst,BRP,,Northeastern University,MSDAE,5 Years and 5 months,2 years and11 month,Manufacturing,IT Services and IT Consulting,"Dallas, texas","Mumbai, Maharashtra",
,,,,,"Cloud Spot Price Prediction and Optimization:

- Collected virtual machine pricing data using Google Cloud Billing API and Azure Retail Price API. Wrote scripts to pull hourly and daily data and integrate with previous timestamps' datasets. Extracted useful data from JSON and converted it to tabular format using Pandas.
- Analyzed data on Google BigQuery, pulled data to Pandas from BigQuery using API. Visualized BigQuery data on Google Data Studio and JupyterLab.
- Collected data from various sources using AWS CLI, AWS API, and several Python packages i.e., boto3. Wrangled, preprocessed, analyzed, post-processed, and visualized the data on JulyterLab and Flourish. Performed regular and time-series feature engineering and hyperparameter tuning. Built various regression, time-series forecast, time-series anomaly detection and clustering models including SARIMAX, Prophet, bagging/boosting algorithms, auto ML i.e., PyCaret and LazyPredict, LSTM, BiLSTM, GRU, AutoKeras, CNN-LSTM, etc. and achieved the best predicted MAPE of 0.48%. Users can input their requirement of CPU number, RAM size, and instances region and the platform will return the cheapest instances combination.

Machine Learning as a Service (MLaaS):

This open-source project utilizes an open-source Auto-ML package to provide users with a free and codeless experience of getting ML models for their own data. Users only need to upload the data, select task type (NLP/CV/Tabular) and target columns and the platform will call the ML API to train the model and return the model to users.",,,,,,,,,

Name,Languages spoken,Indian Experience,Role,Company,job description,University,Course,Work experience,Work experience in the U.S,Industry,Previous industry type,Location,Location from India,LinkedIn profile link
1. Syed Ahrar Anwar,"English, telugu",,Data engineer,Cigna,,UTD,MSCS,~6 years,~6 years,Hospitals and Health Care,IT Services and IT Consulting,"Dallas, texas",N/A,
,,,Database Software Engineer,O'Neil Digital Solutions,"Developed database and programming solutions and ETL processes using SQL Server databases and SSIS packages to facilitate the creation of marketing and communication materials for clients in the health insurance and finance industries. Revamped old processes to handle sensitive client data in line with new requirements. Investigated and resolved technical issues to increase process uptime and allow for errors to be resolved. 
- Automated reprinting process across all client products speeding up reprinting process from potentially weeks to a single day
- Migrated largest volume product to a new database to ease load on production server",,,,,,,,,
,,,Database engineer,Call box,"- Worked as part of the database team that managed and maintained all of the organisation’s SQL Server database servers
- Created and implemented database solutions in the form of stored procedures and SSIS packages for processes such as migrating data between servers and tasks that support backend processes that house the product
- Monitored and troubleshooted database processes such as database replication and scheduled jobs and ensured any impact to the product was minimised
- Performed database audits to identify any misconfigured data or errant processes and worked with the development team to find solutions and any improvements that can be implemented
- Regularly conducted data pulls of varying complexity as requested by other team members from departments such as Marketing and Consulting and was often called upon to translate technical terms and issues into the broader picture of the business",,,,,,,,,
,,,Machine learning Engineer,Call box,"- Worked as part of the Machine Learning team alongside my role as a Database Engineer
- Used Database querying techniques to generate training data for prediction pipelines operating on classifying different aspects of phone calls that our clients receive
- Developed machine learning algorithms using Python and Tensorflow to train and predict on calls using features such as length of call, tracking line info, etc.
- Worked with Python Virtual Environments to deploy the program into the production pipeline that predicts on calls in real time",,,,,,,,,
2. Meshach Joshua,"English, Kannada",,"
Data Engineer
",Cloudflare,N/A,Texas A&M University,B.E in CS,~10 years,~ 10 years,Computer and Network Security,Printing Services,"Dallas, texas",USA,
,,,"
Data Engineer
",Scalable Press," Built out an existing data platform involving PySpark data pipelines using EMR, Redshift, Kafka and MongoDB. Collaborated with stakeholders from multiple lines of businesses to create analytical reports in Looker.",,,,,,,,,
,,,Data Engineer,Capital One ,"

Created ETL and Big Data analytical systems for a marketing use case using
tools such as AWS Data Pipelines, Redshift, Snowflake, Apache Spark, Kafka
and Java.",,,,,,,,,
3. Sree Pooja,"English, Marathi",,Lead Data engineer,H&R Block,"Responsible for optimizing all indexes, SQL queries, stored procedures to improve the quality of software and improve the performance tuning of queries.
Setup the procedures and implemented all of the many Data Driven Report Subscriptions to customize the report delivery process.
Extract data as need by the Finance and Analytic's team and send file to Vendor using the secure ftp process. 
Experienced in TSQL, Extraction, Transformation, and Loading using Microsoft ETL tools.
Experienced in SQL Server performance tuning, Indexes, Views, Partitioning, Transact SQL and Stored Procedures.
Generates data that is required for Financial Reporting.
Create reports to retrieve data using Stored Procedures that accept parameters.
Create stored procedures, views, triggers, user defined functions to incorporate the flow of business.
Expertise in developing complex Drill Down, Cascading, Parameterized, Drill through, Sub reports and Charts. 
Created many Oracle and SQL Server functions, stored procedures, and lookup tables in order to satisfy reporting requirements.
Utilized SQL Server, SQL Server Reporting Services, and SQL Server Integration Services.
Scheduled Jobs and Alerting using SQL Server Agent.
Responsible for the entire project from design, to installation, programming, testing, training and documentation.
Provide production support on the batch jobs that are critical to business.",University of central Missouri,MS in IT,~10 years and 3 months,~10 years and 3 months,Retail,IT Services and IT Consulting,"Kansas, Missouri",,
4. Shakthi Prasad,"English, Marathi",,Senior Data Engineer,"Wayfair LLC, Dallas, TX","

•Worked in complete Software Development Life Cycle (SDLC) process by
analyzing business requirements and understanding the functional workflow of
information from source systems to destination systems.
• Utilizing analytical, statistical, and programming skills to collect, analyze
and interpret large data sets to develop data-driven and technical solutions to
difficult business problems using tools such as SQL, and Python.
• Worked on designing AWS EC2 instance architecture to meet high
availability application architecture and security parameters.
• Created AWS S3 buckets and managed policies for S3 buckets and Utilized
S3 buckets and Glacier for storage and backup.
• Worked on Hadoop cluster and data querying tools to store and retrieve data
from the stored databases.
• Worked with different file formats like Parquet files and Impala using
PYSPARK for accessing the data and performed Spark Streaming with RDDs
and Data Frames.
• Performed the aggregation of log data from different servers and used them
in downstream systems for analytics using Apache Kafka.
Page 1 of 5
• Worked on designing and developing the SSIS Packages to import and
export data from MS Excel, SQL Server, and Flat files.
• Worked on Data Integration for extracting, transforming, and loading
processes for the designed packages.
• Designed and deployed automated ETL workflows using AWS lambda,
organized and cleansed the data in S3 buckets using AWS Glue, and
processed the data using Amazon Redshift.
• Worked within the ETL architecture enhancements to increase the
performance using query optimizer.
• Created integration workflows using the Snap Logic interface, designed
the flow of data and activities by connecting various snaps (integration
components) to build end-to-end integration solutions.
• Configured and deployed Snap Logic connectors (snaps) to connect to
different data sources and destinations, such as databases, cloud applications,
RESTful APIs, and more.",N/A,MS in CS,~10 years and 3 months,~10 years and 3 months,Retail,Bank,"Addison, texas",,
,,,Data engineer,US bank,"•Worked with business/user groups for gathering the requirements and working on the creation and development of pipelines.
• Migrated applications from Cassandra DB to Azure Data Lake Storage Gen 2 using Azure Data Factory, created tables, and loading and analyzed data in the Azure cloud.
• Worked on creating Azure Data Factory and managing policies for Data Factory and Utilized Blob storage for storage and backup on Azure.
• Worked on developing the process and ingested the data in Azure cloud from web service and loaded it to Azure SQL DB.
• Worked with Spark applications in Python for developing the distributed environment to load high volume files using PYSPARK with different schema into PYSPARK Data frames and process them to reload into Azure SQL DB tables.
• Designed and developed the pipelines using Databricks and automated the pipelines for the ETL processes and further maintenance of the workloads in the process.
• Worked on creating ETL packages using SSIS to extract data from various data sources like Access database, Excel spreadsheet, and flat files, and maintain the data using SQL Server.
• Worked with ETL operations in Azure Databricks by connecting to different relational databases using Kafka and used Informatica for creating, executing, and monitoring sessions and workflows.
• Worked on automating data ingestion into the Lakehouse and transformed the data, used Apache Spark for leveraging the data, and stored the data in Delta Lake.",,,,,,,,,
,,,Senior Data Engineer,"Radial Inc.
","

• Involved in various phases of Software Development Life Cycle (SDLC) as
requirement gathering, data modeling, analysis, design & development for the
project.
• Created the infrastructure needed for optimal data extraction, transformation,
and loading from a wide range of data sources.
• Created an optimal data pipeline architecture. In the Hadoop environment
with Linux for big data resources, developed Spark/Scala, Python for regular
expression (regex) project.
• Data sources are extracted, transformed, and loaded to generate CSV data
files with Python programming and SQL queries.
• Involved in developing Pig Scripts for change data capture and delta record
processing between newly arrived data and already existing data in HDFS.
• Designed and developed Security Framework to provide fine grained access
to objects in AWS S3 using AWS Lambda, DynamoDB.
• Responsible for loading data from the internal server and the Snowflake data
warehouse into S3 buckets.
• Experience in building and architecting multiple Data pipelines, end to end
ETL and ELT process for Data ingestion and transformation in AWS and
coordinate task among the team.
• Developed AWS Athena extensively to ingest structured data from S3 into
various systems such as RedShift or to generate reports.
• Created and written aggregation logic on Snowflake Datawarehouse tables.
• Recreated and maintained existing Access Database artifacts in Snowflake",,,,,,,,,
,,,Data engineer,Credit Suisse,"•Experience in building and architecting multiple data pipelines end to end ETL and ELT for data ingestion and transformation in GCP and coordinate task among them.
• Implemented and Managed ET solutions and automating operational processes.
• Design and develop ET integration patterns using Python on Spark.
• Develop framework for converting existing PowerCenter mappings and to PYSPARK (Python and Spark) Jobs.
• Build data pipelines in airflow in GCP for ET related jobs using different airflow operators.
• Used Stitch ETL tools to integrate data into the central data warehouse.
• Experience in GCP DATAPROC, GCS, Cloud functions, Data prep, Data Studio and Big Query.
• Experience in using G-cloud function with python to load data into Big Query for on arrival CSV files to GCS Bucket.
• Experience in loading bound and unbound data from Google subtopic to Big Query using cloud data flow with python.
• Used Rest API with python to ingest data from other sites to Big Query.
• Implemented Spark RDD transformations to map business analysis and apply actions on top of Transformations.
• Design star schema in Big Query.
• Worked on creating various types of indexes on different collections to get good performance in Mongo database.
• Monitoring Big query, DATAPROC and cloud Data flow jobs via Stack driver for all the environments.
• Used Agile for the continuous model deployment.
• Worked with Google data catalog and other google cloud APIs for monitoring, query and billing related analysis for big query usage.
• Knowledge about cloud data flow and Apache beam.
• Used Snowflake for Data Storage, processing which is easier and faster to use.",,,,,,,,,
,,,Software developer,United Airlines ,"
•Installed, configured, and maintained Apache Hadoop clusters for the
development of applications in accordance with the specifications.
• Create ETL data pipelines by combining technologies such as Hive, Spark
SQL and PYSPARK.
• Created Spark programs using Scala and Batch processing using functional
programming techniques.
• Added data to Power BI from a range of sources, including SQL, Excel,
Oracle.
Page 4 of 5
• Writing Spark Core Programs to process and clean data before loading it into
Hive or HBase to be processed further.
• Utilization of tools for data transformation such as Data Stage, SSIS,
Informatica, or DTS.
• Proficient in using UML for Use Cases, Activity Diagrams, Sequence
Diagrams, Data Flow Diagrams, Collaboration Diagrams and Class.
• In charge of building ETL pipelines with Pig and Hive to extract data from
various data sources and import it into the Hadoop Data Lake.
• Worked with several data types, including JSON and XML, and ran Python
machine learning algorithms.
• Created reusable items, such as PL/SQL program units and libraries,
database functions and procedures, and database triggers that the team could
utilize to meet business rules.
• Used SQL Server Integrations Services (SSIS) to extract, manipulate, and
load data from a variety of sources into the target system.
• Created data mapping, transformation, and cleaning rules for OLTP and
OLAP data management.
• Used Tableau for the data visualization during the quick model construction
process in Python. These models are then put into practice in SAS, where they
are connected to MSSQL databases and have timely update schedules.
• Created numerous data frames and datasets using the Spark-SQL context to
pre-process the model data.",,,,,,,,,
5. Shivang Garhwal,"English, Marathi",,Data engineer,Red hat,"• Optimized Ticketing Routing system of Customer Portal for the East Asian customers using Python, NLP, and Machine Learning
• Built a multi-classification model pipeline to classify the tickets on the structured text data with 75% score and deployed on GitLab
• Transformed unstructured text data into the structured format using Data manipulation techniques for building a predictive model
• Creating API framework to deploy Machine Learning model to the server using FastAPI
Technologies Used- Python, Gitlab, Docker, Kubernetes",UTD,MSBA,9 years,6 years,Software Development,Software Development,"Dallas, texas",,
,,,Machine Learning Engineer,Mavenir ,"
• Researched the NVIDIA Deep Learning frameworks on Video effects and
presented the use cases to the executives
• Built POCs for object detection and recognition for real-time video analysis
and deployed using Flask, HTML, CSS",,,,,,,,,
,,,Data scientist intern,Katch,"Involved in the development of Recommendation Engine Platform for the Fortune 500 Entertainment Companies to provide granular insights about the targetted audiences, reducing marketing costs with improved results for their businesses and making better decisions based on the data.

Key Highlights:
• Led a 3-member team to successfully develop a Genome Rating Model gaining $42.3 Bn US-based Streaming Service client to deliver recommendation platform for movies and shows
• Extracted, transformed, and loaded metadata from the Google Cloud Platform repository which was scraped from various resources.
• Automation of Genome Content led to gain 10% cost savings and resulting in the early release of the final product by 12 days.
• Used Natural Language Processing (NLP) techniques like Named Entity Recognition, Topic Modeling, Word Vectorization(TF- IDF/ Word2Vec), Sentimental Analysis to preprocess and convert the unstructured data into the structured format for data modeling.
• Achieved 89% accuracy in prediction model through Feature Engineering and Machine Learning Classification Algorithms.",,,,,,,,,
6. Madhur Mehta,"English, Gujarathi, hindi",,Data Engineer,Lumel,,UTD,MSBA,~4 years 9 months,~1.5 years,Software Development,Healthcare,"Dallas, texas",Gujarat,
,,,Business Operation Analyst,Jefferson Dental & Orthodontics,"• Streamlined and improved waiting time resulting in a 7% reduction in turnaround time by performing in-depth data analysis using 
SQL to identify bottlenecks and areas for improvement.
• Analyzed datasets using Power BI to identify trends and anomalies, providing actionable insights to the management team.
• Managed ETL pipeline for real-time customer data, ensuring 70% uptime and zero data loss during peak time.
• Optimized Teradata database performance, achieving a 20% reduction in query response times through strategic indexing and 
partitioning.",,,,,,,,,
,,,Product Marketing Intern,Cyber cube,"• Developed and deployed a scalable web application on AWS using EC2, S3, and RDS, resulting in a 30% increase in website traffic 
and improved user experience.
• Analyzed financial data, key performance indicators, and metrics to provide actionable insights.
• Conducted exploratory data analysis using R, uncovering patterns and trends that informed strategic business decisions.
• Collaborated with Data Engineers for developing Segmentation, Targeting and Positioning of the new and existing products with 
the help of qualitative and quantitative data analysis.",,,,,,,,,
,,,Business analyst,Tata AIG general Insurance Company limted,"• Performed ETL and visualized 20 years of customer request and execution data using MS SQL and Tableau to identify top reasons 
for customer complaints. The suggested changes resulted in a 4% reduction in complaints.
• Worked with delivery of Data & Analytics applications involving structured and un-structured data on Hadoop based platforms.
• Collaborated with cross-functional teams to develop and maintain HR analytics databases, data warehousing, and reporting
systems, improving data accuracy by 25%.
• Analyzed and designed reports and dashboards using Tableau and Qlik to help the leadership team make informed business 
decisions which increased operational efficiency by 5% for the operation department.
• Built data pipeline using Azure Service like Data Factory to load the data from Legacy SQL server to Azure Data Base using Data 
Factories, API Gateway Services, and Python codes.
• Managed project tasks, timelines, and collaboration using Jira, ensuring efficient project execution and timely issue resolution.
• Leveraged SQL to analyze insights from the app's database, including user retention & segmentation, feature usage and A/B 
testing",,,,,,,,,
7. Rohit Kosireddi,"english, telugu",,Data engineer,Transamerica,"-Demonstrated mastery in Big Data technologies and platforms like HDFS, MapReduce, YARN, Apache Cassandra, NoSQL, Apache Spark, Python,Scala, Sqoop, HBase, Hive, Oozie, Impala, and Pig for robust data solutions.
-Engineered and deployed Spark-SQL and PySpark applications in Databricks for ETL operations, successfully executing data extraction, transformation and aggregation across multiple file formats like JSON, CSV, and Parquet; strategically derived actionable OLAP and ODS insights from customer usage
patterns.
-Adapt in Amazon Web Services (AWS) ecosystem, including EC2, S3, RDS, IAM, Auto Scaling, CloudWatch, SNS, Athena, Glue, Kinesis, Lambda,EMR, Redshift, and DynamoDB for cloud-based data solutions.
-Developed serverless ETL data pipelines through AWS Lambda functions, achieving seamless data integration with Glue Catalog and efficient querying capabilities in AWS Athena; executed robust cloud migration strategies from on-premises to AWS Cloud using EMR, S3, and DynamoDB.","Lewisville, Texas",MSBA,3 YEARS,9 MONTHS,,IT Services and IT Consulting,"Dallas, texas","Bengaluru, Karnataka",
,,,Data analyst,IBM,"- Successfully migrated data from DynamoDB and Aurora RDS using AWS Glue ,while also transferring data between Oracle DB and S3 through Pentaho DI.
- Showcased expertise in AWS cloud services including S3,EMR, Ec2,kinseis and DynamoDB as well as scripting Language like Python and Bash for automation.
- Instituted rigorous data quality assurance protocols,employing test cases and continuous improvement methodologies to elevate the reliability and scalability of data pipelines- Successfully migrated data from DynamoDB and Aurora RDS using AWS Glue ,while also transferring data between Oracle DB and S3 through Pentaho DI. - Showcased expertise in AWS cloud services including S3,EMR, Ec2,kinseis and DynamoDB as well as scripting Language like Python and Bash for automation. - Instituted rigorous data quality assurance protocols,employing test cases and continuous improvement methodologies to elevate the reliability and scalability of data pipelines",,,,,,,,,
"9. Madhumitha Reddy Muduganti
 ",english,,Data engineer,Lifestance Health,"◦ Collected, cleaned, and labeled both health care and commercial databases using SQL queries, Python libraries, MS Access, and MS Excel.
◦ Conducted data filtering and cleansing processes to ensure data accuracy and consistency.
◦ Analyzed datasets using data mining tools, ensuring matching descriptions with incidents and validating data quality.
◦ Developed and maintained database objects, including tables, views, and materialized views, to enhance data accessibility and usability.
◦ Collaborated with a team of researchers to create analysis reports, providing valuable insights to stakeholders.
◦ Achieved an accuracy rate of 89.5 percent with a trained model for a sampled dataset, demonstrating strong analytical skills.
◦ Validated the model through the use of a confusion matrix and Inter-rater reliability reports, ensuring the reliability and accuracy of results.","Dallas,Texas",MSBA,3 Years and 4 months,1 year,Hospitals and Health Care,,"Irving, Texas",Maharashtra,
10. Kelly Ly,english,,Data Engineer,Amazon,"• Support field operations by improving data analytics capabilities for associates, integrating new data sources, creating and optimizing pipelines, and enabling reporting for people data    • Collaborate with stakeholders on science and engineering teams to build ML platforms, data ingestion processes, and service integrations
• Design and implement scalable and efficient ETL extract/load strategies using AWS tools in development and production environments
• Develop code to acquire/transform datasets for machine learning algorithms, analysis and reporting using Python/SQL
• Maintain Redshift clusters and other databases including monitoring cluster health and permissions/access
• Enforce adherence to data governance framework for consistent security and privatization of people data and information","Dallas, Texas","MS, BA",9 years and 2 months,9 years and 2 months,Software Development,,"Dallas, texas",USA,
"11.Charu Nethra Giri 
","english, hindi",,Data engineer,Amazon,"• Demonstrated strength in data warehousing, ETL development, and data modelling.
• Designed, developed, maintained, and supported Enterprise Data Warehouse & BI platform using various data & BI tools.
• Extracted the data from data sources like SQL and NoSQL databases, flat files, xml files, excel files, POS systems, API calls using java and loaded the data into the target databases by performing required transformations based on business logic.
• Have good understanding about different data models like normalized, de-normalized, stars, and snowflake models. Worked with transactional structured and unstructured data.
• Proficient in large data manipulation and data mining with performance optimization using SQL and python.
• Performed analyses on large sets of data to extract actionable insights that will help drive product decisions.
• Automated the testing process across different databases dynamically using Python script, through which the row count, column level, stratification tests could be performed with ease.
• Designed and built data visualizations with a strong understanding of the appropriate chart types to use to highlight patterns in the data for unstructured and structured data sets.
• Proficient in analysing data and developing ML models using Python.
• Extensive Experience with Python Machine Learning libraries such as NumPy, Pandas SciPy, Scikit-learn, PyTorch, Matplotlib and Seaborn, trained people on same and conducted workshops and exams.
• Implemented Machine learning algorithms like regression, random forest, logistic regression, decision tree, XG-boost, naïve bayes for predicting the outcome and measured their performance.
• Iteratively enhanced the performance of the model by tuning the parameter and chose the best model, identified important features and provided outcomes.
• Familiarity with big data concepts and tools (Hadoop, Hive, Spark).","Dallas ,texas",MSDS,7 yaers and 5 MONTHS,"2 YEARS AND 6 ,MONTHS",Software Development,,"Dallas, texas",Tamil Nadu,
12. Bhargav Yerramsetti,"English, telugu",,Data engineer,Capital One ,"• Led a data processing optimization project at Capital One, achieving a 30% reduction in processing times using Apache
Spark and Hadoop.
• Developed Python scripts for seamless integration with AWS S3, enhancing cloud-based storage solutions and
reducing data retrieval times by 25%.
• Automated comprehensive data quality checks within the ETL pipeline, leading to an impressive 40% reduction in
financial data errors.
• Created Power BI dashboards to visually represent data quality metrics, allowing stakeholders to track and address
issues identified through automated data quality checks.
• Leveraged SQL queries to facilitate real-time communication via WebSocket technology, enabling instant updates on
market changes and trade executions.
• Leveraged Apache Spark for distributed data processing, achieving a 30% reduction in overall processing times
through parallelized computation and utilized Hadoop for scalable storage solutions, allowing the project to handle
large volumes of financial data efficiently.
• Applied advanced Excel functionalities for demand forecasting, using statistical functions and regression analysis to
predict future financial data trends.
• Implemented robust data security measures and access controls within the Data Warehouse, adhering to data
governance standards and protecting sensitive information.
• Utilized Pandas' time series capabilities for handling temporal data, essential for analyzing historical consumption
patterns and making informed decisions.
• Utilized Seaborn pair plots for multivariate analysis, exploring relationships between multiple variables and
identifying potential patterns or outliers.","Dallas, texas",,~4 years 8 months,~2 years,Bank,IT Services and IT Consulting,Hybrid,,
,,,Data engineer,Zensar Technologies,"Integrated diverse healthcare data sources, including Electronic Health Records (EHR), medical imaging systems,
billing systems, and administrative databases.
• Provided Tableau dashboards and data sources to healthcare and hospital corporations to understand demand,
pricing, geospatial claim concentrations, deidentified and reidentified customer claims across multiple claims
networks, consultation on hospital expansion and location, etc. as requested.
• Worked in designing tables in Hive, MYSQL using SQOOP and processing healthcare data like importing and exporting
of databases to the HDFS, involved in processing large datasets of different forms including structured, semistructured and unstructured data.
• Standardized and transformed data into a unified format, adhering to healthcare data standards such as HL7 and
DICOM, ensuring consistency and compatibility.
• Implemented robust security measures and ensure compliance with healthcare data privacy regulations such as
HIPAA, including encryption and access controls.
• Utilized Azure Stream Analytics for real-time data streaming, enabling the ingestion and processing of continuous
streams of data from medical devices and IoT devices.
• Assisted in machine learning models for telehealth triage, assisting in prioritizing and routing patient inquiries based
on severity and urgency.
• Designed the data warehouse to be scalable, allowing it to handle increasing volumes of healthcare data, and
implemented performance tuning measures to optimize query execution times.
• Developed pie charts or bar charts in Matplotlib to represent the distribution of patient demographics, aiding in
demographic-based analyses and targeted healthcare interventions.
• Used pivot tables to compare performance metrics across different healthcare facilities, including patient satisfaction
scores, treatment success rates, and resource utilization.",,,,,,,,,
13. Akshat Kakulamarri,"English, telugu",,Data Engineer,Caterpillar Inc.,"I work as a Lead Data Engineer for a high level project in Caterpillar that captures worker efforts in building equipments on shop floor, inventory, Shipments, Payroll, Finance etc. for every quarter that will be reported to the VP/CEO to give an insight of the profit and loss margin in the stock value of the organization. In this role, I am accountable for client-oriented deliverables and actively working in the technical aspects of the team's work and on ETL and Snowflake development and also assist in Snowflake DBA responsibilities. Leveraging a skill set encompassing DataStage, EC2, AWS Glue, and Python, I adeptly choreograph data from diverse sources into Snowflake databases. This technical proficiency is further showcased through impactful PowerBI visualizations, where I utilize Azure GIT for seamless code management and collaboration.I work as a Lead Data Engineer for a high level project in Caterpillar that captures worker efforts in building equipments on shop floor, inventory, Shipments, Payroll, Finance etc. for every quarter that will be reported to the VP/CEO to give an insight of the profit and loss margin in the stock value of the organization. In this role, I am accountable for client-oriented deliverables and actively working in the technical aspects of the team's work and on ETL and Snowflake development and also assist in Snowflake DBA responsibilities. Leveraging a skill set encompassing DataStage, EC2, AWS Glue, and Python, I adeptly choreograph data from diverse sources into Snowflake databases. This technical proficiency is further showcased through impactful PowerBI visualizations, where I utilize Azure GIT for seamless code management and collaboration.",Southern new hampshire university,MSIT,~7 years and 7 months,~7 years and 7 months,Manufacturing,Transportation,N/A,India,
,,,Senior Data Warehouse Analyst,"

GE Transportation, a Wabtec company","I was a Business Intelegence data analyst within a close-knit team of seven professionals. My role encompassed the extraction, transformation, and loading (ETL) of data from locomotives into the Oracle 12C database. I conducted in-depth analyses of various parameters such as grade, speed, and mileage to uncover patterns and insights via PowerBI. Leveraging VBA macros, I crafted automated metrics to facilitate data analysis, and I used Power BI to visually present the alignment between projected expectations and the actual data, contributing to a more comprehensive understanding.",,,,,,,,,
"14. Praveen Kumar
Panneerselvam","English, tamil",,Lead Data Engineer,Wipro,"✔ Extract, transform, and load logic to automate data collection and manage data processes/pipelines including data quality and monitoring
✔ Lift and shift model to move code and data from on-prem Informatica Powercenter to IICS and Teradata to BigQuery and HDFS file systems to GCS bucket.
✔ Worked on the refactoring whole ETL -Informatica powercenter design to load the data into cloud with the logic’s built in on-prem world.
✔ Work closely with Informatica support team and raise tickets for any issues in IICS.
✔ Building inventory to capture all the lineages. 
✔ Working as a Lead and assigning various tasks as per Scrum calls and taking the JIRA’s to closure.
✔ Working proactively and independently to articulate issues/challenges to address project delivery risks.
✔ Analyse the requirements along with defects and performance and its related mapping design’s and providing SQL’s for the reporting and documenting them in JIRA and assigning story points based on the estimated work and complexity.
✔ Worked on providing SQL queries for analytical layer data for Tableau reporting 
✔ Code reviews to ensure code developed meets the requirements.
✔ MDCERTS to validate on-prem data vs CDW data loads.
✔ Analyse the data by these mdcerts and provide solutions for the data discrepancies.
✔ Also schedule triage meetings with the different application teams on the downstream reporting data and create adhoc reporting views for getting analytical data to their reports.",N/A,N/A,10 years 7 months,3 years 5 months,IT services and IT consulting,IT services and IT consulting,"Dallas, texas","Chennai, Tamil Nadu",
,,YES,Software associate,Cognizant,"Loading data into Hive data lake using Informatica BDM as ETL tool.

Designed Hive repository with external tables, internal tables, buckets, partitions for data load of parsed data for batch processing and data mart operations. 

Involved in achieving the performance tuning of the queries by using Vectorization, partitioning and Index

RUNDECK to automate scheduling of jobs which are to be run on batch processing concepts from landing layer to DATALAKE.",,,,,,,,,
,,,Software engineer,Accenture,"experience in Data warehousing as an ETL Informatica Developer in Accenture-India and worked in various Enterprise data warehouse application development. 
• Having worked on developing SQL with various relational databases like Oracle, Teradata.
• Have extensively worked in developing ETL program for supporting Data Extraction, transformations and loading using Informatica Power Center.
• Hands on experience using Teradata utilities (SQL, B-TEQ, Fast Load)
• Used Informatica Power Center for (ETL) extraction, transformation and loading data from heterogeneous source systems into target database.
• Created mappings using Designer and extracted data from various sources, transformed data according to the requirement.
• Involved in extracting the data from the Flat Files and Relational databases into staging area.
• Developed Informatica Mappings and Reusable Transformations to facilitate timely Loading of Data of a star/Snowflake schema.
• Developed the Informatica Mappings by usage of Aggregator, SQL overrides usage in Look-ups, source filter usage in Source qualifiers, and data flow management into multiple targets using Router.
• Created Sessions and extracted data from various sources, transformed data according to the requirement and loading into data warehouse.
• Used various transformations like Filter, Expression, Sequence Generator, Update Strategy, Joiner, Router and Aggregator to create robust mappings in the Informatica Power Center Designer.
• Imported various heterogeneous files using Informatica Power Center 9.x Source Analyzer.
• Developed several reusable transformations and mapplets that were used in other mappings.
• Experienced in writing queries by using SQL commands, keywords, functions, Sub Queries and joins",,,,,,,,,
15. Karan Upadhyay,"English, Hindi",,Data engineer,AWS,"Designed and developed multiple ETl pipelines with PySpark, Redshift, EMR, Airflow and AWS Glue.
Was responsible for developing infrastructure with AWS CDK with typescript for CI/CD continues development.
Got exposure to understand Apache Druid for sub second aggregation query results for 100s of GB of Data.",University of albany,"MS, Computer and information services",7 years and 7 months,~6 years,Information Technology & Services,Information Technology & Services,"Dallas, texas",Gujarat,
,,,Software Engineer - Machine Learning,MTX Group Inc,"- Lead ETL project with 5 Engineers for a government agency to transfer data from Salesforce to Google Cloud Bigquery with help of GCP Data Fusion, Salesforce, Python, Spark, Ephemeral Clusters, Bigquery and IAM for Row level security.
- Responsible for multiple data migration from Legacy data bases to Salesforce with help of SQL, Salesforce connected app, Python, Spark, Jupyter, Pandas, Numpy and excel.
- Implemented multiple Dashboards for complex datasets in GCP Data Studio and Tablues including but not limit to Histograms, Tabular Data, World maps, Bubble Charts and density graphs.
- Exposure to multiple Machine Learning models from Loan Approval probability with binary classification to Analyzing condition of infrastructure with images using CNN neural networks with help of PyTorch, Python, keras, scikit-learn, numpy, pandas and GCP.",,,,,,,,,
,,,Salesforce Technical Consultant,MTX Group Inc,"Salesforce Development :
- Learnt Salesforce Lightning Development.
- I was part of a 3 sprint project which includes development with help of Communities, Lightning 
 component, APEX classes, Triggers, Custom Objects , Batch jobs and Data Loader.
- Built a custom search functionality which finds all the records associated with chatter HashTags.

Artificial Intelligence:
- Created a Convolutional Neural Network to recognise Pneumonia from a data set of 5000 graphs with 
 help of Pytorch Library.
- With help of OpenCV library converted a Drone's video footage in to frames and identified faces from it 
 and accurately measured emotion of a person",,,,,,,,,
16.Kanika R,"english, hindi",,Senior Data Engineer,Leidos,"Develop business architecture using requirements such as scope, processes, alternatives and risks.
• Write business rules and create wireframe (UXI) for the projects to make developer understand properly.
• Translate stakeholder requirements into over 10 different tangible deliverables such as functional specifications, user cases, user stories, workflow/process diagram, data flow/data model diagram.
• Advanced analytical and project management skills in-depth knowledge of various phases and methodologies of software development including hybrid agile, project management.
• Assess ad hoc reporting using BI tools, which include MS Access and Excel, SQL and analysis based on those reports. Work with business analyst to determine priority.
• Customize dashboard using Kibana, Soap UI and obtain essential user info from creating saved searches in GST and RMS environments.","Dallas, Texas",PH.D. DSBA,8 years and 3 months,~7years,"
IT Services and IT Consulting",Hospitals and Health Care,"Dallas, Texas,",,
17. Manvi Lather,"English, hindi",,Data Engineer,Homecare Homebases,"--Created Enterprise GeoDatabase Models using multiple DBMS(SQL Server, Oracle, PostgreSQL).
--Created Versions and Replicas to enable multi-user data editing.
--Worked with more than 3000 clients. Interpreted their project requirements and suggested the best way to execute the project using the ESRI suite.--Improved database performance by running regular database maintenance tasks using SQL script and ESRI tools.
--Worked on Utility network Data to establish solutions with respect to Enterprise geodatabases.
--Performed data Cleaning and mapping.
--Provided multi-dimensional troubleshooting aspects related to querying and analyses of data.","Dallas, Texas",MSBA,8 years and 5 months,3 years and 11 months,Software Development,,"Dallas, Texas,",,
18. Nithin R,"English, hindi",,Data Engineer,Freddie Mac,"->Designed, developed, and maintained efficient and scalable data pipelines for data extraction, transformation, and loading (ETL/ELT) using Azure Databricks.
->Implemented and maintained processes for data quality assurance, ensuring accuracy, consistency, and reliability throughout the data lifecycle.
->Utilized version control systems like Git to track changes to code and data, enabling collaboration and reproducibility.
->Gained familiarity with data warehousing concepts and tools to create centralized repositories for structured and unstructured data.
->Utilized Python for automating data processing tasks and building custom data integrations.
->Designed and optimized data models to facilitate efficient storage, retrieval, and analysis of data.
->Worked with cloud platforms like Azure and their data-related services to manage and process data in a scalable and cost-effective manner.
->Identified and resolved performance constraints in data pipelines and infrastructure to ensure smooth and efficient data flow.
->Collaborated with data engineers to design and implement monitoring and alerting mechanisms to proactively identify and address potential data issues.Data Analysis and BI reporting:-
->Collected, cleaned, and prepared large datasets for analysis, ensuring data accuracy and Validity.
->Conducted exploratory data analysis to uncover patterns, trends, and anomalies using statistical and 
 visualization techniques.
->Applied statistical methods like hypothesis testing and regression to draw inferences from data and 
 quantify relationships.
->Translated complex data analyses into clear, concise, and compelling narratives for both technical and 
 non-technical stakeholders.
->Designed and developed interactive dashboards and visualizations in Tableau to communicate data 
 insights effectively.
->Generated regular and ad-hoc reports to monitor KPIs, track progress, and inform decision-making.
->Leveraged SQL and Python expertise to query and manipulate relational databases, extracting relevant 
 data for analysis and reporting.
->Partnered with cross-functional teams to gather requirements, understand business needs, and 
 identify data-driven solutions.
->Translated business objectives into actionable data-driven questions and analyses, providing valuable 
 insights to stakeholders.
->Maintained and updated documentation for data analysis processes, reports, and dashboards to 
 ensure consistency and knowledge transfer.","McKinney, Texas",Btech ME,7 years and 7 months,3 years and 7 months,Financial Services,,"Dallas, Texas,",,
19.Pradeep  Kumar Laghavarapu,"English, Tamil",yes,Data engineer,RandomTrees,"• Utilized AWS S3 and AWS Glue for seamless integration and data transformation within Step Functions.
• Managed and optimized a data warehousing solution on Snowflake, handling terabytes of data for analytics and reporting.
• Migrated the data tables present in Teradata present in AWS to Snowflake connected to GCP.
• Modified the Python scripts and scheduled a particular time in a day to run the scripts in GCP using Cloud Scheduler.
• Worked on Kafka load scripts that run daily at specified times required by the business requirements.
• Migrated the code developed into development, SIT environments in Bitbucket using the Feature branch.
• Monitored and scheduled the workflows using Apache Airflow.
• Validated the records of the data by converting the data tables from Teradata to Snowflake.
• Facilitated collaborative projects by setting up and managing JupyterHub instances, allowing teams to work on shared notebooks and collaborate in real-time. 
• Handled and maintained the jobs which are errored out in the AWS Glue job, further optimizing data processing.","Richmond, Virginia",Masters Data Science,3 Years 9 months,2years 9 months,IT Services and IT Consulting,Business Consulting and Services,"Richmond, Virginia",,https://www.linkedin.com/in/pradeep-kumar-laghavarapu-b3913a110/
20. Karan Upadhyay,"English,Tamil",,Data Engineer,AWS,"- Lead ETL project with 5 Engineers for a government agency to transfer data from Salesforce to Google Cloud Bigquery with help of GCP Data Fusion, Salesforce, Python, Spark, Ephemeral Clusters, Bigquery and IAM for Row level security.
- Responsible for multiple data migration from Legacy data bases to Salesforce with help of SQL, Salesforce connected app, Python, Spark, Jupyter, Pandas, Numpy and excel.
- Implemented multiple Dashboards for complex datasets in GCP Data Studio and Tablues including but not limit to Histograms, Tabular Data, World maps, Bubble Charts and density graphs.
- Exposure to multiple Machine Learning models from Loan Approval probability with binary classification to Analyzing condition of infrastructure with images using CNN neural networks with help of PyTorch, Python, keras, scikit-learn, numpy, pandas and GCP.Salesforce Development :
- Learnt Salesforce Lightning Development.
- I was part of a 3 sprint project which includes development with help of Communities, Lightning 
 component, APEX classes, Triggers, Custom Objects , Batch jobs and Data Loader.
- Built a custom search functionality which finds all the records associated with chatter HashTags.

Artificial Intelligence:
- Created a Convolutional Neural Network to recognise Pneumonia from a data set of 5000 graphs with 
 help of Pytorch Library.
- With help of OpenCV library converted a Drone's video footage in to frames and identified faces from it 
 and accurately measured emotion of a person","Dallas, Texas",MSCSE,7 years and 11 months,1 years and 7 months,IT Services and IT Consulting,Information Technology & Services,"Dallas, Texas,",,
21.Arjuna Menon Puzhankarai,English,,Data Engineer,Capital One ,"• Project to migrate from the current manual, difficult credit reporting system to a new, easier, mostly automated system
• Agile followed with tickets assigned every two weeks, and daily stand-up meetings
• Initially, focused on setup of few of the GitHub repos owned by my team by setting up required PyCharm virtual environments
• Gathered the data to create Jira tickets for my team by talking with others
• Worked on repos maintained by other teams as well by modifying code using Python in PyCharm
• Onboarded and modified repos to be compliant with the internal DevOps pipeline
• Worked with others for KTs, merging code changes to GitHub without conflicts, and delivering output in a timely manner
• Validated proper deployment in AWS for QA and CTE by checking Cloudwatch Logs and Splunk
• Local end to end testing performed before deploying to AWS through the use of LocalStack, PyCharm, Docker, and MySQL Workbench
• Ensured proper data flow by inserting mock data, and verified that the expected output is obtained in OneLake and Snowflake
• Documented in various Confluence Pages
• Provided evidence on Jira tickets for easy analysis
• Once the groundwork was properly laid, concentrated on code changes for improvements in performance
• Worked on identifying and fixing bugs before deploying to the hands-on prod environment
• Created Jira tickets when gaps and bugs were identified, and helped others find dependent tickets
• Ensured 80% SonarQube code coverage for a few of the repos by writing unit tests
• Worked extensively on client specific tools such as OnePipeline for checking the end-to-end process flow, and Bogiefile in PyCharm for deploying the infrastructure in AWS
• Worked with The Exchange team to register datasets and onboard to OneLake and Snowflake
• Generated Tableau visualizations of the credit reporting data so product can easily identify any issues
• Bug fixing efforts in order for the hands-off parallel run in the production environment to run smoothly","Dallas, Texas",MSDA,4 Years and 10 months,,Financial Services,,"Dallas, Texas,",,
22.Sudeeksha Golla,"English, Telgu",,Data Engineer,Silver hill energy partner,"Designed and implemented data pipelines using python to import data from diverse sources, effectively populating SQL Server database and ensuring data accuracy and accessibility.
• Harmonized data from a variety of sources to generate analysis-ready datasets, streamlining report generation and slashing creation time by an impressive 50%.
• Developed LOE (Lease Operating Expense) and LOS (Lease Operating Statements) reports using Power BI and Spotfire, enabling the financial department to easily analyze and interpret data, leading to a 30% improvement in data-driven decision-making.
• Automated financial and operating dashboards for the business by leveraging Power BI measures and metrics, delivering real-time data analysis capabilities.
• Spearheaded the reduction of manual workload by 20 hours per month through the automation of data flows for database load read files, employing Alteryx macros for enhanced efficiency and accuracy.","Dallas, Texas",MSBA,5 Years and 10 months,3 years and 6 months,Oil and Gas,Financial Services," Dallas, Texas",,
23. Praveen Kumar Panneerselvem,"English, Telgu",,Lead Data Engineer,Wipro,"Loading data into Hive data lake using Informatica BDM as ETL tool.

Designed Hive repository with external tables, internal tables, buckets, partitions for data load of parsed data for batch processing and data mart operations. 

Involved in achieving the performance tuning of the queries by using Vectorization, partitioning and Index

RUNDECK to automate scheduling of jobs which are to be run on batch processing concepts from landing layer to DATALAKEChennai, Tamil Nadu, India
• 4+ years of experience in Data warehousing as an ETL Informatica Developer in Accenture-India and worked in various Enterprise data warehouse application development. 
• Having worked on developing SQL with various relational databases like Oracle, Teradata.
• Have extensively worked in developing ETL program for supporting Data Extraction, transformations and loading using Informatica Power Center.
• Hands on experience using Teradata utilities (SQL, B-TEQ, Fast Load)
• Used Informatica Power Center for (ETL) extraction, transformation and loading data from heterogeneous source systems into target database.
• Created mappings using Designer and extracted data from various sources, transformed data according to the requirement.
• Involved in extracting the data from the Flat Files and Relational databases into staging area.
• Developed Informatica Mappings and Reusable Transformations to facilitate timely Loading of Data of a star/Snowflake schema.
• Developed the Informatica Mappings by usage of Aggregator, SQL overrides usage in Look-ups, source filter usage in Source qualifiers, and data flow management into multiple targets using Router.
• Created Sessions and extracted data from various sources, transformed data according to the requirement and loading into data warehouse.
• Used various transformations like Filter, Expression, Sequence Generator, Update Strategy, Joiner, Router and Aggregator to create robust mappings in the Informatica Power Center Designer.
• Imported various heterogeneous files using Informatica Power Center 9.x Source Analyzer.
• Developed several reusable transformations and mapplets that were used in other mappings.
• Experienced in writing queries by using SQL commands, keywords, functions, Sub Queries and joins","Dallas, Texas",Btech CSE,10 years and 6 months,3 years and 5 months,IT Services and IT Consulting,IT Services and IT Consulting,"Dallas, Texas,",,
24. Hari Priya,"english,Hindi",,Data Engineer,Dell,"• Developed, monitored, and optimized ADE pipelines, leveraging advanced SQL queries in Snowflake for regulatory reporting.
• Implemented Airflow DAGs to orchestrate the scheduling of data ingestions, ETL jobs, and business report generation.
• Was responsible for extract, transform, and load data from various sources into target databases using Databricks and Snowflake.
• Conducted troubleshooting and issue resolution in production environments using AWS CloudWatch & Databricks logs.
• Managed Spark Databricks clusters, estimating cluster sizes, monitoring performance, and resolving technical issues.
• Spearheaded setup of build & deployment automation using Terraform scripts and Jenkins, ensuring efficient pipeline management.
• Ensured compliance with PCI auditing requirements while handling sensitive data (e.g., card numbers, customer names) in Ethos.
• Utilized automation tools like Git, Terraform, and Jenkins to streamline and automate data pipeline processes.
• Designed and implemented Lambda functions to automate PGP key rotation stored in AWS Secrets Manager.
• Utilized Kubernetes and Docker for the runtime environment for the CI/CD system to build, test, and deploy.
• Proficient in creating visualizations, dashboards, and storytelling using AWS QuickSight, Matplotlib, Seaborn, and Plotly for actionable data insights.","Dallas, Texas",MS- MIS,3 Years and 1 months,2 years and 7 months,IT Services and IT Consulting,IT Services and IT Consulting,"Dallas, Texas",,
25. Lakshmi M,"English, hindi",,Data engineer,American Airline,"Use descriptive, diagnostic, and prescriptive analytical techniques to highlight business challenges and potential solutions

Transform data into actionable insights using data visualization and analytical story telling techniques

Act as an internal consultant to stakeholders and provide insights to drive results","Dallas, Texas",MS-ORA,7 years 9 months,4 years,Airlines and Aviation,Motor Vehicle Manufacturing,"Dallas, Texas",,
26. Aishwarya Bhole,english,,Data Engineer,REASONN,"• Worked as a data engineer utilizing Azure Data Factory (ADF), Azure Synapse Workspace, and PySpark with Databricks to create robust data pipelines and perform intricate data transformations.
• Designed and Developed ADF pipelines to extract data from various relational and non-relational sources, including Teradata, Oracle, SQL Server, and JSON files. 
• Developed Databricks Python notebooks for processing data stored in Azure Data Lake Storage and creating reusable pipelines for data loading into Azure SQL DB and SQL Data Warehouse. 
• Utilized Azure Logic Apps for workflow development and Azure Blob Storage for Power BI data sources. 
• Implemented CI/CD pipelines with Azure DevOps for seamless deployment across multiple environments and optimizing data processing performance through techniques such as partitioning and partition pruning","Dallas, TEXAS",MS-BA,3 YEARS 1 MONTH,3 YEARS 1 MONTH,IT Services and IT Consulting,IT Services and IT Consulting,"Dallas, Texas",Delhi,
,,,Technical Consultant,Perficient,"Wells Fargo (Client) 
• Worked with customer remediation team for data analysis to identify populations impacted by system or processing issues.
• Collaborated with cross-functional teams to design and execute effective remediation strategies, ensuring adherence to industry regulations and company policies.
• Conducted quality assurance checks on each remediation artifacts and code assigned using SAS to ensure accuracy.
• Maintained detailed documentation of remediation activities, ensuring accurate and auditable records for regulatory reporting.
• Provide training to new team members on customer remediation process practiced by the client

Volkswagen Group of America (Client) 
• Facilitated the tracking of pipeline health, run summary, test runs, etc using analytics views of Azure Devops.
• Created reports for Code Quality, Security, Deployment, Operations using odata feed in Devops.
• Developed service dashboards suitable for different personas (Scrum masters, engineering leadership) to consume the dashboard
• Executed accurate, timely Service KPI delivery and routine business reporting using PowerBI

Texas health Resources (Client) 
• Acquired data from various data streams such as the Salesforce Marketing cloud, Health Cloud, , Call Rail, etc which had to be cleaned and mapped into Datorama
• Built dashboard for an email campaign for their Women’s Program
• Developed a visualization report for to monitor KPIS such as sent, delivered, bounces, etc for the SMS Campaign

Dexcom (Client)
• Built a new Workspace in Datorama for the client’s new ‘Dexcom -ONE’ product In Datorama
• Created data streams in datorama to consolidate data from various media sources.
• Built dashboards for their marketing campaign to analyze their regional and national sales, marketing engagement and customer responses.",,,,,,,,,
27. Vikram Pratap Singh,"english, Hindi",,Data engineer,Captial One,"Churn Analytics 
• Led 3-member team to create a Customer Churn prediction model for a £833.893 Bn UK-based one of the largest retail bank
• Used Random Forest to understand the churn pattern, F-measure for imbalance dataset and to handle precision as well as recall
• Recommendation of features based on their effectiveness led to improve the retention rate by 3%

Optimal Credit Line Increase (CLI model) 
• Developed an automated optimal CLI model in credit card portfolio which measures loss probability, credit risk, delinquency
status, and Risk Management for one of the largest UK bank
• Used Logistic Regression, F-measure and Kappa statistics to determine profitability margin to find optimal CLI for each account
• Recommendation from result led to gain 11% cost savings and a decent decrement in Exposure At Default figures (EAD)

Real Time Data Ingestion 
• Extracted real time Json messages from Kafka and ingested into Hadoop Distributed File System
• Created Kafka – Spark streaming integration, flattened the nested Json messages fields and saved that data into Hive tables
• Tuned the model performance by optimizing 2 parameters - Batch Interval and Block Interval

Tax Calculation & Reporting (ETL Process) 
• Created data pipeline and transformed datasets in 100 terabytes range from multiple RDBMS data sources and loaded them over
Hadoop distributed file system, providing 70% of time efficiency in querying data for analysis
• Used Sqoop for data migration and Apache Spark, Hive, Pig and SQL for calculation of economic sector for customer and
reported the updated economic sector as well as update Tax charges at customer level
• Improved performance of transactional system by using HDFS for reporting, led to revenue rise by 120k pounds/day","Dallas, TEXAS",MS-ITM,13 YEARS 1 MONTH,8 YEARS 11 MONTHS,Financial Services,University of Texas,"Dallas, texas",,
28. Raghu Vamsi Mummaneni,"English ,hindi",,data engineer,Verizon,"• Spearheaded the design and implementation of data warehousing solutions for business intelligence and analytics purposes.
• Collaborated with cross-functional teams to define data warehousing requirements, ensuring alignment with business goals and led the development of ETL (Extract, Transform, Load) processes to move and transform data from various source systems into the data warehouse.
• Engineered data extraction modules to efficiently retrieve and process large datasets with parallel processing techniques to enhance data extraction speed using Pyspark, Python and SQL.
• Designed and implemented ETL pipelines to extract, transform, and load data from diverse external sources like JSON, XML, ORC/Parquet/Text Files into a unified format and ingest the data into Target Database (SQL Server).
• Designed user-friendly interfaces for application dashboard to enhance the user experience with business insights using Python Flask and achieved implementation using complete opensource software and hosted them in a server using docker containers.","Frisco, Texas",MCSE,3years 8 months,2 years and 3 months,IT Services and IT Consulting,IT Services and IT Consulting,"Frisco, Texas",,
29. Prashant Sharma,"English, Hindi",,Data Engineer,Ford Motor Company,"o Support departmental processes related to student recruitment, including peer advising/
mentoring, orientation activities, and delivery of presentations to prospective students from
India
o Lead the preparation for a successful Virtual Job Fair during the COVID-19 pandemic
o Worked with students to collect data and analyze it to better understand their demographics
and needs in the job market
o Contacted multiple employers - carefully selected based on the information we received from
students","Irving, Texas",ME/IIM,10 years and 7 months,7 years and 5 months,Motor Vehicle Manufacturing,,"Irving, Texas",,
30. Sri Krishna Jajula,"english , hindi",,data engineer,CVS Health,"Extracted and analyzed transactional data using SQL queries, Advanced Excel, Identified KPI’s and built dashboards to understand the purchase behavior of products
• Generated the weekly, monthly, and quarterly reports in Tableau and PowerBI and provided influential presentations to the stakeholders and business leaders that summarize to drive effective business solutions
• Created a retail dashboard involving Shell Scripting, Python, Tableau and Power BI that helped in easy analysis of application
• Identified analytical solutions to extract business insights by conducting analysis on different levels of business data with an emphasis on providing instant resolutions which in return brought multiple appreciations from the Business
• Designed relational databases using MS Access for managing, querying, and analyzing data. Organized and analyzed the customer data tables, orders, inventory data to disseminate the important information and tune queries for performance.
• Effectively utilized project procured business analytics tool (AppDynamics) to find root cause for error fixing
• Built self-analytics tool for the client on AWS Quick Sight by integrating AWS Redshift for product performance tracking","Dallas, TEXAS",MS/BAE,6 YEARS 11 month,3 years and 1 month,Hospitals and Health Care,,"Dallas,Texas",,
31.Harini Vemulapalli,"English , telgu",,Data engineer,nationwide,"Experienced in Big Data, Data visualization, Python Development, SQL, and UNIX.
Expert in quantitative analysis, data mining, and interpreting data for insights.
Managed Informatica workflow migrations and reviewed ETL design documents for standards.
Created AWS Glue job for archiving Redshift data to S3, managing S3 data layers, Redshift, and Postgres.
Designed complex ETL processes using Informatica and advanced SQL queries with analytical functions.
Developed Informatica mappings with various transformations like Joiner, Aggregate, Expression, Filter, and Update Strategy.
Managed AWS S3 buckets, performed folder management, and handled logs and objects within each bucket.
Created complex SQL queries and scripts for data extraction and aggregation, ensuring data accuracy.
Prepared high-level analysis reports using Excel and Tableau, offering feedback on data quality and identifying patterns.
Identified and documented limitations in data quality, wrote SQL Queries for data validation, and created Excel summary reports.
Conducted Business requirement gathering, translating into clear specifications and queries.
Performed ETL Data Cleansing, Integration & Transformation using Hive and PySpark.
Worked on importing metadata into Hive using Python and migrated tables and applications to AWS cloud (S3).
Utilized Spark optimization techniques for performance tuning, including Cache/Refresh tables, broadcasting variables, Coalesce/Repartitioning, and modifying configuration variables.
Read data from various sources (CSV, Excel, HTML, SQL), conducted data analysis, and wrote to diverse data sources.
Developed and managed business logic through backend Python code.","Columbus, Ohio",MS/BAE,3 YEARS 10 months,1 year 4 month,Insurance,Hospitals and Health Care,"Dallas,Texas",,
32. Rohit Kosireddi,"ENGLISH, hindi",,Data engineer,Transamerica,"-Demonstrated mastery in Big Data technologies and platforms like HDFS, MapReduce, YARN, Apache Cassandra, NoSQL, Apache Spark, Python,Scala, Sqoop, HBase, Hive, Oozie, Impala, and Pig for robust data solutions.
-Engineered and deployed Spark-SQL and PySpark applications in Databricks for ETL operations, successfully executing data extraction, transformation and aggregation across multiple file formats like JSON, CSV, and Parquet; strategically derived actionable OLAP and ODS insights from customer usage
patterns.
-Adapt in Amazon Web Services (AWS) ecosystem, including EC2, S3, RDS, IAM, Auto Scaling, CloudWatch, SNS, Athena, Glue, Kinesis, Lambda,EMR, Redshift, and DynamoDB for cloud-based data solutions.
-Developed serverless ETL data pipelines through AWS Lambda functions, achieving seamless data integration with Glue Catalog and efficient querying capabilities in AWS Athena; executed robust cloud migration strategies from on-premises to AWS Cloud using EMR, S3, and DynamoDB.","Plano,Texas",MBAE,3 YEARS,2years 3 months,Financial Services,IT Services and IT Consulting,"Lewisville, Texas",,
33. Aadarsh Nalla,"English, Telgu",,Data Engineer,Charles schwab,"✔ Contribute to the development of data frameworks on cloud
✔ Write and review technical documents, including requirements and design documents for existing and future data systems, as well as data standards and policies
✔ Creating Data Pipelines – implementation of Kafka to BigQuery and Kafka to GCS 
✔ Creating DAG’s for HQL to BQL and hive to bigquery – extract hive hdfs files and store in gcs bucket and load to bigquery.
✔ Cloud function jobs to load data to Firestore/Bigtable
✔ Collaborate with analysts, support/system engineers, and business stakeholders to ensure our data infrastructure meets constantly evolving requirements Working as a Lead and assigning various tasks as per Scrum calls and taking the JIRA’s to closure.
 As part of migration project - move the Hadoop files into the Google cloud storage buckets , so architecting and creating buckets and the folder structure for each subject areas 
 Lift and shift of hive and Teradata tables/data catalogues to Big query/data processing along with tuning, data types and write validation queries
 Good Hands on with CICD tools in GCP Eco systems such as cloud build and code for version control and continuous deployments.
 Working as a Lead and assigning various tasks as per Scrum calls and taking the JIRA’s to closure.
 Worked on requirement gathering by interacting with client/business, creating impact analysis and design documents, proposing solutions, defect fixing and estimating the hours.
 Analyse the requirements along with Defects and performance and its related mapping design’s and providing SQl’s for the reporting and documenting them in JIRA and assigning story points based on the estimated work and complexity. 
 Worked on providing SQL queries for analytical layer data for Tableau reporting 
 Worked on the refactoring whole ETL design to load the data into cloud with the logic’s built in on-prem world.
 Moving of DR files from Hadoop/NAS files to GCS buckets.
 Data quality checks in Big Query and verify data accuracy between on Prem vs cloud data using in-house tool MDCert which will predominantly check data and type with counts.
 Code reviews to ensure code developed meets the requirements.
 Analyse the data by these mdcerts and provide solutions for the data discrepancies.
Also schedule triage meetings with the different application teams on the downstream reporting data and create adhoc reporting views for getting analytical data to their reports.
Involved in different initiatives to give value add solutions to customer to help the business productivity and efficiency effectiveness.","Westlake, Texas",Btech ECE,11 years 5 months,6 years 6 months,Financial Services,Information Technology & Services,"Irving, Texas",,
34. Vyshnavi Yerragunda,"English, Telgu",,data engineer,Capital One ,"May 2023 to Present · 1 yr 3 mos
•Orchestrated end-to-end data processing pipelines on AWS, leveraging AWS Glue for ETL, AWS S3 for scalable storage, AWS Kinesis for real-time data ingestion, and AWS Redshift for high-performance analytics, ensuring efficient data management and actionable insights.
•Developed the Spark SQL Jobs and processed the data in Amazon S3 with complex business requirements.
•Created the Json configuration files for cleansing the data through generic Spark framework.
•Proficiently utilized AWS Glue for automating ETL processes, significantly reducing data processing time and enhancing overall efficiency in data transformation and integration workflows.
•Developed various functionalities for Data Ingestion framework using Python. 
•Create and manage data access APIs using RESTful APIs implemented with frameworks like FastAPI in Python. These APIs enable seamless interaction with the underlying data infrastructure, providing secure and efficient access to data for various applications and services.
•Successfully implemented AWS Kinesis for real-time data streaming, enabling rapid ingestion and processing of large volumes of data, facilitating timely insights and actionable intelligence for critical business decisions.
•Successfully implemented SCD2 logic using Spark for master reference data, enhancing historical data accuracy by 15%. 
•Designed and implemented AWS Redshift data warehouses, optimizing performance and scalability to support complex analytics workloads.
•Troubleshot and debugged CI/CD pipelines using Git and Jenkins to ensure the quality and integrity of the code base.
•Utilized Kubernetes to orchestrate containerized data processing and analytics workloads, ensuring seamless deployment, scaling, and management of data pipelines in a dynamic and efficient manner.","Dallas, TEXAS",MS/BAE,5 years 6 months,,Financial Services,Business Consulting and Services,"Dallas , texas",,
,,,data engineer,Deloitte,"Jun 2019 to Dec 2021 · 2 yrs 7 mos
•Designing and implementing data pipelines to extract, transform, and load (ETL) data from various sources using ADF(Azure Data Factory) into Azure data services like Azure Data Lake, Azure SQL Database, or Azure Synapse Analytics. 
•Experienced in crafting Python scripts, SSIS packages, and ETL tools to facilitate efficient data extraction, transformation, and loading into data warehouse systems, driving data-driven decision-making and business success. 
•Managed data flow in an Azure Synapse environment, extracting files from Azure Data Lake Storage Gen2 and orchestrating transformations before storing intermediate data in sql database and sending the output data to Azure Blob Storage.
•Utilized Snowflake's cloud-native architecture to build and maintain data warehouses, enabling seamless integration with various data sources.
•Developed and maintained batch and real-time data processing systems using Big Data technologies (Hadoop, Spark, Kafka).
•Used PySpark and Databricks to create complex mappings, transformations, and workflows for data integration, data quality, and data validation processes. 
•Have processed history & incremental data using Spark for data validation & for historical data processing. 
•Skilled in building and publishing customized interactive reports, dashboards, and report scheduling on Power BI, facilitating data-driven insights and streamlined data communication for better decision-making.","dallas ,texas",,,,,,,,
35. Siva Koritela,"English, Tamil",,Data engineer,UnitedHealth Group,"• Collaborated within a cross-functional team to automate and optimize processes in the Claims Management application, resulting in a
36% reduction in manual QA tester hours and a 40% decrease in bug identification time.
• Enhanced Data base and created reusable components in ETL pipelines, along with developing APIs for database data retrieval. This
led to a notable 65% increase in user satisfaction, as measured by user surveys.
• Authored design documents and executed the development and deployment (CI/CD) of pivotal features from database end within the
Claims Management application, streamlining workflows for analysts and managers, and enhancing operational efficiency.
• Developed and optimized T-SQL components, stored procedures, functions, views, joins, constraints, temp tables, CTEs, and table
variables, version control (Git), and deployment using Azure and Jenkins. Strong advocate of Agile methodologies (Scrum, Kanban).","Plano, Texas",MTech CSE,8 years 8 months,2years 2 months,Hospitals and Health Care,IT Services and IT Consulting,"Plano,Texas",,
,,,Data Analytics,Innovaccer,"• Analyzed Business Requirements to develop Functional and detail Design Specifications of the application.
• Involved in Data Modeling for ensuring data integrity, consistency and avoiding redundancy.
• Applied advanced Excel skills (pivot tables, macros, lookups, charts) and Access database querying skills in streamlining and automating accounting processes.
• Amazon data migration services, Lambda functions, Amazon Cloud services.
• Executing Json files through Python environment on Function as a service (FAAS).","Plano, Texas",,,,,,,,
36. Rajesh Doolla,"English,tamil",,Data Engineer,EPAM Systems,"Plano, Texas, United States · On-site
• Architected and Designing Several end-to-end ML model data pipelines productionization solution for Recs including feature store updates, offline / online inferencing, model training and evaluation by using the ML EG Platform like Model Registry Service, Model Deployment Service, Databricks and Dataproc by using the Pyspark.
• Extensive work experience in Both AWS and GCP Data Engineer Cloud Components.
• Worked as Big Data Cloud Engineer with big data components from both on-premises and cloud platforms; Hadoop, Hive, Sqoop, HBase, Kafka, PySpark, Snowflake, Databricks, Airflow, AWSEMR, S3, Redshift, Athena, Data pipeline, Databricks, GCP – Big Query, Dataproc, Cloud Functions, GCR, Kubernetes, Composer
• Working knowledge on the Migration of On-prem SQL and Hadoop loads to GCP BQ
• Implementing containerized online inferencing services by using the BentoML. 
• Implementing ML and data pipelines both in DataProc and Databricks emphasis on reliability, cost reductions, standardization. Orchestrated the data pipelines using the Airflow. 
• Write app logs of the ML Orchestrator to Kafka Stream and sink to Datalake table in Iceberg format. 
• Worked and Implementing the Delta Live tables framework in Databricks. Used the Vector DB’s like Redis as a feature store for the improved query midperformance. 
• Designed and Implemented the ETL pipelines to extract the data from clickstream tables to sink the data into Snowflake. Designed and developed the machine learning pipeline for topic discovery unsupervised task based on NMF and LDA algorithm with cluster stability technique
• Worked and implemented the CI/CD approach for data pipeline migration using Jenkins, Spinnaker, and docker.Built Kibana and Datadog dashboards for ML monitoring & reporting for the Opex. Logging the application data into Splunk.
• Performed load testing for the online inferencing model by using Locust framework (MLOps).","Plano, Texas",Btech CSE,14 years 4 months,7 years 10 months,IT Services and IT Consulting,Business Consulting and Services,"Plano, Texas",,
,,,,Accenture,"• Understand and overseeing the full life cycle of a Hadoop solution which involves carrying out requirement analysis, selecting the platform, and designing the technical architecture. Engage with Clients / BA / Managers for strategic requirement gatherings, design proposals and ensure prompt resolution of gaps and roadblocks.
• Architect and develop data pipelines to ingest, process, and report the data. Designed the Schema, structure of the tables as per the Requirement document in Redshift.
• Data sources are extracted, transformed, and loaded to generate CSV data files with Python and loaded into the s3 bucket using the Dataproc to AWS Dynamo DB. 
• Build reporting dashboards in ELK (Elasticsearch & Kibana) platform for the end-users.
• Building End to End Data Pipelines using the AWS Data Pipeline using the EMR, Glue, Athena, Redshift, Dynomo DB and Airflow.
• Building End to End Data Pipelines using the GCP Data Pipeline using the Google DataProc and orchestrate the pipelines with google composer.
• Develop an interface to read data from Kafka, load to Hadoop and analyze it. Automate the run & monitoring processes of data pipelines. 
• Design and build a real-time processing pipeline to get data from the source, ingest in Hadoop, process it using Spark and save the output in Hive tables.
• Making sure to consume the data using Load Balancer, and implement failover mechanisms.
• Redesign the existing legacy implementations to a unified workflow – ingestion, analytics & reporting.
• Automated the CI/CD deployment using Jenkins. Done the Config changes in Jenkins jobs to push the image to Artifactory Repo. Written docker files from the scratch to build the image in docker.","Hyderabad, Telengana",,,,,,,,
37. Sai Suma,English,,Data Engineer,Walmart,"• Created BigQuery authorized views for row level security or exposing the data to other teams.
• Expertise in designing and deployment of Hadoop cluster and different Big Data analytic tools including Pig, Hive,
SQOOP,
• Apache Spark, with Cloudera Distribution.
• Developed Scala application to ingest the data from Kafka topic to Big Query.
• Developed Spark code using Scala and Spark-SQL for faster processing and testing.
• Worked on Spark SQL for joining multi-hive tables and writing them to a final hive table.
• Created Spark jobs to do lighting speed analytics over the Spark cluster.
• Data sources are extracted, transformed, and loaded to generate CSV data files with Python programming and SQL
queries.
• Design ETL using Internal/External tables and store in parquet format for efficiency.
• Performed advanced procedures like text analytics and processing using the in-memory computing capabilities of
Spark.
• Developed Spark/Scala, and Python for regular expression (regex) projects in the Hadoop/Hive environment with
Linux/Windows for big data resources.
• Continuous monitoring and managing of the Hadoop cluster through Cloudera Manager.
• Used Spark API over Cloudera Hadoop YARN to perform analytics on data in Hive.
• Responsible in creating Hive tables, loading with data, and writing Hive queries.
• Worked on User Defined Functions in Hive to load the data from HDFS to run aggregation functions on multiple rows.
• Executed Hadoop/Spark jobs on Data Proc and data is stored in GCS Buckets.
• Used Zookeeper to store offsets of messages consumed for a specific topic and partition by a specific Consumer Group
in Kafka.
• Implemented CI/CD for all the products in the repository using Jenkins.
• Experience in using Docker images to spin up applications on application platform like Kubernetes.
• Build data pipelines in airflow in GCP for ETL related jobs using different airflow operator","Dallas,Texas",Master's DS,6 years 3 months,,Retail,,"Dallas, Texas",,
38. Sri Harsha Reddy Pothireddy,"English, Tamil",Yes,Data Engineer,Roche,"• Leveraging Azure cloud platforms and Databricks for scalable data analysis and model optimization reduced computational costs by 30% and improved prediction accuracy by 15%.
• Implemented Azure services for data storage, processing, and analytics, ensuring seamless integration of diverse data sources and enhancing overall data reliability and accessibility.
• Employed Azure Data Factory to automate and orchestrate complex ETL workflows, reducing manual intervention and enhancing data pipeline efficiency.
• Utilized Azure Data Lake Storage Gen2 for storing and analyzing large volumes of data, enabling scalable and cost-effective data processing solutions.
• Leveraged Azure Synapse Analytics for advanced data warehousing solutions, enabling rapid query processing and real-time analytics capabilities to support data-driven decision-making.
• Streamlined data processing workflows using Azure services, such as Azure Databricks, for efficient data analysis and model optimization.
• Implemented ETL processes using Python and SQL to ensure data quality and consistency, reducing manual intervention by 20%.
• Utilized big data technologies like Spark and Databricks to efficiently process and analyze large datasets.
• Optimizing table structures and indexing strategies in MySQL databases accelerated database query responsiveness.
• Utilized Power Query to efficiently connect and transform data from various sources, reducing data preparation time by 30%.","Texas, United States",Mtech CSE,5 years 6 month,2 years 8 months,Biotechnology Research,IT Services and IT Consulting,"Denton, Texas",,https://www.linkedin.com/in/sri-harsha-reddy-pothireddy-062871120/
,,,Data analyst,Dixon Technologies,"• Analyzed complex datasets using Python, SQL, and R, yielding 3+ actionable insights per quarter, driving business growth and innovation.
• Implemented Python libraries (NumPy, Pandas, scikit-learn) for in-depth analysis, resulting in predictive models and data-driven insights guiding business strategies.
• Created interactive dashboards in Power BI, Excel, and relevant tools contributed to a 20% increase in data-driven decision-making across departments.
• Production of comprehensive reports and visualizations from PostgreSQL data led to a 30% enhancement in data-informed decision-making.
• Executed robust ETL processes, ensuring 98% data quality and consistency through validation, anomaly detection, and error correction.
• Utilized AWS tools for real-time data analytics, reducing decision-making time by 30%.
• Led analytical projects using Agile (SCRUM) methodologies, delivering on-time and within-scope projects.
• Imported and analyzed complex claims data using Pandas, ensuring punctual and precise report submissions.
• Contributed to physical and logical data modeling, enhancing data accuracy by 15%.",.,,,,,,,,
39. Uzair S,English,,Data Engineer,JPMorgan Chase & Co.,"• Developed scalable applications using Python, leveraging AWS services such as EC2, S3, Lambda, Dynamodb and RDS for efficient data processing and storage along with Apache airflow.
• Implemented infrastructure as code using Terraform to automate provisioning and management of AWS resources, reducing deployment time by 50%.
• Orchestrated containerized applications on Kubernetes clusters, optimizing resource utilization and ensuring high availability.
• Established CI/CD pipelines with Jules (Jenkins), enabling automated testing and deployment of software releases, resulting in a 30% increase in deployment frequency.
• Used python for automation of the routine tasks, writing DAG for airflow and lambda functions, API development and other places accordingly.
• Led system design initiatives, incorporating Big Data technologies like Hadoop and Spark to handle large datasets efficiently.
• Implemented security best practices and compliance standards in AWS environments, including IAM policies, encryption, and network security.
• Collaborated with cross-functional teams to troubleshoot and resolve infrastructure issues, ensuring smooth operation of applications and services.
• Ensured operational stability by monitoring application performance and implementing proactive measures to mitigate issues.
• Collaborated with cross-functional teams to deliver solutions that align with business objectives and adhere to security standards.
• Championed agile methodologies, facilitating daily stand-ups, sprint planning, and retrospective meetings to improve team efficiency and productivity.","Planao,Texas","Master's degree, Big Data Analytics and Information Technology",3 years 11 months,,Financial Services,,"Irving, Texas",,https://www.linkedin.com/in/uzairss/
40.Mukesh Koneru,"English, Tamil",yes,Data Engineer,CVS Health,"Familiarity with Jupyter notebooks for data analysis.
• Skilled in validation data modules for parsing and loading data in healthcare.
• Competency in loading JSON files into intermediate and final FHIR stores.
• Solid understanding of the data lifecycle, including profiling, mining, migration, quality integration, master data management, and metadata management services.
• Utilized data frames to read text data and CSV data from cloud storage.
• Worked extensively with Google Cloud Platform (GCP) services, including cloud SQL, Dataproc, Google Cloud Storage (GCS), Cloud Functions, BigQuery, and Dataflow.
• Built data pipelines in Apache Airflow on GCP for ETL-related tasks using various airflow operators.
• Experience in migrating Oracle databases to Big Query and using Power BI for reporting.
• Built Power BI reports on Azure Analysis Services.
• Developed scripts for automating ETL execution in a Unix environment.
• Coordinated with teams to develop frameworks for generating daily ad hoc reports and extracts from enterprise data stored in Big Query.
• Collaborated with data science teams to implement advanced analytical models in Hadoop clusters","Frisco, Texas",,10 years,1 years 11 month,Hospitals and Health Care,Financial Services,"Frisco, Texas",,https://www.linkedin.com/in/mukeshk1993/
,,,,Barclays,"● Build a general framework for ingestion and manipulation of data from multiple batches and streaming sources using Spark. Enhanced the existing spark streaming applications to support structured streaming and new sources like Kafka, JMS topics, and queues to improve the message delivery semantics.
● Experience with different components of Spark and Hive along with extensive experience working on performance optimization. 
● Support for processing data in a variety of formats, including POS XML, JSON, and flat files, was added.
● Used PySpark data frame to read text data, CSV data, image data from HDFS and Amazon S3. 
● Development of ETL pipelines for transferring data from diverse sources to many layers in S3 using AWS Glue and Databricks.
● Implemented partitioning strategies to improve the performance of spark tasks that ingest tables from multiple JDBC sources like Oracle.
● Developed Lambda scripts in Python to launch the EMR clusters on-demand and automated the process.
● Enforced the deletion of records containing Personally Identifiable Information from multiple layers of data based on the user requests to be compliant to CCPA.
● Developed ETL pipelines using Data Pipelines and EMR jobs for ingesting data from various sources to store in S3.","Frisco, Texas",,,,,,,,
41. Manasa C,"English, Hindi",yes,Data Engineer,Wells Fargo," Utilized advanced Excel skills (macros, v-lookups, h-lookups, pivot tables) to analyze and manipulate data for detailed reporting and decision-making.
 Supported Warehouse Management Systems (WMS) and order management applications by maintaining and troubleshooting database systems.
 Converted raw data into actionable insights, enabling data-driven decision-making and strategic planning.
 Handled inventory discrepancies between physical inventory counts and system records, ensuring accuracy and reliability of inventory data.
 Maintained up-to-date and accurate inventory data, both physically and systemically, to support operational efficiency and reduce errors.
 Employed SQL expertise to identify and manage inventory groups, including holds on items and allocations, enhancing inventory control.
 Maintained databases, extracted information, and developed metrics to measure and improve overall performance, contributing to continuous improvement initiatives.
 Researched performance and productivity data, analyzing error rates to identify trends and areas for improvement.
 Investigated and addressed root causes of inventory transaction errors, implementing corrective actions to enhance data integrity","Arlington, Texas,",Masters Data Science,4 years 2 months,2 years 7 months,Financial Services,IT Services and IT Consulting,"Arlington, Texas",,https://www.linkedin.com/in/manasa-c-37a737172/
,,,Data Analyst,tcs,"Collaborated with cross-functional teams to design and implement data backup and recovery 
strategies, minimizing the risk of data loss.
• Provided technical support and troubleshooting assistance to end-users, resolving IT incidents and 
service requests in a timely manner.
• Documented IT processes and procedures, creating comprehensive guides for system 
administrators and end-users.
• Conducted exploratory data analysis to uncover patterns, anomalies, and correlations within 
datasets, informing business strategies and initiatives.
• Created data visualizations, including charts, graphs, and heatmaps, to effectively present 
findings and support data-driven decision-making processes.
• Created data models in Power BI using relationships, measures, and calculated columns to 
establish logical connections and hierarchies within datasets.
Developed and implemented data cleaning scripts and workflows using Python libraries such as 
pandas, NumPy, and scikit-learn to automate data cleansing processes and improve efficiency.
• Assisted in the implementation of data security measures to protect sensitive information and 
ensure compliance with industry regulations.","Bengaluru, Karnataka",,,,,,,,
42. Aravindh  Madhavan,"English, hindi",   yes,Data Engineer,JPMorgan Chase & Co.,"• Led the migration of the on-premises Hadoop data ecosystem to AWS cloud, resulting in improved scalability, reliability, and cost efficiency.
• Built ETL/ELT data pipelines using AWS EMR, Glue, Lambda, EKS, and other AWS data analytics services, along with Spark, to transform data across various stages of the data lifecycle.
• Configured and managed AWS EMR clusters tailored to specific job requirements, optimizing resource utilization and improving job performance.
• Developed and implemented ETL processes using SparkSQL on EMR to extract, transform, and aggregate data from multiple sources and file formats, loading it into Amazon Redshift.
• Implemented a hybrid automation strategy using Control-M for on-premises environments and Airflow for AWS, enhancing operational efficiency and ensuring seamless data transfers.
• Developed and implemented custom shell scripts to automate data processing jobs, enhancing workflow efficiency and reliability.
• Provided production on-call support, resolving data pipeline issues, system outages, and performance bottlenecks to ensure uninterrupted data operations.
• Designed and implemented incremental data loading logic for fact and dimensional tables, reducing storage usage on S3 and minimizing redundant data storage.
• Investigated and resolved root causes of EMR failures and performance issues, significantly improving job performance.
• Utilized Jenkins CI/CD pipelines and Liquibase to provision, configure, and maintain modular and scalable ETL pipelines across multiple AWS regions.","Plano, Texas",Master's Data Science,5 Years 8 months,4 years,Financial Services,,"Plano, Texas",,https://www.linkedin.com/in/aravindh-madhavan/
,,,Software engineer,Texas Tech University,"• Analyzed RAWLS datasets using Python libraries and SQL queries, creating bespoke tables in Tableau and visualizing results through interactive dashboards.
• Worked on all phases of data integration development, including real-time and batch data pipelines design and implementation, as well as Big Data ETL and reporting support.
• Migrated legacy Data Warehouse from Oracle/SQL Server to a central Data Lake on AWS using Informatica.
• Developed real-time streaming applications using PySpark, Kafka, and Hive on a distributed Hadoop cluster.
• Created serverless data pipelines using AWS Lambda, Glue Catalog, and Athena; managed workflows with Apache Airflow.
• Developed Spark applications using PySpark and Spark-SQL for data extraction, transformation, and aggregation from various file formats.",United States,,,,,,,,
43. Ramyasri Teegala,"English,Hindi",Yes,Data Engineer,Anblicks,"•Developed scalable data pipelines using Apache Kafka, Apache Nifi, and Talend, processing 5 TB daily, reducing processing time by 50%, and ensuring data accuracy and integrity.
•Managed MySQL database, optimizing queries and indexing to handle millions of records efficiently, achieving a 30% improvement in query performance.
•Orchestrated the extraction, transformation, and loading (ETL) of over 20million delivery records using Apache Spark and AWS Glue, ensuring a streamlined data pipeline for analysis.
•Developed and deployed Machine Learning models Random Forest and XGBoost with Python's scikit-learn and MLlib on Apache Spark, boosting forecasting accuracy by 15%.
•Developed data models and optimized storage on S3, easing efficient data retrieval and reducing storage costs by 20%, also used Python and SQL for data cleaning, transformation, and analysis, for actionable insights.
•Created functions in AWS Lambda for event-driven processing and optimized storage classes on AWS S3, resulting in a 30% cost reduction.
•Integrated sentiment analysis and topic modeling using NLTK and spaCy into the data pipeline to analyze customer feedback and social media data, providing insights for marketing strategies & product enhancements.
•Built a data lake and optimized computational resources using PySpark on AWS EMR.
•Utilized Power BI for interactive dashboards and visualizations, and managed code integrity through Git version control, ensuring seamless collaboration with a team of 6 data engineers.",United States,Mtech CSE,5 years 8 months,4 years 8 months,IT Services and IT Consulting,IT Services and IT Consulting,"Dallas, Texas",,https://www.linkedin.com/in/ramyasri-teegala/
44.Merve Karakis,English,,Data engineer,Infosys,"-Accomplished the various tasks in Development and Production Environment which contains Amazon Web Services such as Redshift, EC2, S3 and AWS Lambda; and Databricks, ADLS, SQL Server, Azure Storage and ADF.
-Designed and deployed many ETL workflows to extract, transform and load data from different source systems such as Oracle, SQL Server, and MYSQL to Azure Data Lake Gen2 using a combination of Azure Data Factory, Qlik Replicate, T-SQL, Spark SQL,Azure Data Lake Analytics. 
-Data ingestion to one or more Azure Services such as Azure Data Lake, Azure Storage, Azure SQL, Azure Datawarehouse and processing the data in Azure Databricks.
-Developed Spark Applications using PySpark and Spark SQL in Databricks for data extraction, transformation, and aggregation from multiple systems and stored on ADLS using Databricks notebooks.
-Utilized ADF Pipelines to copy parquet files from ADLS Gen2 location to Azure Synapse Analytics Data Warehouse.
-Good understanding of Spark Architecture with Databricks including Spark SQL, Spark Core, DataFrame, Driver Node, Worker Node, Stages, Executors and Tasks, Deployment Modes, Fault Tolerance, the Execution Hierarchy and Spark Streaming.
-Worked in Solution Design, Development, Deployment, Troubleshooting and Debugging when replication errors, CDC Framework, data replication and other codes production issues.
-Designed and deployed ETL workflows to extract, transform and load data from different AWS S3 buckets using Data Sharing mechanism. 
-Configured and managed windows servers on Amazon using IAM, Security Groups, Relation Databases, SSL, EBS, ELB, EC2.
-Good experience in configuring secure cloud VPC using private/ public network with subnets in AWS.
-Enabled Amazon IAM service to grant permission and resources to developers and business users in the project and managed roles and permissions of users based on the necessities.
-Utilized Terraform Code for AWS DMS, Python Boto3 for AWS Appflow to replicate data into S3 buckets.","Plano ,Texas",MA / mathematics education,8 years 8 months,,IT Services and IT Consulting,Business Consulting and Services,"Plano, Texas",,https://www.linkedin.com/in/mervekarakis/
,,,Senior Business Intelligence Developer,L.E.K. Consulting,"-As a technical expert, provided recommendations in assessing new software projects and initiatives to support and enhance existing OLTP and OLAP application.
-Actively partaken in end-user and client meetings to gather Business Requirements Documents (BRD), Data Mapping documents and Data Dictionaries. 
-Designed, Developed and Maintained Data Engineering solutions by providing full end-to-end support in Requirement Gathering, Documentation processes, Solution Design, Development, Deployment, Troubleshooting and Debugging when ETLs, stored procs and other codes had production issues.
-Designed and deployed many ETL workflows via Azure Data Factory (ADF) and SSIS packages to extract, transform and load data from Oracle, SQL Server databases, excel and flat file sources into DW. 
-Expert Level TSQL skills, creating complex and efficient stored procedures, User Defined Functions (UDF), Triggers, Views, Common Table Expressions (CTE), Subqueries, Indexes, Table Partitions.
-Defined the dimension, fact tables and designed the Data-Mart using Snowflake and Star schemas.
-Created both clustered and non-clustered Indexes to retrieve faster the data from the databases. 
-Modified slowly running queries by replacing row by row operations with set-based approaches which implement correct joins, CTEs, Temporary Tables and Window / Ranking Functions.
-Advanced level expertise in Microsoft Azure cloud platform, working with ADF V2, ADF Data flows, Azure Databricks, Azure SQL PAAS and IAAS, Azure Data Lakes, and other Azure services.
-Built efficient ETL packages, using Azure Data Factory ADF2 pipelines for processing Fact and Dimension tables with complex transforms and SCD type 1/ type 2 changes.
-Performed Dimensional Modeling for Data Warehousing development using Azure data platform, including Azure SQL, Azure Data Factory, Azure Databricks, Azure SQL, Azure Data Lake Storage","Planao,Texas",,,,,,,,
45.Mahesh G,"English, Tamil,Hindi",yes,Data Engineer,Nissan North America,"● Developed Spark jobs to clean data obtained from various feeds to make it suitable for ingestion into Hive tables for analysis.
● Developed the batch scripts to fetch the data from AWS S3 Storage and do required transformations in Scala using Spark framework.
● Developed Scala scripts, UDF’s using both Data frames/SQL and RDD/MapReduce in Spark for Data Aggregation, queries and writing data back into RDBMS through Sqoop.
● Responsible for designing and building new data models and schemas using Python and SQL.
● Built Spark jobs using PySpark to perform ETL for data in S3 Data Lake.
● Involved in developing data Pipeline using Kafka, Spark and Hive to ingest, transform and Analyzing data. 
● Developed Pig Scripts, Pig UDFs and Hive Scripts, Hive UDFs to Analyses HDFS data.
● Involved in ETL process consisting of data transformation, data sourcing, mapping, conversion and loading.
● Performing ETL testing activities like running the Jobs, Extracting the data using necessary queries from database transform, and upload into the Data warehouse servers. 
● Developed connections for Tableau Application to core and peripheral data sources like Flat files, Microsoft Excel, Tableau Server, Amazon Redshift Database, Microsoft SQL Server, etc. to Analyze complicated data.
● Used Apache Kafka to aggregate web log data from multiple servers and make them available in downstream systems for analysis.
● Utilized AWS services with focus on big data architect /analytics / enterprise Data warehouse and business intelligence solutions to ensure optimal architecture, scalability, flexibility, availability, performance, and to provide meaningful and valuable information for better decision-making.","Franklin, Tennessee",MS/ Busines Analytics,6 years 8 month,2 years 3 month,,Investment Banking,"Irving, Texas",,https://www.linkedin.com/in/mahesh-g-b6361719b/
,,,,Jefferies,"● Gathered, analyzed, and translated business requirements to technical requirements, communicated with other departments to collect client business requirements and access available data.
● Developed various spark applications using Scala to perform various enrichments of user behavioral data (click stream data) merged with user profile data. 
● Involved in developing production ready spark applications using Spark RDD APIs, Data frames, Spark-SQL and Spark-Streaming API's.
● Involved in implementing advanced procedures like text analytics and processing using Apache Spark written in Scala.
● Involved in converting Hive/SQL queries into Spark transformations using Spark RDDs, Spark SQL using Scala.
● Using Apache Kafka for Streaming Purpose.
● Design and implement secure data pipelines into a Snowflake data warehouse from on-premises and cloud data sources.
● Developed Simple to complex MapReduce Jobs using Hive and Pig. Developed Shell and Python scripts to automate and provide Control flow to Pig scripts. 
● Involved in Extraction, Transformation and Loading (ETL) of data from multiple sources like Flat files, XML files, and Databases.","Houston, Texas,"

Name,Languages spoken,Indian experience,Role,Company,job description,University,Course,Work experience,Work experience in the U.S,Industry,Previous industry type,Location,Location from India,LinkedIn Profile
1. Manish RamChandani,"English, hindi",,Business Analyst,TXU Energy,,UTD,MSBA,2 Years and 2 months,5 months,IT Services and IT Consulting ,IT Services and IT Consulting ,Dallas. Tx,,
,,,Data Analyst,Foster Roads,"• Led implementation of visualization by breaking down the problem and creating a planning chart with Tableau, resulting in 12% increase in operational efficiency. • Directed statistical analysis using scikit-learn and seaborn, contributing to a 6% increase in customer retention. • Collaborated with development teams, identifying data-driven solutions contributing to $43,000 annual cost savings. • Used propensity modeling to refine user engagement KPIs, designed and executed A/B testing frameworks leading UX overhaul, resulting in a 20% increase in session duration.",,,,,,,,,
,,,Financial Analyst,Unisoft Technologies Nagpur,"• Developed and maintained data pipelines using SQL, significantly reducing manual workload time by 20%. • Developed a fraud detection model using logit / Probit regression analysis which helped in identifying customers. • Designed and optimized databases to improve data quality and accessibility, reducing data processing time by 10%. • Automated financial reports using UI Path, creating practical learning opportunities for students.",,,,,,,,,
,,,Data Analyst,Unisoft Technologies Nagpur,"• Developed & implemented data models for the firm's relational database, showcasing proficiency and precision in database design and management.",,,,,,,,,
2. Louis Pien,English,,Business Analyst,JP Morgan & Chase,• Risk Data Strategy & Execution,UTD,MSBA,3 years and 6 months,3 years and 6 months,Finance,Service,"Plano, Tx",,
,,,Data Analyst,Service Experts Heating & Air Conditioning ,"• Develop and implement interactive dashboards in Power BI to optimize recurring and ad-hoc credit risk reporting processes, increasing overall KPI tracking productivity by 50% • Generate reports/aggregated data from multiple sources (Spreadsheet/Power BI Report/SQL Database) by Excel Power Query to assist internal business requirements and management needs on a timely basis • Build automated VBA Macros and efficient procedures to conduct large-scale aging accounts receivable analysis, saving up to 400% in operational labor hours • Support activities across CRDM team and third-party vendors to ensure accurate agendas, acting as the subject-matter expert in key data analytics for the organization to provide business insights and improvements",,,,,,,,,
,,,Sales & Marketing Intern ,Yamaha Corporation,,,,,,,,,,
3. Robin Alunkal,English,,Business Analyst,CoreLogic,,UTD,"MSBA, MBA",2 Years and 3 months,2 Years and 3 months,Real Estate,IT service Management,"Allen, Tx",,
,,,Business and Technology Strategy Consultant,NTT Data Services,,,,,,,,,,
4. Amisha Shukla,"English, Hindi",,Business Analyst,Johnson & Johnson,"Implementing Agile Methodology for building an internal application. • Performing Gap analysis by identifying existing technologies, and documenting the enhancements to meet the end-state requirements. • Familiar with MS Project to manage deadlines, and schedules, analyze project information, and interact with different teams. • Working with data models with complex relationships in Power BI and connected different data sources to the Power BI desktop. • Utilizing Microsoft SharePoint to manage the team website for document collaboration and deliverables management. Page 1 of 2 • Creating ad-hoc reports for users in Tableau by connecting various data sources, multiple views, and associated reports. • Creating various UML diagrams Activity Diagrams/State Diagrams and Class diagrams Documented and maintain requirements in Visio. • Involving Joint Application Development (JAD) sessions with SMEs and development teams and documenting functional business requirements as product backlogs using Jira.",UTD,MSBA,4 Years and 7 months,4 Years and 7 months,Pharmaceutical Medical Technology,Retail,"Dallas, Tx",,
,,,Business Analyst,Tesco,"• Developed projects using Software Development Life Cycle (SDLC), and Waterfall Methodology. • Performed SWOT analysis and market research to understand the competitors. • Facilitated JAD sessions, as well as conducted interviews with appropriate business stakeholders. • Created interactive and insightful visualizations using Tableau and Power BI, enhancing data-driven decision-making by stakeholders. • Developed Requirements Traceability Matrix (RTM) using MS Excel. • Managed functional and non-functional business requirements and new request requirements using Jira. • Use MS Visio and Lucid Chart to develop process flows and diagrams in order to provide the stakeholders with a visual representation of the system functions",,,,,,,,,
5. Jaswanth Reddy Yanumula,"English, Telugu",,Business Analyst,Texas Wholesale,,UTD,MSBA,3 Years,2 years and 3 months,Retail,IT Service & Consulting,"Dallas, Tx",,
,,,Business Analyst,Re-Vive,"Successfully managed end-to-end data processes, from collecting and cleaning B2B data using excel and python, to constructing streamlined star schemas using SQL Server for efficient analysis. Devised and finetuned SQL queries, views, and procedures, reducing query execution time. Collaborated cross-functionally to implement ETL solutions, boosting productivity. Seamlessly integrated SSAS data models into Power BI, resulting in interactive KPI-driven dashboards that amplified stakeholder engagement.",,,,,,,,,
,,,Data Analyst,Emergers Technologies,,,,,,,,,,
,,,Industrial Engineering Intern,BHEL ,"Simulated and modeled boiler header manufacturing using FlexSim, elevating efficiency by up to 15%. Implemented quality standards, reducing defects by 4% through Kaizen. Designed lean layout in AutoCAD/visTABLE, increasing throughput by 6% and reducing cycle times by up to 10%.",,,,,,,,,
6. Rashna Bhetwal,"English, hindi, nepalese",,Business Analyst,HireWorks,,Trine University,MS Information Science,7 years and 3 months,3 years and 7 months,Staffing/Employment,IT Services,,,
,,,Business Analyst,Robotech Solutions Pvt. Ltd. ,"As a BA , I bridged business needs with development efforts, ensuring smooth communication and alignment. I introduced Agile tools, reducing project delays Page 1 of 2 and boosting productivity . Collaborating with support teams, I enhanced product usability, reducing complaints by and increasing retention.",,,,,,,,,
,,,Project Program Coordinator,Everest Up Technologies ,"Managed diverse projects, coordinated cross-functional teams, and optimized resources to align with objectives. Spearheaded remote project coordination, enforced deadlines, and enhanced efficiency. Implemented risk assessment framework, streamlined operations, and saved time. Established communication channels, collected project data for strategic decisions, and facilitated post-merger integration seamlessly.",,,,,,,,,
,,,Assistant Inventory Manager,CFMOTO,,,,,,,,,,
7. Alen Koshy,English,,Business Analyst,Dolphin Digital OOH Media,"Utilized Power BI to conduct an in-depth analysis of sales performance and revenue generation for Digital Out-of-Home (DOOH) screens with partnership from T-Mobile, presented within designated Designated Market Areas (DMAs)across the United States. The insights gleaned informed strategic decisionmaking processes to an increase of 20%",UTD,BS Information Technology and Systems,1 Year,1 Year,Media,Sales,"Plano, Tx",,
,,,IT Data Analyst ,Dolphin Digital OOH Media,"• Guided a team through Agile methodologies, leveraging Jira for project management, and executed efficient sprints to achieve project milestones. • Utilized Jupyter Notebook to streamline code transfer and testing, ensuring efficiency in the development process, with a quantifiable improvement of 14%. • Managed front-end development using GitHub and Snowflake, collaborating with the team to optimize version control, resulting in a 20% improvement in project efficiency",,,,,,,,,
,,,Retail Sales Associate,Best Buy,"• Generated $140,000 in sales for electronics and 12 financing applications via Citibank's partnership with Best Buy. • Provided excellent customer service skills. Received positive customer feedback, resulting in a customer satisfaction rate of 95%. • Informed and recommend proper technology for the required customer.",,,,,,,,,
8. Teja R,"Enlglish, telugu",,Business Analyst,Genpact Global Tech Inc,,UTD,MS Information Technology,2 years and 3 months,2 years and 3 months,IT Service,,"Frisco, Tx",,
9. Ishika Bhargava,"Enlgish, hindi",,Business Analyst,Alcon,,UTD,MS ITM,3 years and 7 months,2 years and 3 months,Pharmaceuitcal ,IT Services,"Fort Worth, Tx",,
,,,Data Analyst (IT) Intern,Alcon,,,,,,,,,,
,,,IT Intern,Alcon,,,,,,,,,,
,,,Data Analyst Intern,Shriram Fortune Solutions,"• Developed Tableau dashboards for quick analysis of trends and patterns on the customer data for the senior executives • Performed data cleaning techniques and created SQL generator in MS Excel to automate updating the customer information, enhancing workforce",,,,,,,,,
,,,Team Lead,AIESEC,"• Facilitated 50+ international exchanges in collaboration with the United Nations. • Led a team of 8 members and helped the entity achieve an operational upgrade at a national level. • Designed Power BI dashboards for interactive visualizations, creating reports and predicting strategies to be implemented by studying patterns and trends of the previous years. • Organized various events locally for lead generation and enhancing brand awareness involving Youth Speak Forum 2018 sponsored by Coca-Cola.",,,,,,,,,
10. Aditi Agrawal,"English, hindi, gujarathi",,Business Analyst,Aisera,"Led Agile ceremonies such as sprint planning, daily stand-ups, and retrospectives to ensure efficient project execution. • Developed and customized software solutions using Microsoft SharePoint and VBA scripting for Microsoft Office applications. Page 1 of 3 • Created and managed Tableau dashboards and reports, providing stakeholders with real-time insights into key performance metrics. • Performed Gap Analysis on existing processes to identify and resolve discrepancies, ensuring alignment with business goals. • Conducted functional testing and documented defects and enhancement suggestions in Jira, collaborating with developers for resolution. • Established terminology, performed stakeholder analysis, gathered business requirements, modeled business processes, and facilitated Joint Application Development (JAD) sessions. • Utilized CRM to manage client contacts, tracking and documenting interactions and communications.",UTD,MS ITM,4 years and 4 months,9 months,Software,Software,,,
,,,Business Analyst,Freshworks,,,,,,,,,,
11. Nishanth Reddy Polu,"English, telugu",,Business Analyst,Molina Healthcare,"Collaborated within an Agile team to tackle challenges and deliver projects in a fast-paced environment, achieving a 95% problem resolution rate within project timelines. • Gathered and meticulously documented business requirements (BRD) and functional requirements (FRD) through formal and informal sessions, validating stakeholder needs with a 98% accuracy rate. • Utilized advanced Excel functions to create spreadsheets and pivot tables, enabling comprehensive reporting and data analysis, resulting in a 30% reduction in data processing time. • Designed interactive and visually appealing Power BI reports and dashboards, incorporating advanced features such as drill-through, bookmarks, and custom visuals, resulting in engaging and informative data presentations for stakeholders. • Conducted Gap Analysis, SWOT analysis, Cost-Benefit Analysis, and Risk Analysis, providing critical insights that led to a 15% increase in project efficiency and cost savings of $100,000. • Planned and coordinated system releases in close collaboration with business, technology, and infrastructure teams, resulting in a 10% improvement in on-time project delivery. • Developed business transformation strategies and conducted root cause analysis to drive improvements, leading to a 25% increase in operational efficiency. • Created highly interactive and visually compelling reports and dashboards in Power BI, incorporating custom visuals and DAX calculations to provide deep insights into business performance, resulting in a 20% improvement in datadriven decision-making. • Conducted JAD sessions with Subject Matter Experts (SMEs), gathered functional requirements from system users, and created comprehensive Business Requirement Documents (BRD) and Functional Requirement Documents (FRD), organizing requirements systematically and ensuring a 98% defect-free testing process. • Used Python to graphically analyze datasets and obtain insights into how to evaluate the data's nature.",Texas A&M,,3 years and 8 months,1 year,Healthcare,Consulting,"Dallas, Tx",,
,,,Business Analyst,KMPG,"• Gathered User and Business requirements using various elicitation techniques such as Brainstorming, 1-on-1 Interviews, Document analysis, JAD sessions, and Focus Groups. Collaborated closely with product owners and stakeholders, ensuring comprehensive requirements capture. • Reviewed and meticulously gathered requirements from Subject Matter Experts (SMEs) and stakeholders using elicitation techniques. Produced Scope Management Documents, Business Requirement Document (BRD), and Functional Requirement Document (FRD) to incorporate new features into the current website, reducing scope-related issues by 20%. • Worked on data that was a combination of unstructured and structured data from multiple sources and automated the cleaning using Python scripts • Employed Tableau Prep for data preparation tasks, encompassing data cleansing, shaping, and profiling, ensuring data quality and accuracy in preparation for analysis. • Developed, maintained, and improved databases used for tracking data, generating reports, and addressing management queries, enhancing datadriven decision-making. • Worked on gathering analytics and data mining to drive business decisions, providing valuable insights for strategic planning. • Collaborated closely with the Corporate Vendor Management team to ensure alignment with outsource strategy, particularly in call segmentation and resource utilization, leading to a 20% improvement in operational efficiency. • Conducted in-depth GAP analysis by comparing requirements with the current and improved website. Identified gaps using outcome analysis and proxy benchmarking, and documented the GAP analysis report, facilitating targeted improvements. • Performed Root Cause Analysis using techniques like 5 Whys, Fishbone, and affinity diagram to optimize processes, leading to a 15% increase in process efficiency. • Incorporated advanced statistical analysis techniques and custom Python scripts into Tableau to enhance the sophistication of statistical",,,,,,,,,
12. Muhammad Basil,English,,Business Analyst,Cognizant,,UTD,BS Information Technology,3 years and 2 months,3 years and 2 months,IT services & Consulting,Oil & Gas,"Plano, Tx",,
,,,Product Manager,Hack for LA,"• Led successful transition from v1 to v2, enhancing project functionality and ensuring seamless updates. • Streamlined project timelines by assigning GitHub issues strategically and optimizing team productivity and delivery. • Contributed to member retention and organizational growth, fostering strong relationships and facilitating critical meetings with up to 20 members, including top management and the company’s director.",,,,,,,,,
,,,Data Analyst,KW International LLc,"• Extracted and cleaned up to 20,000 data points at a time using company databases and Excel, enhancing data quality and accuracy. • Analyzed data to identify trends and discrepancies, creating comprehensive reports and dynamic PowerPoint presentations for higher management. • Utilized exceptional communication, planning, and organizational skills while closely working with higher management to customize reports and visualizations, facilitating informed decision-making aligned with organizational objectives",,,,,,,,,
13.Juveria Baig,English,,Busines System Analyst,State Farm,"Served as both a business analyst and project manager, driving data-driven initiatives, managing timelines, and facilitating seamless project delivery.

-Project management such as planning iterations/timelines and ensuring Agile project delivery.
- Developed impactful reporting visualizations to showcase architectural competencies and drive improvement.
- Implemented streamlined data governance process across internal teams, fostering collaboration.
- Owned program-level features within Agile/Safe, delivering customized enhancements to Guidewire Policy Center.
- Led training coordination for Agile train of 50+ members, reducing time via SharePoint development.",UTD,M.S./  ITM,10 YEAR 8 month,10 year 8 month,Insurance,Insurance,"Dallas,Texas",,https://www.linkedin.com/in/juveriabaig/
,,,data analyst / Senior Manager,Globe Life,"Led data-driven initiatives, shaped analytics strategy for data driven decision-making. Managed analytics team, collaborated with stakeholders, and oversaw model and dashboard design/maintenance.

- Orchestrated cross-functional collaborations with both internal and external business leaders, ensuring alignment with business objectives and successfully fulfilling a wide range of business use cases.
- Managed a large team of data and BI analysts, data scientists, and engineers, fostering collaboration and driving a 25% increase in team productivity.
- Streamlined reporting processes by converting thousands of text files into relational structures, reducing manual effort by 80% and improving data accuracy.
- Designed and implemented effective reports using Tableau, QlikView, and AWS QuickSight, resulting in a 50% reduction in report generation time and enabling stakeholders to make data-driven decisions with ease.
- Managed vendor relationships, including contract negotiations and external hiring processes, ensuring optimal resources were secured for project success.",UTD,,,,,,,,
14.Vineela Peddi,"English, Hindi",Yes,Senior Business Analyst,JPMorganChase,"• Drove customer retention up by 20% by creating targeted feedback mechanisms and providing analytical insights on results.
• Facilitated Agile sprints and backlog grooming sessions, resulting in a 30% increase in project delivery speed and enhanced team collaboration.
• Leveraged Tableau to consolidate and visualize sales data, resulting in a 15% increase in sales forecast accuracy.
• Identified a new market opportunity that resulted in $2M additional annual revenue.
• Streamlined project tracking and task management in JIRA, resulting in a 25% improvement in team productivity and faster resolution of issues.",UTD,MS  Business Analytics,5 years 1 month,3 years 2 months,Financial Services,Retail,"Greater Seattle Area ,New York",,https://www.linkedin.com/in/vineelapeddi05/
,,,,Walmart,"• Implemented a company-wide software that decreased annual expenditure by $2M.
• Executed complex SQL queries to extract, transform, and load (ETL) data from multiple sources for comprehensive business analysis.
• Supported Agile or Waterfall methodologies within the SDLC framework, adapting project management approaches based on project complexity and stakeholder needs.
• Oversaw the implementation of a new ERP system leading to an improvement of business processes by 30%.
• Utilized advanced Excel functions such as VLOOKUP, INDEX-MATCH, and SUMIFS to manipulate and analyze large datasets efficiently.",UTD,,,,,,,,
15. Hina A ,English,,Business Analyst ,,"• Spearheaded data-driven initiatives, utilizing Python, R, and SQL to analyze and extract insights from large datasets, resulting in a 15% increase in operational efficiency.

• Designed and maintained interactive and user-friendly dashboards in Tableau and Power BI to visualize key performance metrics, enabling the leadership team to make informed decisions and achieve a 20% reduction in reporting time.

• Conducted thorough statistical analysis using tools like SPSS and Excel, leading to the identification of market trends and customer behavior patterns, which contributed to a 10% boost in customer retention.

• Managed cross-functional projects using JIRA and Trello, ensuring seamless communication and project delivery within scope and on time, resulting in a 25% reduction in project delays.

• Implemented business intelligence solutions with QlikView and MicroStrategy, facilitating real-time data access and analytics for stakeholders, leading to a 10% increase in data-driven decision-making.",UTD,"Master's degree, Business Analytic",4 years 7 months,,,,"Dallas, Texas",,https://www.linkedin.com/in/hinaaafreen/
16. Syed Mujtaba Abbas Zaidi,"English, hindi",,Business Analyst ,Intuit,"• Documented metadata for over 2000 tables in the AWS data lake using SQL, Python, and Lucid Chart, resulting in a comprehensive data dictionary that improved data accessibility and usability for company-wide data users.
• Utilized Qlik Sense, Tableau, and ETL tools to ensure clean and reliable financial data migration for organization-wide data lake migration, conducting extensive data cleaning, sampling, testing, and validation to achieve high-quality data.
• Collaborated with leadership to develop and implement robust data governance policies and procedures, ensuring regulatory compliance, effective data stewardship, and data security for highly sensitive data categories.
• Successfully trained end-users on LLM models in Amazon QuickSight and developed custom methodologies to enhance data analysis capabilities and provide more accurate and actionable insights.
• Optimized Qlik Sense reports by creating highly-structured data models and implementing customized SQL queries to reduce Qlik Sense runtime duration by 50% and improve report accuracy.
• Developed comprehensive data models to facilitate effective data analysis and management across the organization through extensive data modelling activities.
• Conducted data classification to identify and categorize sensitive data and implemented specialized security measures to protect confidential information, ensuring data integrity and security.",UTD,Mtech CSE,6 years 4 month,3 years 3 month,Software Development,IT Services and IT Consulting,"Southlake, Texas",,https://www.linkedin.com/in/smz96/
17. Nivethika Jayashree Maine,"english, Tamil",yes,Bussiness Analyst,Massimo Motor Sports,,Team A&M University,"MS, Business Analytics",4 years and 2 months,2 years 10 months,Motor Vehicle Manufacturing,Telecommunications,"Dallas, Texas",,https://www.linkedin.com/in/nivethika-mani/
,,,Data Engineer,AT&T ·,"Coordinated with stakeholders to elicit, analyze, document, and validate business requirements and business analysis.
Programmed python/ Pyspark scripts in Azure Databricks for efficient data transformations including data cleansing and aggregation, resulting in a 30% reduction in data processing time and 94 % increase in the match.
Implemented data quality checks, reducing data errors by 15% and ensuring data integrity.
Applied ML algorithms like FuzzyWuzzy within Azure Databricks to derive predictive models and improve decision-making for match rate by 88%.
Devised data model validations and schema to represent business processes, systems, and Business intelligence analytics.
Managed data pipelines and workflows and ingested 10M data for processing and improving data accuracy by 58%.
Crafted compelling narratives through data visualizations, communicated business data to identify patterns, trends, and key insights to stakeholders.
Tracked changes to the analysis scripts and maintained the code repository in GitHub, resulting in a 25% decrease in code review turnaround time.
Developed interactive dashboards using Power BI, reducing report generation time by 25% and improving data accessibility for cross-functional teams.
Generated over 50 ad hoc and scheduled reports using MS SQL Server Report Builder and deployed to the SQL Server Reporting Services (SSRS) environment for widespread sharing among team members.
Created UAT test plans outlining the scope, objectives, and resources required for testing.
Documented the pipeline enhancements and drafted reports to keep track of the deployments.",Team A&M University,,,,,,,,
18. Kyle Tonkovich ,English,,Business intelligence Manager,Biote,,University of cinncinati,B.S Engineering/Industrial Mgt,8 years and 11 months,All in US,Wellness and Fitness Services,,"Irving, texas",,https://www.linkedin.com/in/kyletonkovich/
,,,Sr. Business analyst,Biote,"➤ Led weekly stakeholder meetings (Marketing, IT, Analytics, Sales) to gather business requirements and translated into user stories, features, and epics via ADO (Azure Devops).
➤ Utilized Agile methodologies to manage the backlogs of international development teams in India and the Philippines.
➤ Conducted daily standup meetings to discuss and prioritize user stories.
➤ Performed UAT for PowerBI Reporting, Magento Online Stores and WordPress development items.
➤ Managed Production Support issues via Zendesk to meet project deadlines.",,,,,Wellness and Fitness Services,,,,
,,,Sr. Business analyst,"Freeport-McMoRan 
","➤ Triaged and migrated over 100 TB of data from 16 physical servers to cloud databases in SharePoint. ➤ Aided in the company's transition to agile methodologies and helped establish working groups (pods). ➤ Led daily stand ups calls to maintain user stories via ADO (Azure Devops), undercover roadblocks, and establish escalations. ➤ Documented migration process from start to finish with the use of Microsoft Visio and PowerPoint. ➤ Utilized DLP (Directory Lister Pro) and Treesize software to scan hard drives, obtain essential data, and construct migration goals. ➤ Developed proof of concept migration projects to review with product owners and provide statistical data that supported successful migrations.",,,,,Mining,,,,
,,,Business analyst,"RealPage, Inc.
","➤ Collaborated with global business leaders in India, Philippines, and United States to develop 19 capacity plans, forecast volume drivers, establish KPI’s, and reinforce workforce utilization. ➤ Documented user stories and tasks within JIRA. ➤ Created project workflows via Microsoft Visio and documented detailed BRD’s. ➤ Led product owner meetings to determine customer needs during mergers/migrations and collaborated with cross functional teams to drive business requirements. ➤ Utilized HRIS systems to create advanced reports that identified cost saving and process improvement opportunities. ➤ Built SQL Macro, reducing a process by 350–500 man hours per month. ➤ Prepared extensive cost-benefit analysis for submeter, allowing the hire of 8 new technicians. ➤ Leveraged strong analytical and research techniques to identify gaps and inconsistencies in current R.U.M. reporting tools.",,,,,Software Development,,,,
,,,Business analyst,7-Eleven ,"
➤ Utilized Agile Software Development / SDLC to plan the implementation of New Software to POS systems across stores in the United States.
➤ Led relocation of national Help Desk from India to United States.
➤ Managed software/hardware updates, downstream impacts, and end-user training.
➤ Developed process documentation and training guides.
➤ Provided Level 2 helpdesk triage support and worked advanced tickets.
➤ Programmed SQL Queries discovering billing errors that saved over $300,000 a year.
➤ Performed Root Cause Analysis for IT Operations and Procedures.",,,,,Retail,,,,
,,,Business analyst,Sabre Corporation,"
➤ Partnered with business leaders and system owners to translate business needs into system workflow requirements.
➤ Constructed business analytics reporting for application development and software.
➤ Implemented Agile Management software (Rally) to assess project impact, set and meet project deadlines and resolve business needs. 
➤ Managed BI software (Oracle) to develop and improve in-house IT program",,,,,IT Services and IT Consulting for travel,,,,
,,,Business analyst,"Vizient, Inc","➤ Executed data mining skills to create an analytical report that highlighted essential criteria for executive decision making for over 2,000 VHA affiliated hospital networks, reducing report development time from 8 hours to 30 minutes. ➤ Automated the entry process of custom hospital contracts via Excel/Access macros and queries, eliminating training needed and quicker access to contracts in the data base system. ➤ Established SQL Server and Oracle databases to create the New Member Savings Report. This report obtained an individual hospital yearly spend data ranging from $100,000 to $500,000,000, analyzed product quality levels, and listed the potential savings based on product spend categories, if the hospital were to join a V.H.A. network.",,,,,Hospitals and Health Care,,,,
,,,Supply Chain Analyst,"ARRIS

","➤ Managed weekly customer demand, ranging from roughly $10,000 to $10,000,000 for the Satellite CAT (Customer Account Team) using purchase orders (PO), invoicing, data transmission, and internal warehouse transfers. ➤ Maintained Satellite CAT product tracking file and SMI (Supplier Managed Inventory) to ensure optimal inventory levels were met and internal issues communicated to internal customers. ➤ Supervised and lead weekly meetings with the Sales Department to provide accurate product fulfillment across all customer bases and eliminate potential bottlenecks.",,,,,Telecommunications,,,,
,,,Project Planning Analyst,Toyota North America ,"➤ Constructed over 185 ECIs (Engineering Change Instruction) between Design engineers in Japan and the manufacturing facilities within the KPI (Key Performance Indicator) of 3 days. ➤ Assembled the Master Schedule for future vehicle projects, utilizing Microsoft Excel and formally meeting with multiple divisions within Toyota and external company suppliers. ➤ Maintained and provided pro-active insight for three project vehicle specification books and facilitated weekly meetings to present essential information to upper-level management. ➤ Traveled to Toronto, Canada to support Toyota’s first ever North American Global Assembly build.",,,,,Automobile,,,,
,,,Supply Chain Analyst,"
Meritor

","➤ Organized and managed shipment orders for various departments of Meritor, vendors, and possible buyers, including overseas foreign companies.
➤ Computed programs, macros, and queries to filter and produce large company vital data that accounted for over $75 million in inventory.
➤ Authored a Microsoft Access database that reported outstanding orders and parts due to lack of vendor fulfillment that resulted in saving countless hours of calculation and approximately $1.4 million.",,,,,Motor Vehicle Manufacturing,,,,
19. Avik Kohli,"English, hindi",,Business Intelligence Analyst 2,Mouser Electronics,Skills: Tableau · Alteryx · Google Analytics · Microsoft SQL Server · Google BigQuery · SQL,UTD,MSITM,8 years and 5 months,6 years and 6 months,Semiconductor Manufacturing,,"Mansfield, texas",Pune,https://www.linkedin.com/in/avik-kohli/
,,,Data Management Analyst,"U.S. Bank
","Data Management and Reporting. • Processed access management-related operations and other recurring data cleanup tasks using Oracle SQL Developer, Microsoft Excel, and Oracle Identity Management platform. • Created flat files using SQL and MS Excel to run a variety of access management requests to modify access for users, roles, and entitlements on Oracle Identity Management. Achieved a 98% SLA for all requests assigned to me during my time with the Bank.",,,,,US bank,,,,
,,,Consulting Data Analyst,"
Kforce Inc 
","• Performed data cleanup and report automation for the Identity Access and Management team using Oracle SQL Server and Oracle Identity Management platform. • Generated scheduled and ad hoc reports for stakeholders to monitor access management processes using SQL, GitLab, and Rundeck. Data Analytics Consultant at Kemper Insurance • Led data migration efforts after the acquisition of American Access Casualty Insurance company by Kemper Insurance. • Led the data mapping process to map Kemper’s data with that of American Access Casualty Insurance which enabled data migration. Consulting Data Analyst at USAA • Created the base transaction file for a 6-year compliance look-back. • Created Tableau dashboards to automate compliance reports. Used SAS and SQL queries. • Performed analytics on harvested USAA banking data hosted in Snowflake to facilitate the achievement of compliance goals",,,,,IT Services and IT Consulting,,,,
,,,"Business Analyst, Shipping and Delivery Support","Amazon 

","• Identified gaps in operations and created SQL generated reports to reduce incorrect call transfers to my stakeholder team by 85% which improved associate productivity. • Created metrics around operational processes using data to enable process optimization. • Generated advanced operational dashboards with quick filters, parameters and calculated fields using SQL and Tableau that were used by the senior leadership team in their daily and weekly business reviews. • Managed timely flow of business intelligence information to users by overseeing the complete ETL process in SQL. • Synthesized current business intelligence or trend data to support recommendations for action.",,,,,E-commerce and software development,,,,
20. Aswin Krishnamoorthy,"English, Kanada",yes,Business Analyst,AWS,"• Spearheaded cross-functional initiatives to enhance customer-centric products, leading from conception to execution. Defined comprehensive functional and technical requirements, orchestrated team efforts, and managed project lifecycles to deliver new features on schedule.
• Directed the implementation of three projects, grounded in meticulous cost/benefit analyses leveraging data-driven methodologies.
• Pioneered process enhancements within the AWS Billing Organization, strategizing and implementing solutions to streamline the pricing journey for over 200 AWS service teams, to improve process efficiency and reduce time for go-to-market 
• Engineered intricate pricing logic for AWS website pricing pages and calculators for 50+ AWS services leveraging advanced scripting techniques, empowering customers with insightful usage and cost estimates for cloud services' requirements",UTD,MSBA,6 years,4 years,Cloud,Automobile,"Dallas, Tx",Airoli,https://www.linkedin.com/in/aswin-krishnamoorthy-60452279/
,,,Product analyst,Copart,"• Managed a portfolio of 7+ products within the Car Auctions Platform across diverse regions including the US, UK, Canada, and EMEA. Responsibilities encompassed thorough analysis of user requirements, offering consultative solutions, facilitating decision-making processes, and delivering strategic recommendations to sales, marketing, operations, and senior stakeholders, including the CEO.
• Conducted comprehensive data analysis on product performance and consumer behavior utilizing various data analysis tools. Defined and developed key product metrics to gauge performance and inform strategic decision-making.
• Delivered data-driven insights and discoveries through impactful reports and dashboards crafted using Tableau and other advanced data visualization tools. Actively collaborated with stakeholders to define and steer product vision in alignment with overarching business objectives.
• Identified and strategized new opportunities, leveraging analytics on performance data to drive innovation. Spearheaded the implementation of new initiatives aimed at boosting sales and expanding the user base.",,,,,,,,,
,,,Product analyst intern,Copart,"• Orchestrated the complete product lifecycle of Online Auction system applications, overseeing product evolution and spearheading process optimization initiatives. Led the successful decoupling of legacy systems, resulting in a considerable increase in operational efficiency.
• Leveraged Adobe Analytics and Tableau to extract actionable insights from web conversion data, user feedback, and user experience metrics. Presented key findings to stakeholders, guiding product vision alignment with business objectives.
• Strategically prioritized roadmaps, developed implementation plans, and established and monitored KPIs and OKRs. Conducted experimental designs, A/B tests, and UI/UX optimizations in collaboration with diverse cross-functional teams.
• Utilized predictive analytics and machine learning algorithms to support top insurance companies in making informed business decisions, reinforcing the application's efficacy and relevance.",,,,,,,,,
21. Raga Rasagna,"English, Tamil",Yes,Business Analyst,Solventum,"- Facilitating data migration from legacy systems to Global PLM system, improving data integrity by 85%.
- Gathering requirements from stakeholders, ensuring a 100% alignment with project goals and objectives.
- Designing and implementing data cleansing, conversion, and mapping strategies, achieving >95% accuracy.
- Reviewing the structure and operation of source and target data systems, resulting in a 20% reduction in data migration errors.",UTD,MS ITM,5 years,2 years,health,Technology,DFW,Hyderabad,https://www.linkedin.com/in/raga-rasagna/
,,,PLM Data Engineer,TEK Ninjas,"- Responsible for developing ETL scripts to extract data from legacy systems for a medical technology company.
- Transformed the data into the required format as defined by the business teams.
- Validated the data templates for accuracy by comparing them with source systems.
- Facilitated data cleansing, enrichment and data quality improvements.
- Coordinated with the technical team to load the data into the Windchill PLM System.
- Assisted the business in UAT and reported any discrepancies in data after thorough validation.",,,,,,,,,
,,,Business data analyst,Quarterhill Inc.,"- Subsidiary: Electronic Transaction Consultants (ETC)
- Collaborated with internal and external stakeholders to enhance Colorado's Tolling System Traffic Data.
- Led a team of 4 in requirements gathering and design sessions, aligning with stakeholders' unique needs and objectives according to the Requirements Specifications.
- Created comprehensive Business Requirements Documents (BRDs) and Project Plans, outlining project objectives, problem statements, scope, risks, assumptions, workflow, QA, and Functional Specifications.
- Extracted live data of 30M+ records from Big Query, showing proficiency in handling large datasets.
- Designed and developed Summary Dashboards, Detailed Views, and Focus View reports in Looker to gain real-time insights into traffic data.
- Offered revenue improvement recommendations and facilitated actionable decision-making by 60%.",,,,,,,,,
,,,VP Consulting & Operations,TechPact,"- Acted as a key liaison between the President and external stakeholders, ensuring seamless planning and execution of events.
- Cultivated strong relationships with clients, effectively securing future projects for club members and maintaining professionalism in all interactions.
- Offered consulting services to local businesses, providing innovative solutions to address their unique challenges and drive growth.
- Demonstrated proficiency in business development, leveraging analytical skills to identify opportunities and build lasting client relationships, resulting in a 95% client satisfaction rate.
- Took charge of internal operations, overseeing marketing, publicity efforts, and spearheading recruitment initiatives to attract new members.",,,,,,,,,
22. Saumil Khadilkar,English,,Business Analyst,Capital One,"Fortune 100 financial institution specializing in credit cards, auto financing, consumer banking, and commercial banking

+ Leveraged valuations models to recommend credit policy and pricing changes to Pre-Approval’s $600M credit portfolio
+ Analyzed loss performance across 150+ credit segments and presented findings and risk mitigation plans to senior leaders
+ Collaborated with cross-functional stakeholders to launch two marketing partnerships, totaling $5.8M in annual profit
+ Performed credit sizing of a new SEM optimization framework, driving $7.0M in incremental originations and 1.5K leads",UT Austin,BBA Management Information Systems,5 years,all in us,Finance,Sports,"Dallas, Tx",,https://www.linkedin.com/in/saumil-khadilkar/
,,,Business Analyst Intern,Capital One,"Performed SQL analysis of auto refinance marketing strategies and identified $320K revenue difference between strategies
+ Evaluated marketing funnel metrics for 60+ million leads to contextualize current strategy and simulate proposed scenario
+ Analyzed Auto Navigator solicitation eligibility of 379K leads by reviewing distribution of risk and response scores in MS Excel",,,,,,,,,
,,,Business Analyst Intern,Cerebro Sports,".Identified strategy of increasing outreach to grassroots athletes and parents to increase subscriber lifetime value by $350+
+ Created entity-relationship diagram for SQL database of ten entities and proposed 15+ changes to ensure normalization
+ Facilitated $15,000 in sales by building a database of video coordinator contacts for 340+ NCAA Division I basketball programs",,,,,,,,,
23. Sandeep D Arasappa,"English, Tamil",Yes,Senior Business Analyst,Cisco,"• Collaborated with Enablement Leads to identify important KPIs for their respective verticals.
• Modified existing Dashboards, thereby increasing their usage by 20%.
• Worked with the data engineering team to consolidate metrics in one platform by building a proof-of-concept
Dashboard on ThoughtSpot, a self-service Dashboarding tool.",UTD,MSBA,7 years,3 years,technology,Consulting,"Dallas, Tx",Bengaluru,https://www.linkedin.com/in/sandeep-d-arasappa/
,,,Finance & Data Analytics Intern,The University of Texas Systems,"• Built multiple dashboards in Power BI and Tableau to identify trends in $1.8 Billion payments, top 10 vendors, the total number of payments made, and their payment methods, and derived yearly, quarterly, and monthly payment trends.
• Spearheaded conversations with SMEs to collect, clean, and compile six years’ data to create a dashboard to keep track of inventory worth $536M and 2705 assets. 
• Generated operational metrics to show the performance of FTEs in the Financial Shared Services department. This helped disprove the hypothesis that workload is proportional to the workforce, suggesting an increased FTE count.
• Developed Dashboards for the Accounts Receivable team to show the reconciliation of $28M worth of payments and the distribution of said payments within the departments in the organization.
• Utilized Advanced Excel and R to collect and clean operational metrics data for six fiscal years, driving data-driven decision-making processes.
• Designed and constructed six interactive dashboards with Power BI and Tableau to visualize and identify trends and gaps in operations, providing actionable insights.
• Presented operational metrics insights to vice-chancellors and directors, initiating regular operational metrics tracking and promoting transparency and accountability.
• Spearheaded digital transformation efforts by implementing Robotic Process Automation, reducing human effort and FTE requirements while providing an alternative to hiring more staff.
• Leveraged operational metrics insights to help executives understand the employees’ workload in the Financial Shared Services and Contracts and Procurement Department, contributing to optimizing business processes, improving overall operational efficiency, and ultimately hiring 2 FTEs, 1 for each department, and investing in RPA. All these efforts to manage the workload while optimizing costs to keep the operations running and well managed.",,,,,,,,,
,,,Associate Consultant,Consulting Leadership & Development Society,"• Conducted an impact study on existing verticals and identified overlap on horizontal demand for an on-demand labor marketplace provider.
• Analyzed the unique needs of each vertical and provided a competitor analysis.",,,,,,,,,
24. Parsa Nejad,English,,Business Analyst,Hewlett Packard Enterprise,"Conducts and summarizes complex data and business analyses to develop business plans, including revenue and demand projections, workforce optimization, and channel management.
Constructs statistical and financial models with minimal direction to forecast business performance.
Defines the metrics required to measure business performance, and compares actual data to forecasted values.
Executes market research projects, gathers intelligence on current industry, technology, and consumer trends, and summarizes research findings tailored to business needs.
Works with cross-functional teams to facilitate the data collection and performance measurement process, and escalates issues as necessary. Makes contributions to research and analyses on priority projects within established guidelines.",UTD,BS IT,5 years,all in us,computer & IT,Pathology,"Plano, Tx",,https://www.linkedin.com/in/parsa-nejad/
,,,Digital Account Manager,Hewlett Packard Enterprise,"•Translates customers' business challenges and goals into IT opportunities. 
•Builds and executes a plan to drive growth, profitability across HPE's portfolio, in a structured and recurring way
•Develops and updates expertise in IT technology. Engages as appropriate with the company’s CEO CTO/CIO
•Builds influential relationships with executives. Defines an effective engagement model with the customer's key influencers and decision-makers.
•Selling HPE products, services, software, or solutions to customers, both directly and indirectly
•Effectively manage the Customer-Reseller-HPE alignment to drive and accelerate sales opportunities to closure
•Develop and nurture a strategic and mutually beneficial relationship with the channel community (i.e., Distributors, Value Add Resellers (VARs), Alliances, etc.)
•Understand client requirements and competitively position HPE solutions to meet customer needs",,,,,,,,,
,,,Finance operation intern,Verizon,"Navigate billing system to understand Indirect Agent billing cycles, invoices, returns and credit processes
Query Data in SQL Server Database Validate, Cleanse, Prepare Data, Create ETLs Create Reports and Dashboards in Power BI or alternative visualization tool. 
Develop and deliver a working set of dashboards to align solving the Top 5 issue and have built out the framework",,,,,,,,,
25. Srinivas Simadri,"English, Tamil",Yes,Business analyst,Cisco,"• Conducted detail analysis on financial and business data related to Annual Recurring Revenue (ARR) with a focus on upsell, cross sell and customer attrition. Collaborated closely with IT subject-matter experts on data warehouse and application design. 
• Developed SQL queries in GCP BigQuery and SAP BO queries to extract relevant data, and subsequently performed detailed analysis on the extracted data to gain insights and inform decision-making processes. 
• Worked with various BI tools, including SAP BO, Tableau, MicroStrategy, and MS Excel for financial data reporting. 
• Served as a Subject Matter Expertise, providing insights into business and technical processes. 
• Collaborated with business teams to identify key requirements and developed analytics and reporting solutions to meet evolving needs. 
• Developed and analyzed pivot tables and utilized VLOOKUP functions to conduct comprehensive customer transaction analysis, identifying root causes for any issues and driving data-informed solutions resulting in a 70% reduction in issues. 
• Prepared weekly, monthly, quarterly, annual financial reports by using MS Excel and Tableau for management and external stakeholders, ensuring adherence to reporting standards and accuracy of financial information of ARR/AOV. 
• Monitored and tracked revenue and booking trends, identifying areas for improvement and providing recommendations for financial performance. 
• Led the QA effort from a functional perspective and supported Business Testing.",University of North Texas,MSBA,3 years,1 year,Technology,Software,"Little Elm, Tx",Guntur,https://www.linkedin.com/in/simadri/
,,,Business analyst,Wipro,"• Collaborated with key business partners to understand priorities, identify strategic initiatives, and develop effective analytic solutions.
• Worked on Designing and Development of data extracts using SQL scripts.
• Created views in Tableau Desktop that were published to the internal team for review and further data analysis and customization using filters and actions. Advised the Business team on data-focused business improvement measures for customers, resulting in enhanced customer satisfaction.
• Designed Ad-Hoc reports based on requirements of Client and Business team.
• Conducted in-depth research on sales trends and gained deep knowledge of material handling operations within the dealer network and customer base. Utilized user, product, and market data for statistical analysis supporting customer segmentation, competitor analysis, and behavioral models.
• Monitored the JIRA Server for case tracking for end user support.",,,,,,,,,
26. Yash Gujre,"English, marathi, Hindi",Yes,Business analyst,Galderma,"• Led end-to-end design and development of dashboards to implement supply chain visibility, empowering data-driven decision-making for business
owners and executives, reducing backlogs by 10%.
• Implemented process automation systems integrating data from disparate sources, enhancing operational visibility, and optimizing workload by
25-75%.
• Architected robust data models (schemas) underpinning critical US supply chain operations dashboards. This implementation led to a 30% increase 
in data accessibility and a 25% improvement in operational competence, enabling data-driven insights and streamlined operations.",UTD,MS ITM,4 years,1 year 5 months,Pharmaceutical ,IT Consulting,"Dallas, Tx",Mumbai,https://www.linkedin.com/in/yashgujre7/
,,,Business analyst,ProductBuild Consultancy,"• Utilized project management tools such as Jira for efficient task tracking and agile methodologies for iterative development.
• Authored clear and concise documentation, including user stories, use cases, and process flows, resulting in a 30% reduction in misunderstandings 
and a 20% increase in project efficiency.
• Utilized MS Visio to create detailed process flow diagrams, system architecture diagrams, and workflow visualizations, improving team 
understanding by 25% and reducing development time by 15%.
• Collaborated with testing teams to develop test cases and scenarios, ensuring thorough testing of applications and achieving a 95% test coverage 
rate.
• Facilitated effective communication between business users, technical teams, and stakeholders, resulting in a 40% decrease in project delays and a 
25% increase in stakeholder satisfaction.• Utilized project management tools such as Jira for efficient task tracking and agile methodologies for iterative development.
• Authored clear and concise documentation, including user stories, use cases, and process flows, resulting in a 30% reduction in misunderstandings 
and a 20% increase in project efficiency.
• Utilized MS Visio to create detailed process flow diagrams, system architecture diagrams, and workflow visualizations, improving team 
understanding by 25% and reducing development time by 15%.
• Collaborated with testing teams to develop test cases and scenarios, ensuring thorough testing of applications and achieving a 95% test coverage 
rate.
• Facilitated effective communication between business users, technical teams, and stakeholders, resulting in a 40% decrease in project delays and a 
25% increase in stakeholder satisfaction.",,,,,,,,,
,,,Business analyst,WebCraft IT,"• Led end-to-end design and implementation of comprehensive onboarding systems at a business consulting firm, focusing on product development
to create a positive and engaging client-first experience.
• Systematically gathered and documented business Requirements Documents (BRD) and Functional Requirements Documents (FRD), employing a 
blend of formal and informal sessions. Achieved a 20% improvement in project requirement accuracy, validated by business stakeholders.
• Prioritized features with a cost-conscious approach, utilizing brainstorming, scoring, and scaling technical features. Documented priorities in Jira
and cooperated with engineering/design, resulting in a 50% reduction in operating budget.
• Work together with testers, planned tests/data, and crafted test cases in Jira, resolving bugs to achieve an impressive 98% usability success rate.
• Compiled market research and feature findings into clear Excel reports, facilitating stakeholder communication and decision-making, resulting in a 
20% increase in stakeholder satisfaction and a 15% reduction in decision-making time",,,,,,,,,
27. Anushka Srivastav,"English, Marathi, Hindi",Yes,Business Analyst,Syneos Health,"Worked with Agile methodologies and streamlined workflows, boosting team productivity by 28%.
• Collaborated with cross-functional teams to gather and document requirements, including Functional Requirement
Documents (FRD), Business Requirement Documents (BRD), and System Requirement Specifications (SRS).
• Managed and tracked project progress using project management and reporting tools, including MS Project, MS Excel,
MS Access, MS SharePoint, and Tableau.
• Conducted in-depth interviews and stakeholder workshops to elicit and document business requirements.
• Played a key role in process improvement initiatives, applying Six Sigma methodologies to reduce defects by 15% in a
critical workflow.
• Coordinated user acceptance testing (UAT) and facilitated Joint Application Design (JAD) sessions, streamlining
communication, and ensuring project alignment.",UT Arlington,MS CS,4 years,1 years,Health,Software,"Dallas, Tx",Mumbai,https://www.linkedin.com/in/anushka-srivastav/
,,,Data Analyst,Cybcage Software,"Improved process compliance and consistency, resulting in a 25% reduction in errors and rework.
• Led the implementation of Agile and Waterfall methodologies, ensuring project deliverables met business objectives
and were delivered on time and within budget.
• Managed UAT efforts and achieved a 95% satisfaction rate among end-users.
• Conducted comprehensive system and user acceptance testing, ensuring software met quality standards and user
expectations.
• Facilitated JAD sessions with cross-functional teams, resulting in a 20% reduction in project delivery time and enhanced
stakeholder satisfaction, and maintained database stored procedures and SQL queries.
• Enhanced stakeholder communication and engagement, leading to a 15% reduction in project misunderstandings, and
scope changes, and ensured on-time project delivery, resulting in a 15% increase in client satisfaction.
• Utilized various analysistechniques,such as cost/benefit analysis, impact analysis,GAP analysis,risk analysis, and SWOT
analysis, to evaluate project feasibility and identify opportunities for improvement.",,,,,,,,,
28. Vishal kumar Prajapati,"English, Hindi",,Sr. Business analyst,Cognizant ,".• Led and contributed to a cross-functional team to deliver a multi-million dollar control automation dashboard project for a leading financial services company
• Collaborated with senior leaders from top financial services to strategically automate compliance reporting, identified deficiencies, and provided strategic solutions for 100% compliance audit
• Created and maintained product backlog, process flows, use cases, and BRDs for 4 teams under the Agile framework, ensuring comprehensive alignment between the DB team and Business team
• Led grooming meetings, requirement walkthroughs, planning sessions, retrospectives, and demos for each sprint, fostering over 99% efficiency in the workplace
• Conducted user acceptance testing, data analysis, and data validation to pinpoint defects, and offered recommendations for resolution
• Researched and assembled a user-friendly commercial lending handbook to train the new hires with lending processes and industry practices while reducing 25% of training costs for the company",UT Arlington,,3 years,all in us,Technology,,"Dallas, Tx",,https://www.linkedin.com/in/vishalkumar-prajapati/
29. Chisom Anyaegbuna,English,,Business analyst,Twitter,"In-depth knowledge of CMDB discoveries by identifying hardware and software IT infrastructure. In-depth knowledge of service mapping and how it’s used to track applications, Responsible for the accuracy and the currency of the assets and attributes throughout their lifecycle, Making sure data is up to date my updating the primary System Owner and Business Process Owner when someone leaves the company , all being done in ServiceNow . Ability to build a job guide , Working closely with other process leads to ensure that asset- specific information can be gathered using an efficient process . Work closely with stakeholders to understand business requirements and needs related to servicenow CMDB",Nnamdi Azikiwe University,BS Pyschology,8 years,all in us,Social Media,Finance,"Garland, Tx",,https://www.linkedin.com/in/chisom-anyaegbuna-csm-pmp-2565a1186/
,,,ServiceNow BA,Wells Fargo,"Work Closely with Product Owner/Stakeholder to understand business requirements and needs related to ServiceNow ITSM.
Managed projects and served as primary liaison between client and multiple internal groups to clarify goals and meet standards and deadlines.
Work Closely with Product Owner/Architect to decompose Features into stories that can be accomplished in each Sprint.
Oversee the Product/Technical Backlog by creating Stories/Spikes/Defect for all Sprints.
Great experience in facilitating sprint ceremonies like Sprint Planning, Daily standup, Sprint Review, and interactive Sprint Retrospectives",,,,,,,,,
,,,Sr. Business analyst,Medecision,"Act as the face of the ServiceNow delivery team and drafted / implemented the intake process for new enhancements. 
Determine and define business needs and global requirements to develop and continue the growth of a multi-instance ServiceNow environment with CMDB, Change, Incident, Problem, Knowledge, SDLC, Reporting, Requests, Visual Task Boards, and Service Catalog
Work with ServiceNow developers, admins, and business leadership to deliver workflows and renewed processes.
Drive the requirements gathering efforts (either development or implementation), including managing the expectations of the Process Owner, the stakeholders, the development team, and executive management
Operates as a liaison between technical personnel and the ITSM process owners such as Change manager
Supports team information sharing and on-boarding of colleagues as the team grows
Led scrum meetings such as daily stand up, Sprint planning, Sprint reviews, and retrospectives, 
Coordinated training and led training sessions for the organization and partners.",,,,,,,,,
30. Rachit Arora,"English, Hindi",Yes,Business analyst,Cognizant ,"Develop a project roadmap for integrating Gen AI into the BCBC claims processing chat system, which
communicates through Blues Internal Tool deployed on Amazon Connect.
•Identify the data sources, response times, and query frequencies for multiple claims, and prepare input data
for the Large Language Model (LLM).
•Enhanced the organization's analytical capabilities, resulting in tangible outcomes and enabling more
informed decision-making, which positioned the company for sustained growth and a competitive edge.
•Applied automated data extraction procedures utilizing Python, VBA Macros, and SQL, leading to a 50%
decrease in scraping time. This improvement boosted operational efficiency and sped up data retrieval
processes.",UTD,MSBA,6 years,5 years,Technology,Insurance,"Dallas, tx",Jabalpur,https://www.linkedin.com/in/arora-rachit/
,,,Business analyst,AXA XL,"•Created strategic workshops using tools like Jira, Confluence, and other business analyst technologies to enhance security protocols across AXA XL subsidiaries, fostering proactive risk management and compliance.
•Identified and mitigated security risks through comprehensive analysis, leveraging data-driven insights and project management techniques to optimize security remediation strategies while minimizing costs.
•Developed detailed project timelines using project management tools to streamline remedial processes,
proactively identifying and addressing potential obstacles to ensure timely completion.
•Orchestrated data migration initiatives, utilizing advanced data management tools and techniques to facilitate seamless transfers between systems, uphold data integrity, and comply with stringent industry regulations.",,,,,,,,,
,,,Business analyst,Toyota Motor coproration,"•Collaborated closely with cross-functional teams to facilitate the efficient deployment of RPA solutions,
ensuring alignment with organizational objectives and requirements.
•Developed comprehensive process flow diagrams, elucidated business rules, and formulated guidelines for handling exceptions within RPA bots, enhancing operational efficiency and minimizing errors.
•Provided post-implementation support and conducted ongoing monitoring of RPA processes, proactively identifying areas for enhancement and optimization.
•Managed A/B testing initiatives to evaluate the efficacy of personalized recommendations on user engagement and sales, leveraging advanced tools such as Google Analytics and Optimizely to derive actionable insights.",,,,,,,,,
,,,Business Intelligence analyst,JPMorgan Chase & Co,"•Proficiently extracted, blended, and analyzed data from diverse sources including SharePoint, Excel, and SQL databases using Tableau Desktop.
•Developed interactive dashboards and comprehensive data narratives tailored for confidential banking and finance data, ensuring effective communication of insights to business leaders.
•Deployed and maintained Tableau Dashboards on servers to facilitate real-time monitoring of loan systems across global regions such as EMEA and APAC, adhering rigorously to security standards.
•Established and managed connections with multiple data sources for both live and extract data extraction, optimizing data integration processes to meet business requirements effectively",,,,,,,,,
,,,Business analyst ,Genpact,"•Developed and implemented robust KPIs and metrics, driving a notable 20% increase in operational efficiency, fostering a data-driven organizational culture.
•worked with cross-functional project teams adeptly utilizing Jira and Confluence, ensuring timely and budget friendly project completion, consistently exceeding stakeholder expectations.
•Employed advanced data analysis and visualization tools, including Tableau, Power BI, and Excel, to dissect complex datasets and deliver actionable insights to senior management and stakeholders.
•Presented concise and insightful reports on project progress, challenges, and solutions to senior leadership , facilitating informed decision-making and alignment across departments.
•Proactively identified opportunities for process improvement, leveraging expertise in Microsoft Excel to
streamline workflows and enhance project management effectiveness.",,,,,,,,,
31. Dave Shivhare,"English, Hindi",Yes,Business Analyst,Aisera,"• Facilitated Agile ceremonies, including sprint planning, daily stand-ups, and retrospectives, to 
 ensure effective project execution.
• Designed and implemented tailored software solutions using tools like Microsoft SharePoint and 
 VBA scripting for Microsoft Office applications.
• Conducted Gap Analysis on existing processes to identify and address discrepancies, ensuring 
 alignment with business goals.
• Led functional testing and reported defects and enhancement suggestions through Jira, 
 coordinating with developers for resolution.
• Built and maintained Tableau dashboards and reports, offering stakeholders real-time insights into 
 key performance metrics.
• Gathered requirements through integrated JAD sessions, workshops, and several brainstorming 
 sessions with SMEs.
• Involved in creating and maintaining the Requirements Traceability Matrix (RTM).
• Produced clear documentation for requirements management plans, Functional Requirements, 
 supplemental Requirements, Test Plans, and Test Cases.",UTD,MSBA,4 years,9 months,Software,Software,"Dallas, Tx",Chennai,https://www.linkedin.com/in/daveshivhare/
,,,Business analyst,Hexaware Technologies,"• Employed Waterfall and SDLC methodologies for project execution, incorporating Storyboards as a 
 technique for requirements gathering.
• Created BRD and Requirements Traceability Matrix to communicate the needs of the solution to 
 internal and external users.
• Specialized in Business Requirements Elicitation, Process Modeling, Risk analysis, SWOT analysis, 
 and drafting Functional Specifications.
• Produced and maintained key project documentation, including business requirements, design 
 documents, and executive presentations.
• Effectively managed stakeholder expectations to ensure project alignment, leading to a 20% 
 reduction in scope creep.
• Developed Excel and Power BI reporting solutions that extracted data from SQL databases using 
 complex queries.
• Created Technical/Functional Requirement Documents to guide the design team in building 
 applications based on User Stories.
• Handled documentation necessary for implementing changes according to functional departmental 
 requirements, including User Acceptance Testing (UAT).
• Refined and input business requirements in the HP Quality Center for traceability to test 
 requirements.",,,,,,,,,
32. Tharun Kishor A R,"English, Tamil",Yes,Business analyst,AmerisourceBergen,"Skilled in leveraging data for strategic decision-making, I've developed comprehensive dashboards, analyzed sales trends to identify growth opportunities, and implemented tools to increase customer acquisition. I've driven operational efficiency by designing customizable reports, projecting administrative fees, and optimizing product performance. I focus on improving processes, mitigating errors, and delivering actionable insights from data.",UTD ,MSBA,4 year,3 year,Retail,software,"Dallas, Tx",Chennai,https://www.linkedin.com/in/artk19/
33. Omer Shakeel,"English, Tamil",Yes,Business analyst,"Amazon 

","- Designed data solutions by gathering data from multiple internal and external data sources using Amazon Enterprise Big Data Platforms like Cradle (for Batch Processing & Serverless), Spark SQL, S3 (Storage), AWS Glue (ETL), Redshift, AWS Quicksight and building end to end ETL pipelines using Advance SQL
- Develop data tables by sourcing data from internal and external datasets, APIs ,JSON and Excel uploads, automating the data pipelines and maintaining metadata by implementing data governance methodologies
- Lead end to end projects to track fulfillment center operations and performance of 20+ newly launched sites which measured Quality, Cost, Workforce Planning and Operations of the sites and displaying these metrics on Tableau, PowerBI and Quicksight dashboards.
- Collaborated cross functionally with TPMs and site leaders and generate reports with over 120+ KPIs and metrics to present to senior leadership for WBR(weekly business reports) and making data driven recommendations for strategic decision making
- Work as a liaison between the non tech teams and data engineering teams 
- Created ETL health monitor dashboards for monitoring ETL pipelines to proactively prevent data procurement delay and resolve data quality issues within the agreed upon SLA",UT Arlington,MS Engineering,5 year,4 years,E commerce,Education,"Dallas, Tx",Hyderabad,https://www.linkedin.com/in/omer-shakeel9/
34. Mayank Kumar,"English, Hindi",Yes,Business analyst,Cognizant ,"Google (Client), PEGA Business Analyst Aug 2022- Present
• Designed & implemented the Self-Service application in PEGA by creating user stories in TaskFlow, depicting E2E flow
using Lucid charts, building data models and organizing the entire work-flow into intake, solution & release cases
• Overhauled the existing GND application for Google by organizing the backlog and the Goals section of TaskFlow,
creating Epics, Features, Milestones and User Stories to implement new functionalities
• Created Release notes, organized Demo and Triage sessions with Google client to get LGTM once user stories are completed,
work on exceptions and shared Demo ppt/recordings with client for reference
Anthem (Client), PEGA Business Analyst Aug 2020- July 2022
• Worked with a leading healthcare firm to design and implement the new ticket management system in PEGA platform
• Engaged with the client stakeholders and managed the product scoping, requirements gathering and finalization discussions
with healthcare client to effectively manage scope of the product for release in an agile environment
• Updated Business Processes and SOPs and created URS, FRS, Use Cases using JIRA and Confluence for healthcare client
• Performed UAT, SIT Testing of JIRA stories and created CR’s/ Enhancements/Defects, reducing sprint timeline by 10%
• Researched and updated the missing bibliographies/articles using Article Galaxy in the EndNote & Zotero tool for the client",UTD ,MSBA,13 year,4 year,technology,Electricity,"Dallas, Tx",Odisha,https://www.linkedin.com/in/mayank-kumar-utd/
,,,"Sr. Product Manager, Operations & Strategy",BHEL ,"Coordinated comprehensive operations of a state-of-the-art steam turbine/gas turbine generator manufacturing facility, ensuring production efficiency while promoting 24/7 operation and consistent record production. Conducted root cause analysis, identifying issues with production and implementing innovative solutions to optimize productivity and motivate employees. Spearheaded evaluation of vendor application and performance, as well as review of SAP material master data and vendor development programs through quarterly intra-departmental meetings 

 • Led a cross-functional team of 10 members to ensure compliance to new government tax structure, including identification of 300 pending receipts and communication with 200 vendors, resulting in collection of $10 mn invoice 
 • Analyzed inventory turnaround cycle by inhouse lab testing to revalidate expired parts, obtained product certification and standardized inventory flow, which yielded $4 million in cost savings
 • Developed a new purchase order closeout process including reconciliation of material receipts, 
 billings, changes, and payments by analyzing slow moving purchase orders, resulting in 10% decrease in purchase order backlogs
 • Implemented a sustainable subcontract model and utilized unused inventory in workplace to reduce cycle time of procurement by 40% and increased profits to $400,000 within 2 years, a rise of 15% YOY profit growth from 2016",,,,,,,,,
,,,Sr. Engineer,BHEL ,"Partnered with procurement team throughout evaluation and award of 600 MW scale sub-contract orders, developing templates for techno- commercial evaluations leading to a significant reduction in offer evaluation time. Oversaw in-house and contractor production, conducting third-party inspections that enabled efficient delivery of quality products within stringent contractual commitments. 
 
 • Identified cost reduction opportunities by validating, analyzing and making sourcing recommendations based on quote packages from suppliers, implementing ad hoc pricing negotiations and leading to reduction in negotiation time by 7%
 • Developed and implemented a business model which eliminated redundant processes, optimized resources, nullified competitor advantage, increased profitability and led to over $50 million in new business over the next 5 years
 • Designed and managed development of an online tracking tool to monitor project timeline and critical issues. Enabled automation of project reports, translating to $4.5M annual savings on manpower and delivery costs. 
 • Developed KPIs for chosen suppliers and negotiated on multiple variables to award longer-term strategic contracts to suppliers, resulting in cost reduction by 6% and improvement in service levels by 3%
 • Mapped purchase portfolio against risk &profit, developed vendor segmentation, efficiently managed supplier base",,,,,,,,,
,,,Business Analyst,Jindal Steel & Power LTD,"Led the testing and analytics team to highlight exceptions and formulate growth driven strategies
• Formulated SQL queries for real time application monitoring tool to improve Jindal’s market research and reduced reporting latency by 30%
• Migrated excel-based weekly job run and process checks reports to interactive Tableau dashboards and KPI’s to cut down the dependency on manual reporting by 15%",,,,,,,,,
35. Sindhuri Chantigari,"English, Hindi",Yes,Business Analyst,Mckesson,"• Developed Python scripts for SQL Server databases, enabling data manipulation and extraction.
• Collaborated on data-driven solutions, improving business processes.
• Used SQL for ETL processes from diverse sources like Access and Excel via SSIS.
• Translated end-user requirements into technical specs, reducing dev time by 30%.
• Acted as liaison between business and tech teams, conducting data analysis.
• Utilized MySQL for complex analysis, enhancing customer retention by 15%.
• Created dynamic dashboards with Excel and Power BI for actionable insights.
• Led development of a data-driven analytics platform.
• Created UML diagrams for clear communication, reducing errors by 20%.
• Contributed to risk analysis and comprehensive documentation.
• Conducted gap analysis, reducing errors by 25%.
• Collaborated with cross-functional teams, proposing process improvements.
• Conducted UAT sessions to refine software functionalities.
• Used Microsoft Visio for project diagrams and flowcharts.",University of Central Missouri,MS Big Data Analytics & IT,3 years,1 year 6 months,Health,Consulting,"The Colony, Tx",,https://www.linkedin.com/in/sindhurireddyc/
,,,Business Analyst Intern,McKinsey & Company,"• Conducted SWOT analyses for internal strengths and weaknesses, and external opportunities and threats, informing strategic planning.
• Collaborated on Impact Analysis for business process changes, assessing risks and consequences.
• Supported change management initiatives, analyzing impacts on workflow and implementing new processes and technologies.
• Utilized advanced Excel functions for data analysis and report creation.
• Managed relational databases with MySQL, employing robust data modeling techniques.
• Ensured meticulous documentation and communication of BRDs and FRDs for cross-functional teams.
• Conducted various analyses including GAP, risk, cost/benefit, and SWOT analysis for decision-making.
• Assisted in ROI analysis for proposed projects.
• Utilized Tableau for developing interactive data visualizations and dashboards.
• Applied Waterfall model for project management.
• Employed Jira and HP Quality Center for project tracking and meeting deadlines.",,,,,,,,,
,,,Business Analyst,Adani Group,"•Collaborated in the development of (BRD) and (FRD) to ensure precise documentation of project objectives, scope, and functional specifications.
• Conducted User Acceptance Testing (UAT) with the QA team, leading to the creation of test plans, test cases, and test scripts meticulously aligned with business requirements and functional specifications.
•Applied business expertise in change management, risk analysis, SWOT analysis, Gap analysis, and impact analysis, resulting in a 25% reduction in project risks and increased stakeholder satisfaction.
•Developed and implemented statistical models in SAS to forecast key business metrics, enabling more precise resource allocation.
•Leveraged Excel's powerful data analysis tools, such as regression analysis and scenario modeling, to provide accurate forecasts and insights into business performance trends.
•Developed and implemented statistical models in SAS to forecast key business metrics, enabling more precise resource allocation and improvement in resource utilization.
•Demonstrated proficiency in root cause analysis, identifying underlying factors in complex issues and implementing solutions that boosted operational efficiency by 20%.
• Utilized Tableau's capabilities to extract actionable insights and bolster business analyses, enhancing the decision-making process.
•Utilized MS SharePoint for project documentation and communication, facilitating seamless information sharing among teams.
•Conducted gap analyses to identify system changes, leading to a 30% reduction in project development time. Developed project documentation, design specifications, and test plans.
• Designed process maps, facilitating discussions and interviews with business partners, service teams, and project teams supporting data across digital properties enterprise-wide.
•Spearheaded agile project management using Jira, ensuring the punctual delivery of critical features and enhancements.",,,,,,,,,
36. Tapan Dhakan,"English, Hindi",Yes,Business Analyst,Cardinal Health,"• Utilized Agile/Scrum methodologies to successfully manage projects, ensuring on-time delivery and meeting stakeholder expectations.
• Conduct thorough analyses, including cost/benefit, GAP, and SWOT analysis, to provide insights that drive strategic decision- making.
• Manage projects using MS Project and Jira, resulting in a 10% increase in project completion ahead of schedule and optimal resource utilization.
• Used Google Analytics, Stata, and Adobe Analytics to analyze web and business data, deriving insights for optimization.
• Created process flow diagrams and visual representations to streamline communication and understanding of business processes, leading to an approximately 30% decrease in errors.
• Establish clear and concise wireframes, UI mock-up screens, and prototypes to enhance user experience and stakeholder communication.
• Employ advanced functions in MS Excel, including Pivot Tables, VBA’s, H & V-LOOKUPs, for data analysis and efficient reporting.
• Effectively elicited product requirements through one-on-one interviews and facilitated Joint Application Design (JAD) sessions for stakeholder panels, ensuring comprehensive and well-defined product vision",UTD,MS Management Science,3 years,1 yesr,Health,Software,"Dallas, Tx",Rajkot,https://www.linkedin.com/in/tapan-dhakan/
,,,Business Analyst,BrainByte Infotech,"• Managed sprint planning meetings, retrospectives, and daily stand-ups, ensuring clear communication and alignment among team members; increased team productivity by 25%.
• Crafted detailed user stories encompassing key elements such as business value, scope of change, and acceptance criteria, fostering clear communication between stakeholders and development teams and ensuring the successful alignment of project deliverables with business objectives.
• Created ad-hoc reports using MS Excel and Pivot tables to do the calculations created reports accordingly and created and modified SQL queries to match the requirements.
• Improved project team collaboration by 20%, implementing a standardized workflow and issue-tracking system in MS Project and JIRA.
• Developed dashboards to monitor team velocity, backlog health, and sprint progress, enhancing data-driven decision-making and reducing project cycle time.
• Streamlined user story management by leveraging Git labels and milestones to categorize and track user stories throughout the development lifecycle.",,,,,,,,,
37. Adi reddy,"English, Tamil",Yes,Business Analyst,Cisco,"• Collaborated with diverse teams, extracting business needs, and transforming them into tangible insights and solutions, fostering cohesion and driving impactful outcomes through effective communication and collaboration.
• Developed and sustained dynamic dashboards and reports via Tableau, granting stakeholders instant access to vital performance metrics, facilitating informed decision-making and enhancing organizational agility and responsiveness.
• Leveraged Python and R for predictive modeling, enhancing sales forecasts and customer insights. Optimized resource allocation and pricing strategies through data-driven analysis, improving overall business performance and profitability.
• Utilized data analysis techniques to identify trends and insights, contributing to strategic decision-making processes.
• Implemented and managed ERP systems such as SAP and Salesforce, optimizing business workflows. Resulted in a notable 20% enhancement in operational efficiency through streamlined processes and integrated data management solutions.
• Accelerated project timelines by 25% through adept utilization of Agile methodologies and JIRA. Enhanced team collaboration and efficiency while meticulously tracking SDLC phases, ensuring optimal project management and delivery.",Texas A&M Commerce,MBA ,3 years,10 months,Technology,Software,"Irving, Tx",Bengaluru,https://www.linkedin.com/in/adi-reddy-90521527a/
,,,Business Analyst,Cybcage Software,"• Leveraged BPMN techniques to model integration workflows, identifying inefficiencies and optimizing the e-commerce platform. Resulted in streamlined processes, enhancing efficiency and overall system performance.
• Designed intuitive Tableau and Power BI dashboards showcasing vital KPIs, facilitating informed decision-making and strategic planning for stakeholders. Enhanced data comprehension and actionable insights through compelling visualizations.
• Led collaborative efforts to tailor service solutions for SaaS applications, aligning closely with client needs. Resulted in enhanced user experience and satisfaction through customized design and development processes.
• Utilized SQL queries proficiently on MySQL and MongoDB databases, extracting and analyzing crucial data to comprehend transaction patterns and customer behaviors, enabling informed decision-making and strategic planning.
• Developed intricate wireframes and process flows with CAD and Visio, enhancing stakeholder communication and comprehension. Streamlined project approval by facilitating clear visualization and efficient decision-making processes.
• Crafted comprehensive project documentation in Confluence, delineating precise requirements and specifications. This instrumental resource fostered seamless communication among stakeholders and guided development teams adeptly 
through the project lifecycle.",,,,,,,,,
,,,Business Analyst ,Intex Technologies,"• Utilized advanced Excel functions and SQL queries for in-depth data analysis, resulting in actionable insights. Instrumental in achieving a 15% boost in operational efficiency through informed decision-making.
• Led the seamless integration and optimization of Salesforce CRM, enhancing sales pipeline visibility and forecasting accuracy by 30%, catalyzing streamlined operations and informed decision-making within the organization.
• Crafted interactive Tableau dashboards and visualizations to facilitate data-driven decisions, boosting stakeholder comprehension by 30%. Enhanced understanding of complex data for informed decision-making.
• Implemented advanced analytics and reporting tools on Azure, enhancing system monitoring and identifying areas for improvement. Resulted in a notable 10% increase in overall system efficiency, optimizing performance effectively.
• Collaborated cross-functionally, gathering and documenting business requirements with stakeholders. Ensured alignment with project objectives, delivering tailored solutions meeting organizational needs, fostering synergy and efficient workflow 
across departments.
• Implemented Python scripts for data manipulation and automation, reducing manual workload by 20% and improving data accuracy in ETL processes.",,,,,,,,,
38. Satya Pratapa,"English, telugu",,Business Analyst,Signify Health,"As a Business Analyst at Signify Health in Dallas, TX, I have documented functional specifications for operational reports and worked with teams to identify data sources. 
I have worked as part of a scrum team in an agile methodology and have experience collaborating with IT teams. 
I have utilized Agile Software Methodology and contributed to the development of the Health Systems’ Enterprise Resource Platform (ERP) application. 
I have participated in creating user stories and prioritizing them. 
I have performed GAP analysis and conducted JAD sessions to gather requirements. 
I have facilitated the scrum framework and created data mappings to transform data. 
The project involved re-engineering the existing billing system to achieve HIPAA compliance.",Osmania University,Bachelor of Engineering,6 years,all in us,Health,Banking/Finance,"Lewisville, Tx",Hyderabad,https://www.linkedin.com/in/satyapratapa/
,,,Business Analyst,Texas Capital Bank,"I worked as a Business Analyst at Texas Capital Bank in Dallas, TX. 
The project involved the development of a web portal for credit card holders to pay their bills online, access statement history and get rewards information. 
I defined business requirements and analyzed possible technical solutions. 
I designed Use Case Diagrams, Activity Diagrams and Sequence Diagrams, Use Cases and web prototypes. 
I developed processes and tools for requirements gathering, analysis, planning, tracking and delivery. 
I worked on BRDs and FRDs as a Business Systems Analyst. 
I created an Agile process flow in JIRA and reviewed Design Documents and Requirements Analysis Specifications with stakeholders. 
I designed test cases and the module included Online Bill Payments, Transfers and Online Bank Statements. 
I assisted in creating schedules and resource planning. 
I analyzed and managed requirements using Jira. I prepared and executed test cases for Navigational testing, Functionality testing and GUI testing. 
I worked closely with the development team and tested software releases.",,,,,,,,,
39. Sampita Sen,"English, Hindi",Yes,Business Analyst,DTCC,"Serve as a Business Analyst in Depository Trust and Clearing Corporation (DTCC), where responsible for managing DTCC - Settlement Modification process integration, documentation, and implementation. My work is to identify potential batch processes which take information form upstream and by various path and collected the same in downstream, those which are under DTCC settlement server, sample test plan reviews and test case drafting. In this project, our scope is to change the settlement turnaround from T+2 to T+1 to make the process routine quick and easygoing for the client. Responsible for modification of RSK application and its requirement gathering, system study and analysis. Manage the decision tree and data plan to identify potential problems and proactively identify solutions to address them in advance. Collaborate and consult with business and technology teams to provide comprehensive technological solutions for complex business problems.",IILM,MBA HR,10 years,6 years,Finance,Software,"Irving, Tx",Kanpur,https://www.linkedin.com/in/sampita-sen-85b904190/
,,,Senior Business Analyst,Intelliswift Software,"Managing OMS integration, client requirements, documentation, implementation, conducting review meetings to ensure timely completion and delivery of the project to the client; responsible for client interaction for requirement gathering, system study & analysis. Manage decision trees and data plans to identify potential problems and proactively identify solutions to address them in advance.",,,,,,,,,
,,,Business Analyst Project Management,California Department of Public Health,"Served as Business Analyst for California Department of Public Health for the vaccination initiative for COVID19 across the state. Proudly assisted in this health initiative to protect the community from COVID19. Worked with 15 different medical providers to set up, manage, and troubleshoot over 50 vaccination clinics on the MyTurn.ca.gov system. Used Salesforce to support everyday clinic operations including user management, clinic schedules and clinic reports. Tracked all provider support issues via ServiceNow. Responsible for staffing the project with state employees, LVN / consultants, developing / monitoring clinic appointments and inventory management, and setting up clinics on weekly basis and keep checking with the clinic staff about any query, user setup in clinic, report analysis and weekly extension of the clinics based on vaccine allocations.",,,,,,,,,
,,,Business Analyst ,City of Austin,"Served as Business Analyst for City of Austin, responsible for supporting the business in different phases of the project life cycle, with post-production support and ongoing maintenance by monitoring the current plan, identifying the scope of improvement, suggesting better plans and implementing them with consent of the project manager and team. The entire set of processes were carried out within Agile Methodology.
Involved in Inception Phase and prepared vision statement and initial data models that contain Business Requirement Documents and supporting documents (SOW, Request for Proposals, review past documents) that contain the essential business elements and detailed definitions.
Working with functional teams in an agile environment, analyze factors and components of systems and processes to manage interrelationships and facilitate change. Work with end-users and Stakeholders to define Business Requirements Documents (BRDs) for ITAM Configuration Management.",,,,,,,,,
40. Mark Moghadam,English,,Business Analyst,Fidelity Investment,"-Perform data consulting for Fidelity's business units and build data views that are tailored to the unique financial makeup of each business unit; these are then leveraged for decision-making.
-Act as a middle-man that communicates the data needs of Fidelity's internal business units to the technology teams.
-Manage financial allocations that fluctuate and input them into Fidelity's data system for the business units to ensure accurate data is being captured.",University of Missouri-Columbia,Bachelors in Finance and Economics,4 years,all in us,Finance,Finance,"Dallas, Tx",,https://www.linkedin.com/in/mark-moghadam-61456216b/
,,,Associate Financial Analyst,Fidelity Investment,"-Provided firmwide analysis in forecasting and budget planning; deeply knowledgeable of every facet of Fidelity’s business.
-Developed detailed spreadsheets, P&L statements, reports, Multi-Year Plans, and variance analysis. Highly skilled in Excel, PowerBi, Essbase, and Anaplan.
-Built documentation of data processes for Senior Leadership and used data findings to capture a unique story in various monthly
board decks and reports.
-Oversee Budget Transfer process and built Planning Software training; including knowledge of back-end calculations, for every
business group within Fidelity.
-Perfected knowledge of data hierarchies, account structures, and dimensions; validated various datasets, and their relationships.",,,,,,,,,
41. Goodluck Eze,English,,Business analyst,Dell Technologies,"• Conducted stakeholder interviews to gather comprehensive business requirements and translated them into actionable user stories, ensuring a clear bridge between business needs and technical implementation. 
• Leveraged SQL and Excel to analyze large datasets and provide actionable insights, aiding in decision-making processes.
• Collaborated with cross-functional teams to streamline processes, resulting in a 20% reduction in turnaround time for critical workflows through effective process mapping and gap analysis. 
• Utilized Tableau to create interactive dashboards and reports, visually presenting key performance metrics to senior leadership and enabling data-driven decisions. 
• Managed and prioritized a backlog of user stories using JIRA, ensuring the agile development team was aligned with business priorities and delivering value in each sprint. 
• Led the successful implementation of a ServiceNow-based workflow automation system, resulting in a 30% reduction in manual intervention and increased efficiency across incident management processes. 
• Proficient in all phases of the SDLC, from requirements gathering to system deployment.
• Oversaw system deployment, ensuring smooth transition and minimal disruption to business operations.
• Collaborated with IT teams to identify system enhancements, leading to the implementation of system improvements that positively impacted user experience and operational efficiency. 
• Provided post-deployment support, addressing system issues, and implementing necessary enhancements.
• Developed and monitored key performance metrics, providing regular reports to senior management.
• Authored comprehensive documentation artifacts including user manuals and technical specifications, ensuring clear communication between technical and non-technical stakeholders. 
• Engaged in weekly cross-functional meetings, effectively communicating project updates, and collaborating with stakeholders, resulting in successful project execution.",Covebtry University,MS Environmental Science,7 years,all in us,Technology,Health/Insurance,"Dallas, Tx",,https://www.linkedin.com/in/goodluck-eze-17800728a/
,,,Business analyst,Blue cross & blue shield of Illinois,"• Collaborated with a team of analysts to successfully implement a streamlined claims processing workflow, reducing processing time by 28% through meticulous process analysis and optimization.
• Conducted 40+ interviews with key stakeholders to elicit comprehensive business requirements, translating them into detailed functional specifications and user stories for agile development teams.
• Utilized Power BI to create interactive dashboards for 3 executive-level presentations, effectively communicating complex data trends and facilitating data-driven decisions.
• Led the evaluation and selection of a new customer relationship management (CRM) system, resulting in an improved customer satisfaction rate of 14% within the first six months of implementation.
• Analyzed 6 years of historical customer data to identify purchasing patterns, leading to the development of targeted marketing strategies and increasing sales by 18% in the first quarter.
• Played a pivotal role in the integration of ServiceNow for incident management, automating 42% of incident resolution processes and enhancing service quality.
• Collaborated closely with software development teams, ensuring that 97% of user stories were delivered on time and within scope during each sprint cycle.
• Facilitated 15 cross-functional workshops to identify process bottlenecks, resulting in the implementation of process improvements that reduced operational costs by $120,000 annually.
• Conducted comprehensive ROI analysis for proposed IT projects, contributing to the prioritization of initiatives aligned with the organization's strategic goals.
• Played a pivotal role in the development of a comprehensive business continuity plan that reduced downtime during critical system failures, ensuring operational resilience and reducing recovery time by 23%.",,,,,,,,,
,,,ServiceNow BA,Allstate,"• Work Closely with Product Owner/Stakeholder to understand business requirements and needs related to ServiceNow ITSM.
• Established requirements for the Financial and Management reports that measured the applications effectiveness at meeting its primary Objectives.
• Managed projects and served as primary liaison between client and multiple internal groups to clarify goals and meet standards and deadlines.
• Work Closely with Product Owner/Architect to decompose Features into stories that can be accomplished in each Sprint.
• Oversee the Product/Technical Backlog by creating Stories/Spikes/Defect for all Sprints.
• Great experience in facilitating sprint ceremonies like Sprint Planning, Daily standup, Sprint Review, and interactive Sprint Retrospectives
• Work closely to organized PI scope with Stakeholder to gauge need and urgency, team lead to gauge capacity. Looking over requirements and solutioning to ensure everything is ready for use.
• Created all testing scripts in ServiceNow Test Management 2.0 to test the recently developed changes and ensure stakeholder satisfaction.
• Responsible for training all end users on newly developed solutions.
• Defined the business need based on the business goals and objectives and defined the solution scope based on the assumptions & constraints, dependencies, and business needs.
• Integrate AIML models into the ServiceNow platform.
• Train/test complex ML models at scale
• Modeled cash flows for securitized transactions containing a wide variety of underlying assets.
• Responsible for creating proprietary Excel-based models to calculate bonds.
• Work in an agile-scrum environment where documentation, attention to detail, and team collaboration is required. Significant project management experience and high attention to detail.
• Write test cases in the HP Quality center application and run regression testing for financial integration applications.",,,,,,,,,
42. Imtiaz Uddin Ahamed,"English, bengali",,Business analyst,Texas A&M University - Commerce,"• Responsible for creating and maintaining online products and stores and issuing refunds in Touchnet Marketplace, as well as user administration and training.
• FAMIS Security Administrator.
• Assists with tracing payment transactions in Banner, Touchnet and FAMIS in support of reconciliation efforts.
• Assists with the support of technical/computer support for the division.
• Develop and maintain reports for Accounting to ensure proper reconciliation of Banner/FAMIS interface. These reports must meet all the fiscal areas reporting requirements to aid in the preparation of financial reports, audit projects, budget and strategic planning.
• Assists with the proper accounting and timely posting of the daily general ledger feed for the university..
• Assist users of financial area software such as FAMIS, Banner, Touchnet, Ticketrak, WebFocus, Call-em-All, Cascade.
• Assist with daily processing and scheduling of financial reporting utilizing Webfocus, Visual Basic (.asp), scripting (DOS/cron/Appworx), and PL/SQL.
• Research and analyze the business and technical problems faced by the office and then design, recommend, and/or implement solutions.
• Provide excellent customer service.
• May temporarily perform other duties as assigned to maintain operations and services.",Texas A&M Commerce,MSBA,9 years,2 years,Education,Education,"Commerce, Tx",,https://www.linkedin.com/in/iuahamed/
,,,Project Management Executive,The bridge consultancy,"• Devised multiple Request For Proposals (RFP), Expression of Interests (EOI), Tenders and Procurement Documentations 
• Worked on E-Procurements and Promising Research Journal, Social Media, Event Marketing 
• Developed research proposals 
• Organized Customized Training Sessions all around the globe for Government Officials 
• Maintained regular basis correspondence with foreign counterparts in 56 countries 
• Prepared Pre Departure Documents, Itinerary, Program Modules and Budget using MS Excel 
• Produced Digital Marketing during COVID pandemic using G-suit 
• Participated as an active member of the Business Development Team",,,,,,,,,
43. Vignesh Krishna,"English, Tamil",Yes,Business analyst,MTX Group,"Lead business architecture for an Agile fast paced delivery of a multi-million-dollar SaaS system for a Humanitarian project to help Asylum seekers with Housing, Legal and Education Services
Worked with cross functional teams across Development, QA and UI design to translate business requirements and functional process flows to technical specifications, epics and sprint story points for weekly product releases.
Managed key client expectations for delivery timelines and requirements changes driven by rapidly changing asylum policy requirements. 
Led the design and delivery of reporting activities including operational metrics",University of Illinois Chicago,MS Management Information Systems,7 years,1 year,Technology consulting,Software,"Frisco, Tx",Bengaluru,https://www.linkedin.com/in/vignesh-krishna-775103138/
,,,Business analyst,K&K Engineering,"• Worked with cloud database architecture writing complex queries in SQL.
• Solved business problems by conducting data analysis, data prep and data visualization using Power BI
• Designed machine learning use cases for business insights using Pytab plugin.
• Converted business requirements into technical requirements and sprint story points.
• Delivered data insights to multiple departments such as Supply-Chain, Engineering, and Finance.",,,,,,,,,
44. Austin Otunomo,English,,Business analyst,Epsilon,"• Conducted thorough data analysis on customer behavior, resulting in a 15% increase in targeted marketing efficiency.
• Utilized SQL and Tableau to extract, manipulate, and visualize complex data sets, streamlining the reporting process and reducing report generation time by 20%.
• Led the implementation of a new agile methodology, resulting in a 30% reduction in project delivery time and improved collaboration across cross-functional teams.
• Collaborated with stakeholders to perform SWOT analysis on existing processes, identifying and mitigating potential risks, leading to a 25% increase in overall project success rates.
• Spearheaded the development and documentation of comprehensive workflow analyses, resulting in a 20% improvement in operational efficiency.
• Managed end-to-end requirement gathering process for multiple projects, ensuring accurate and complete specifications, leading to a 15% decrease in project rework.
• Employed JIRA for efficient project tracking and management, resulting in a 25% reduction in backlog and improved project visibility.
• Implemented a stakeholder communication strategy that enhanced project transparency and reduced misunderstandings, contributing to a 30% increase in stakeholder satisfaction.
• Led a team in the creation and maintenance of comprehensive data models and mappings, resulting in a 20% improvement in data accuracy.
• Applied continuous improvement methodologies to enhance existing processes, leading to a 15% increase in overall team productivity.",Missouri State University,MS Business Administration Management ,5 years,all in us,Marketing ,Health/Insurance,"Dallas, Tx",,https://www.linkedin.com/in/austin-otunomo-9a902281/
,,,Business analyst,Blue cross & blue shield of Illinois,"• Conducted comprehensive requirement gathering sessions for key projects, ensuring 100% alignment with business objectives and reducing project rework by 20%.
• Utilized Microsoft Excel and SQL to analyze and interpret large datasets, resulting in a 15% improvement in data accuracy.
• Led the implementation of an Agile framework, increasing project delivery efficiency by 30% and fostering a more collaborative work environment.
• Developed and maintained detailed data mapping documentation, contributing to a 25% reduction in data integration errors.
• Collaborated with cross-functional teams to perform process mapping for critical workflows, leading to a 20% improvement in overall process efficiency.
• Managed and resolved stakeholder conflicts, improving team dynamics and resulting in a 15% increase in stakeholder satisfaction.
• Conducted SWOT analysis on existing business processes, identifying areas for improvement and contributing to a 20% increase in operational effectiveness.
• Utilized Power BI to create interactive dashboards for executive-level presentations, enhancing data-driven decision-making and improving communication effectiveness by 30%.
• Played a key role in the implementation of a new database querying tool, reducing query response time by 25%.
• Developed and delivered comprehensive training sessions for team members on the use of new tools and methodologies, resulting in a 20% increase in team proficiency.",,,,,,,,,
45. Zeel Patel,English,,Business analyst,Epic,"Designed and developed a business intelligence dashboard using Tableau Desktop, allowing executive
management to view past, current and forecast sales data.
Able to comprehend and translate complex and advanced functional, technical and business requirements into executable architectural designs.
Created custom queries/reports designed for quality verification and information sharing.
Create storyboard of backlog items in Agile and develop items according to business needs.
Authored Business Requirements (BRD), User Requirements, and Functional Requirements (FRD).
Created data queries and reports using WellView, Qliksense, Visual Studio, SQL Server Management Studio, SSRS, and Excel.
Creating and maintaining technical documentation. Experienced in data integration through extracting,
transforming and loading (ETL) data from various sources.
Analyzed key aspects of business to evaluate factors driving results and summarized into presentations.
Supervised daily operations and sales functions to maximize revenue, customer satisfaction and employee productivity. Increased customer satisfaction by resolving issues.
Provide financial insights to business units to improve financial performance, identify potential risks, and
opportunities.
Developed and implemented performance improvement strategies and plans to promote continuous
improvement.
Facilitated JAD sessions involving management, development and user teams for clarifying requirements and facilitating better communication.
Present internal and external stakeholders including customer reports through Confluence and Jira.
Resolved problems, improved operations and provided exceptional service.
Conducted research, gathered information from multiple sources and presented results.",Texas Wesleyan University,BBA Management,6 years,all in us,Health,Software,"Fort Worth, Tx",,https://www.linkedin.com/in/zeel-patel-a3840829a/
,,,Business analyst,Kofax,"Utilized Software Development Life Cycle (SDLC) to configure and develop process, standards procedures. 
Involved in weekly walkthrough and verification meetings with various stakeholders in the project.
Worked closely with various project stakeholders, SMEs, and staff to understand and document business
requirements.
Developing business requirement documents and functional specifications.
Embedded live Tableau dashboards on PowerPoint presentations, keeping the slides always updated.
Created reporting solutions in Excel and Power BI that sourced data from SQL data sources using complex queries. 
Utilize an Agile methodologies for defining and sizing user stories.
Facilitate daily Scrum Meeting and responsible for removing impediment
Identified process inefficiencies through gap analysis and outlined sensible solutions.
Collaborated with finance department on invoicing accuracy for applicable products, services, software and logistics.
Supported existing integrated platforms and new integrations using third-party integration tools to enhance business processes and operations.
Used HP Quality Center as a repository for requirement analysis, designing test cases, Executing test cases, Bug tracking and reporting.
Conducted research, gathered information from multiple sources and presented results.
Led projects and analyzed data to identify opportunities for improvement.
Worked to maintain outstanding attendance record, consistently arriving to work ready to start immediately.",,,,,,,,,
46. Joshua Sem,English,,ServiceNow BA,AHEAD,"• Work directly with key clients to capture business and user requirements and communicate those requirements to the platform team
• Define detailed stories and epics, with applicable acceptance criteria in collaboration with product owners and CDIs development team
• Elicit, analyze, communicate and validate requirements for business processes , accurately translating them into functional and technical requirements for the development team
• Responsible for authoring content and peer reviewing a wide array of documents, including functional, technical, training as well as planning and roadmaps",North Carolina Agricultural and Technical State University,BS IT,4 years,all in us,IT Consulting,Data,"Dallas, Tx",,https://www.linkedin.com/in/joshuasem/
,,,ServiceNow BA,NTT Data Services ,"• Work closely with and support business process consultants during client workshops and throughout ServiceNow implementations.
• Capture business requirements, work with process flow diagrams, and document business cases as well as end-to-end process flows.
• Partner with leadership and project teams to write, review and maintain user stories.
• Prepare training materials, knowledge transfer documents, and quick reference guides
• Major clients worked with as business analyst include Wood Mackenzie, CGI Federal, Novavax, Indiana Public Retirement System, and Lockheed Martin.
• Worked as QA Tester with clients such as Corium, Sylvamo, First West Credit Union, and National Commercial Bank of Jamaica to fulfill testing requirements and ensure ServiceNow implementation is functioning end to end as expected.",,,,,,,,,
47. Terralyn C.,English,,Business Analyst,Insight,"● Increased team productivity by 35% weekly through strategic Agile consultations with Product Owners, Scrum Masters, and Project Managers.
● Elicited requirements using a variety of interview methods including interviews and documentation, BRDs, use cases and surveys to discover key areas of process re-engineering.
● Performed highly complex analysis of business and user needs, documents requirements and translated into proper system and processes requirement specifications within JIRA and AzureDevOps.
● Created operating procedures (SOP’s) and release notes which detail, at a high level, need-to-know information about our applications and feature releases.
● Developed and maintained strong relationships with key stakeholders and subject matter experts to gather insights and feedback on system requirements and improvements.",NYU,,5 years,all in us,IT Solutions,Finance,"McKinney, Tx",,https://www.linkedin.com/in/terralyncherrybrown/
48. Richa Thakkar,"English, Hindi",,Business Analyst,Tetra Tech,"Preparing for elicitation by defining the desired outcomes of the activity, considering the stakeholders involved and the initiative goals.
 Utilize agile software development methodology SCRUM as a lightweight process we used to manage and control software and product development. 
 Decomposing the high-level EPICs into the granularity of user stories in detailing the user stories descriptions and the acceptance criteria using the agility software tool.
 Creating the Mockups for the data loading, mapping, imputing, and weighting processes UI for desktop applications. 
 Review the test cases written by the testers during the sprints and provide the appropriate feedback.
 Refining the user stories before the sprint starts and clarifying the technical queries developers raised during the refinement sessions.
 Organized the backlog stories with the product owner and prioritized the stories for upcoming iterations.
 Resolved the conflict arises during the defect management process between the developers and testers and took the appropriate action.
 Participated and played a key role during the Product Increment (PI)/ MVP or PSI planning from the EPICS priority prospective and helped stakeholders in doing the T-shirt sizing estimation. 
 Participating in the scrum ceremonies, including pre-iteration and PI planning.
 Participating in the research and gathering business requirements through surveys, interviews and JAD sessions, decision making, and User Acceptance Testing (UAT). 
 Creating documentation of the AS-IS and TO-BE analysis and workflows using UML modeling.
 Writing user stories, acceptance criteria, and requirement documents and reviewing with relevant stakeholders for Sign Off.
 Assisted the Project Manager in setting realistic Project expectations and in evaluating the impact of changes on the organization and plans accordingly and conducted Project related presentations.",Gujrat University,,9 years,all in us,Technology,,"Irving, Tx",Gujrat,https://www.linkedin.com/in/thakkar-richa/
,,,Business Analyst,Tale Team,"Preparing for elicitation by defining the desired outcomes of the activity, considering the stakeholders involved and the initiative goals.
 Utilize agile software development methodology SCRUM as a lightweight process we used to manage and control software and product development. 
 Decomposing the high-level EPICs into the granularity of user stories in detailing the user stories descriptions and the acceptance criteria using the agility software tool.
 Creating the Mockups for the data loading, mapping, imputing, and weighting processes UI for desktop applications. 
 Review the test cases written by the testers during the sprints and provide the appropriate feedback.
 Refining the user stories before the sprint starts and clarifying the technical queries developers raised during the refinement sessions.
 Organized the backlog stories with the product owner and prioritized the stories for upcoming iterations.
 Resolved the conflict arises during the defect management process between the developers and testers and took the appropriate action.
 Participated and played a key role during the Product Increment (PI)/ MVP or PSI planning from the EPICS priority perspective and helped stakeholders in doing the T-shirt sizing estimation. 
 Participating in the scrum ceremonies, including pre-iteration and PI planning.
 Participating in the research and gathering business requirements through surveys, interviews and JAD sessions, decision making, and User Acceptance Testing (UAT). 
 Creating documentation of the AS-IS and TO-BE analysis and workflows using UML modeling.
 Writing user stories, acceptance criteria, and requirement documents and reviewing with relevant stakeholders for Sign Off.
 Assisted the Project Manager in setting realistic Project expectations and in evaluating the impact of changes on the organization and plans accordingly and conducted Project related presentations.",,,,,,,,,
,,,Business Analyst,Dunkin,"Understood the client vision of what they wish to build and conveys that vision to the SCRUM team
> Worked with client to gain a solid understanding of users, the marketplace, the competition, and future trends for the domain in which the client’s business lives
> Documented the use cases/user stories and functional requirements from project business requirements and as-is system behavior
> Documented system impacts, data flows and exchange between systems
> Worked with technology team to refine project requirements and review designs and test plan results to confirm that line of business goals is met
> Worked with Digital Product Managers and Line of Business partners to develop and define strategic goals, roadmaps to achieve those goals, and success criteria to confirm goals have been met
> Worked with Digital Product Managers, Architects, and Line of Business partners to develop and define technology project scopes, requirements, and operational impacts (migrations support, etc.)",,,,,,,,,
49. Onos Akpobo,English,,Business Analyst,Akami Technologies,"• Conducted comprehensive data analysis on customer traffic patterns, resulting in a 15% increase in website load speeds, enhancing user experience.
• Implemented Agile methodologies to streamline project workflows, reducing time-to-market by 20% for new product launches.
• Collaborated with cross-functional teams to gather and analyze requirements for the development of a proprietary content delivery platform, resulting in a 25% improvement in content delivery efficiency.
• Facilitated stakeholder meetings to elicit business needs and translate them into actionable user stories, ensuring alignment between business objectives and technical solutions.
• Identified process inefficiencies through detailed process mapping, leading to the implementation of workflow optimizations that resulted in a 30% reduction in operational costs.
• Acted as a liaison between business stakeholders and technical teams, ensuring clear communication and understanding of project requirements, contributing to a 95% client satisfaction rate.
• Conducted user acceptance testing (UAT) for software enhancements, identifying and resolving issues to maintain product quality standards and minimize user disruptions.
• Assisted in the development and execution of training programs for internal staff on new software systems, resulting in a 40% increase in user proficiency within the first quarter.
• Utilized SQL and data visualization tools such as Ms power BI to generate weekly reports on key performance metrics, facilitating data-driven decision-making for senior management.
• Managed a portfolio of projects concurrently, consistently meeting project deadlines and budgetary constraints, with an average project success rate of 90%.
• Contributed to the development of a predictive analytics model using machine learning algorithms, resulting in a 10% increase in customer retention rates within the first year of implementation.",De;ta State University,BS Economics,4 years ,all in us,Cloud,Marketing,"Lewisville, Tx",,https://www.linkedin.com/in/onos-akpobo/
,,,Business Analyst,Epsilon,"• Collaborated with cross-functional teams to gather and analyze business requirements, leading to the successful implementation of 5 major system enhancements within strict deadlines.
• Acted as a key liaison between business stakeholders and technical teams, facilitating clear communication and alignment of project objectives.
• Utilized Agile methodologies to manage project timelines, ensuring timely delivery of 10+ initiatives, each meeting or exceeding client expectations.
• Produced detailed reports and presentations showcasing insights derived from data analysis, aiding executive decision-making processes.
• Conducted comprehensive data analysis utilizing SQL and Ms power BI to identify trends and patterns, resulting in a 15% increase in customer retention rates.
• Led process improvement initiatives, streamlining workflows and reducing operational costs by 20%.
• Managed a portfolio of projects simultaneously, maintaining a 95% on-time delivery rate and within budget constraints.
• Utilized CRM systems such as Salesforce and HubSpot to track and analyze customer interactions, resulting in a 25% increase in sales leads conversion.
• Developed and maintained comprehensive documentation including project plans, requirements specifications, and user manuals.
• Provided training and support to internal stakeholders on newly implemented systems and processes, increasing user adoption by 30%.
• Conducted regular performance reviews and evaluations of business processes, identifying areas for optimization and achieving a 10% increase in overall efficiency",,,,,,,,,
50. Abhinav Reddy,"English, telugu",Yes,Business Analyst,Princpal Financial,"● Create a storyboard of backlog items in Agile and develop items according to business needs.
● Utilize MS Project to create and maintain project schedules, defining project tasks, dependencies, and timelines.
● Developing and maintaining interactive Tableau dashboards, providing stakeholders with real-time access to critical business metrics, leading to a 25% improvement in data accessibility and informed decision-making.
● Contributing to a 10% increase in revenue by conducting market research, analyzing customer behavior, and recommending strategic pricing and product positioning strategies.
● Conducting Impact analysis on business processes, identifying areas with the most potential for improvement and cost-saving opportunities.
● Developing and maintaining a Requirements Traceability Matrix (RTM) to track requirements throughout the project lifecycle.
● Developing SQL scripts for creating tables, Sequences, Triggers, and materialized views.
● Manage functional and non-functional Business Requirements and new requested requirements using Jira.",UT Arlington,MS Engineering/Industrial Management,4 years,1 year,Finance,Finance,"Dallas, Tx",Pune,https://www.linkedin.com/in/abhinav-reddy-4a278617b/
,,,Business Analyst,Venquest Investments,"● Utilized Waterfall methodologies to effectively assist with the planning and implementation of Business.
● Gathered and documented business BRD, and FRD from both formal and informal sessions and validated the needs of the business stakeholders.
● Developed and automated reports using MS Excel, reducing report generation time by 50% and providing stakeholders with realtime insights for data-driven decision-making.
● Implemented data visualization tools and dashboards, enabling stakeholders to make informed decisions, resulting in a 30% improvement in business performance metrics.
● Designed and developed interactive Power BI dashboards and reports, providing stakeholders with real-time visualizations and resulting in a 40% improvement in data accessibility and user engagement.
● Conducted GAP analysis to identify discrepancies between current and desired business processes, facilitating process improvements and increasing operational efficiency.
● Leveraged SQL points to optimize query performance, reducing execution time by 60% and enhancing overall database efficiency.
● Developed and maintained project timelines using time management points to track progress and allocate resources efficiently.",,,,,,,,,
,,,Software Development Intern,MindShare Business Consulting,"• Build UI front-end code in SAP-Fiori through the Javascript framework.
• Executed cross-platform linking of SAP systems to the Front-end Fiori structure. 
• Performed Unit testing activities on application functions."

Name,Languages spoken,Indian experience,Role,Company,job description,University,Course,Work experience,Work experience in the U.S,Industry,Previous industry type,Location,Location from India,

1. Nibhrat Lohia,"English, Hindi",,Machine Learning Engineer,Experian,,Southern Methodist,MSBA,13 years and 9 months,13 years and 3 months,Credit,Sound,"DFW, Tx",,
,,,Adjunt Lecturer ,SMU,,,,,,,,,,
,,,Sr. Data Scientist,Bose,,,,,,,,,,
,,,Sr. Data Scientist,Humana,,,,,,,,,,
,,,Data Scientist,S5 Startos,,,,,,,,,,
,,,Data Scientist,Copart,Successfully completed two projects: 1) Elimination of defects in Long DRV. 2) Elimination of sorting defects in Overflow Valves,,,,,,,,,
,,,,,,,,,,,,,,
"2. Kalyan (Arjun) Lakshmanan 
","English, Telugu",,Machine Learning Consultant,NEST,"Principal machine learning engineer at NEST. Brought in clients for data discovery and ML/AI solutions. Hammes Partners: Improved the performance of a real estate property classification model that groups properties according to potential ROI. Improved model accuracy and recall by more than 15% while also reducing overfitting by utilizing tree-based methods (Random Forest, XGBoost). Instructed business analysts on standard Python practices, and utilizing an organized data pipeline in order to bring the model into eventual production.",UTD,BS Physics,8 years and 1 months,7 years and 1 months,IT Services ,Edtech,"Dallas, Tx",,
,,,Data Science Fellow,General Assembly,"Successfully completed a rigorous data science fellowship, where expertise in machine learning techniques were further honed and refreshed. Multiple end-to-end projects were completed and productionized: Painting => Art-Movement Classifier - Resnet18 Convolutional Neural Network -Gradio / HuggingFace Twitter / X.com - Disaster Tweet Recognition - LSTM with GloVe Embeddings - Streamlit IMDB.com - Movie Revenue Prediction - MLR with L1 Regularization - Kaggle OpenAI / Reddit.com - ChatGPT vs Human Recognition - Multinomial Naive Bayes - openai, PRAW",,,,,,,,,
3. Mounika Dantuluri,"English, Kannada",,Machine Learning Engineer,Goldman Sachs,,UTD,MS ITM,6 years and 11 months,9 months,Finance,Finance,"Dallas, Tx",,
,,,Machine Learning Engineer Intern,Toyota Financial Services,,,,,,,,,,
,,,MLOps Engineer,Wells Fargo,,,,,,,,,,
,,,Senior Analyst,Infosys,,,,,,,,,,
4. Srishti Srivastava,"English, Hindi",yes,Senior Business Intelligence Engineer,Humana,,Okhlahoma SU,MSBA,5 years and 2 months,2 years and 1 month,health,Finance,"Austin, tx",Rajasthan,
,,,Machine Learning Engineer,William Blair ,"Worked with cross-functional stakeholders under Institutional Sales, Research & Trading to define problem statements, collect & analyze data, make recommendations, and routinely communicate progresses and other key indicators to leadership - Led end-to-end data migration transferring over 10+TB of on-premises data to ADLS using Azure Blob Tables and Synapse pipelines, resulting in a remarkable 60% reduction in pipeline runtime compared to previous systems - Built a scalable data processing system in Azure Synapse by leveraging PySpark’s distributed computing capabilities - Established a robust data governance framework for raw, silver, and gold data zones, ensuring compliance with industry standards and improving overall data quality by 25% - Streamlined data ingestion with an efficient ETL workflow & automated incremental data load, saving cloud storage cost by 40% - Orchestrated 15+ interactive Power BI dashboard to analyze readership data; track client interests in securities and identify relevant stock options resulting in an increase of $300K annual revenue from improved trading - Communicated insights effectively to leadership through weekly presentations, improving cross-functional alignment and ensuring timely decision-making",,,,,,,,,
,,,SAP Functional Consultant,TCS,"Client: American Fortune 500 Industrial Supply Company - Designed SAP solutions in Warehouse Management Systems by prioritizing efficiency, resiliency and maintainability - Automated multiple weekly & yearly activities by developing Python scripts saving ~500 to 650 hrs of manual effort per year - Developed sustainable and scalable ABAP code updates using efficient and optimized SQL queries and stored procedures - Resolved 100% major incidents by providing effective and rapid responses as per SLA time-frame - Compiled and reviewed problem metrics to identify recurring problems, trends and potential problem sources - Developed a firm understanding of Agile values and principles and the Scrum framework.",,,,,,,,,
,,,Data analyst,ISRO,"- Developed project titled “Crime Data Generation, Reconfiguration and Analysis” aimed at aggregating & plotting live news

- Developed model to aggregate & process the real-time news data from websites and generate structured crime data.

- Visualized the structured data plotted on Bhuvan Portal (ISRO’s GeoPortal: UI to explore a set of map-based content).

- Used Python as the programming language wherein Numpy and Pandas were used for data aggregation and refinement, NLTK for data processing and Matplotlib for visualization.",,,,,,,,,
5. Nicole Hui ,English,,Machine Learning Engineer,JPMorgan Chase & Co,"• Working on a team of developers to productionize machine learning models in Community and Consumer Banking Financial Card Risk using Pytorch, Hadoop, and Spark

• Productionized cloud-based machine learning model, enabling the firm to predict the probability of customer inactivity after receiving a banking welcome offer 
• Implemented feature engineering module to create production-ready input features for the model using PySpark and SQL 
• Preformed mismatch analysis to achieve exact feature transformation match with preproduction output

• Migrated an on-prem production model that predicts customer banking activity during economic downturn to AWS
• Removed dependencies on decommissioned models and customer sensitive data and by integrating multiple models using PySpark
• Implemented a proof-of-concept protocol to reduce data transfer time for validations by creating a cross-account S3 bucket with managed role and lifecycle policies in multiple environments using terraform
• Conducting end-to-end model integration testing to validate model output, achieving 100% match with modeler’s output",UTD,MSBA,2 years,all in us,Finance,Finance,"Plano, Tx",,https://www.linkedin.com/in/nicole-hui/
,,,Software Engineer Intern,JPMorgan Chase & Co,"• Created an extended reality web application as a proof of technology using Python, Flask, and ThreeJS to host data in a centralized location for bankers to access client information 
• Coordinated with data science team create project plan, designing data flow and models, API structure, interface, and JIRA stories 
• Wireframed and developed an immersive user interface screen detailing client and subsidiary insights using Javascript and ThreeJS",,,,,,,,,
6. Lanka Mounica,"English, Telugu",Yes,Machine Learning Engineer,CVS,"• Developed a high-accuracy prescription refill demand forecasting model using ARIMA and XGBoost in Python, optimizing inventory and reducing out-of-stocks at CVS pharmacies.
• Implemented NLP pipelines with NLTK and spaCy for sentiment analysis and topic modeling of customer feedback, leveraging Word2Vec and BERT to enhance feature extraction and classification for deeper customer insights.
• Explored deep learning models (RNNs, LSTMs) with TensorFlow and PyTorch in both time series forecasting and NLP tasks to further enhance predictive accuracy.
• Deployed trained models in a scalable, production environment using Docker and Kubernetes, ensuring optimal performance and robustness through rigorous model evaluation and hyperparameter tuning (grid search, cross-validation).",UTD,MSBA,3 years,2 years,Health,Retail,"Irving, Tx",Hderabad,https://www.linkedin.com/in/lanka-mounica/
,,,Machine Learning Engineer,7-Eleven,"• Designed an alerting system leveraging SNS, REST API, and Redshift data sources to proactively notify fulfillment centers of potential risks via messaging platforms, facilitating preemptive issue resolution.
• Orchestrated a real-time data ingestion pipeline into an S3 data lake, triggering Lambda functions to execute alert-specific logic and deliver notifications to Slack via webhooks.
• Developed and integrated a machine learning model for inventory shortage forecasting into the alerting system, achieving a 15% reduction in both overstock and stockouts.",,,,,,,,,
7. Jash Raval,"English, Gujrati",Yes,Machine Learning Engineer,TCS,"Engaged in comprehensive phases of Data Mining, including Data Extraction, Data Cleaning, model development, and Data visualization, with subsequent inferencing.
Ensured model's high true positive rate while minimizing false positives.
Utilized PyTorch and transfer learning to train a Convolutional Neural Network (CNN) for precise identification of road signs and directional cues in diverse lane images.
Trained neural networks to achieve elevated precision in human pose estimation, face recognition, image detection, and other domains.
Optimized model hyperparameters using TensorFlow, with preprocessing of image datasets using OpenCV.
Evaluated model accuracy and data sources using evaluation metrics such as F1 score and mAP score.
Utilized YOLO and RESNET to perform object detection, in addition to employing Voxelnet for comprehensive point cloud-based 3D object detection, all within the domain of deep learning methodologies for image processing.
Demonstrated proficiency in generating computer vision images from Lidar and camera data through expertise in Synthetic Data and point cloud techniques.
Troubleshoot compatibility issues between CUDA versions, Python packages, and hardware configurations, ensuring seamless integration and functionality.
Formulated Python scripts for the conversion of 3D point cloud data into JSON format.
Contributed to various 3D and 2D annotation tasks, encompassing video and image annotations.",Valparaiso University,MS IT,4 years,3 years,Consulting,Finance,"Frisco, Tx",Ahemdabad,https://www.linkedin.com/in/jash-raval/
,,,Bug Data Engineer,Huntington National Bank,"Proficient in Data Extraction, Transformation, and Loading (ETL) through tools like SQL Server Integration Services (SSIS), ensuring streamlined data workflows.
Demonstrated expertise in SQL server encompassing Data Definition Language (DDL) and Data Manipulation Language (DML), coupled with adeptness in table construction and normalization techniques.
Designed and executed secure and efficient data storage solutions using technologies such as Hadoop Distributed File System (HDFS), Apache Kafka, and Snowflake, for managing extensive data volumes.
Implemented data processing and transformations in PySpark, within the Spark framework, optimizing data handling.
Constructed robust data pipelines utilizing Kafka, Spark, and Hive to facilitate seamless data ingestion, transformation, and analysis.
Possess a comprehensive grasp of relational database concepts, with hands-on experience in Oracle DB, DB2, and SQL Server environments.",,,,,,,,,
,,,Software Developer,Path IT Solution,"Applied best coding practices and employed object-oriented programming concepts, including abstraction and association, to drive full-stack software development initiatives.
Executed end-to-end website development utilizing PHP, JavaScript, and HTML, spanning both front-end and back-end components.
Optimized webpage functionality and user experience by crafting site structures, refining navigation, implementing page optimization strategies, and seamlessly integrating graphics.
Engineered RESTful APIs using Node.js and TypeScript, facilitating seamless communication between front-end and back-end systems while adhering to industry standards.
Utilized HTML, CSS, and Java to extensively overhaul the flagship application's homepage, yielding a substantial surge in click-through rates.
Utilized React's core concepts including components, props, and state to build basic user interface elements and manage their dynamic behavior.
Devised and executed solutions for scalability, performance enhancement, monitoring, and system configuration management, leveraging Amazon Web Services",,,,,,,,,
8. Raag Patel,English,,Machine Learning Engineer,Amerya Global INc,"Built and deployed advanced ML, AI, and deep learning models and algorithms using Vertex AI.
Logistic regression, XGBoost, Random Forest, K-Means clustering.
Conducted data vectorization and feature engineering for enhanced model performance & to enrich dataset insights.
Comfortable using the streaming data load window (PyFlink).
Streaming and batch data load ingestion using Pub/Sub, GCS, Cloud Functions, App Engine, AppServer.
Data pipelines using Apache Spark, Google Cloud Dataflow, Azure Data Factory, and Apache Airflow.
Creating, managing, and optimizing Dataproc and Databricks clusters to load data into BigQuery, Bigtable, and HDFS.
Python, R, SQL, Kubernetes (K8s), Docker, VMs.",SMU,MSBA,2 years,all in us,Software,Retail,"Dallas, Tx",,https://www.linkedin.com/in/raagpatel/
,,,Data Science Intern,Hanesbrands,"Partnered with stakeholders to launch a comprehensive data science project. And oversaw the full data science lifecycle, from data exploration to presenting findings to management.
Applied a quasi-Poisson regression model to assess revenue impacts and broader business
benefits.
Utilized Python, R, and SQL for diverse data operations.
Worked on the inception and the implementation of:
 Q Groups:
Segmented SKUs using K-Means clustering and performance criteria.
Optimized SKU groupings based on sales and inventory metrics.
 Breakpoints:
Analyzed SKUs to determine optimal inventory levels.
Offered insights on inventory stocking based on sales metrics.
 Power BI Dashboard:
Developed an interactive Power BI Dashboard, tailored for stakeholder engagement and real-time insights.",,,,,,,,,
9. Philip Martin,English,,Machine Learning Engineer II,Hunt Energy Network,"Designing and Developing an intelligent platform for the rapid development, testing, and deployment of real-time revenue maximization models in the cloud. Designed to facilitate make CI/CD and DevOPS as painless as possible.

Developing ML and Optimization models for revenue maximization.",UTD,BS CS,4 year,all in us,Energy,Education,"Dallas, Tx",,https://www.linkedin.com/in/philip-martin-software/
,,,Software Engineer Intern,UTD,Developed an open source laboratory protocol automation and monitoring application in C# .NET. Planned for use in neuroscience research in the Neurobiology of Memory Lab. Delivers a more consistent experience to laboratory workers with Windows Presentation Framework (WPF) while providing an easy to use extension system and API through C# Managed Extensibility Framework (MEF).,,,,,,,,,
10. Aashesh Nareshchand,"English, Tamil",Yes,Machine Learning Engineer,Data Society,"• Python developer of an internal data product that allows users to create customized data science courses, enabling them to choose datasets and course materials to suit their needs. Constructed data pre-processing logic on user uploaded datasets with various data mining steps performed tailored to each course's requirements.
• Deployed the product as a Flask application to Google Kubernetes Engine (GKE) on GCP. Established CI/CD with Bitbucket pipelines that automates building of Docker images with custom dependencies and streamlines application's deployment.
• Employed coding best practices, including OOPs, virtual environments, and secret management standards.",UTD,MSBA,6 years,4 years,Technology,Technology,"Dallas, Tx",Chennai,https://www.linkedin.com/in/aasheshnareshchand/
,,,Data Scientist,Data Society,"• Contributed towards developing an AI-powered semantic search engine for cybersecurity professionals by building - ETL pipelines to integrate diverse data sources of web-scraped and API-extracted information, NLP based linkages using distilbert embeddings.
• Achieved a 5% improvement in lead conversion for a client through data-driven marketing analytics and recommending point changes in lead-scoring systems. Used Dask to data engineer 100 GBs of lead-activity data and pipelined the workflow using Data Version Control.
• Built Tableau dashboards for a state department of health, visualizing key metrics for early care and learning programs.
• Summarized content marketing text using transformer-based BART and T5 models post data preprocessing.",,,,,,,,,
,,,Offering Manager Intern,IBM,"• Identified, analyzed, and interpreted trends or patterns in JIRA data sets of a Product Management team by finding correlations and visualizing with charts using Python
• Analyzed metrics across 7 domains using regression, Ctree and clustering algorithms to group issues based on resolution time
• Predicted the customer experience at 64% accuracy consuming historical Net Promoter Score (NPS) data and implementing several classification algorithms using scikit-learn
• Forecasted the count of backlog issues by developing plots and time series models like ARIMA, SARIMA, SES in R",,,,,,,,,
,,,Programmer Analyst,Cognizant,"• Worked on Application Production Support for Walmart, overseeing backend operations of Linux applications.
• Achieved a 20% reduction in incident inflow by automating solutions with SQL and Linux shell scripts.
• Presented reports and dashboards in MS Excel to upper management regarding project progress and results based on data fetched from ServiceNow
• Provided ad-hoc reports to clients by manipulating store data from Informix database with SQL 
• Authored code fixes/enhancements for inclusion in future code releases and patches",,,,,,,,,
11. Tarun Vakkalagadda,"English, Telugu",Yes,Senior Machine Learning Engineer,Fidelity Investments,"- Designed a solution to scrape data from various websites and automatically classify them based on the business usecase.
- Developing solutions to create fault tolerant bulky end points for open source LLMs",University of South Florida,MSBA,5 years,2 years,Finance,Pharmaceutical,"Dallas, Tx",Hyderabad,https://www.linkedin.com/in/tarun-vakkalagadda/
,,,Data Science Intern,Bayer,"- Working with unstructured textual data to create topic models.
- Creating data pipelines for ingestion and harvesting data using google bigquery",,,,,,,,,
,,,Machine Learning Engineer,TCS,"-Worked with Business Analyst’s and Product Managers to frame a problem, both mathematically and within the business context
-Researched and applied machine learning algorithms in the areas of analytics, computer-vision, NLP and timeseries analysis
-Technical expertise with data models, data mining, and segmentation techniques.
-Knowledge of programming languages and analytical frameworks - Python,spark, tableau, R,SPSS, Hive, and Hadoop.
-Hands-on experience with database design for both SQL and NoSQL database design.
-Tested and deployed highly reliable solutions to improve data reliability, efficiency and quality.
-Working knowledge on various deployment tools like docker, kubernetes and jenkins.
-Analyzing, organizing, and cleaning unstructured data to bring valuable insights for customers.
- Develop & Implement NLP models (topic modeling, semantic search, Q&A answering, chatbots, etc) for real-time inference on text data;
- Demand forecasting: Implemented algorithms to forecast the demand for several client products accurately;
- Define clear target performance metrics from ambiguous the client's requirement and accomplish them at a fast pace;
- Developing tools to standardize data quality;
- Automating several manual tasks.",,,,,,,,,
12. Haonan (Howard) Wang,English,,Principal Machine Learning Engineer,DriveTime,"Built the ML pipeline for data collect, preprocess, model training, and deploy.
Built the CI/CD pipeline
Built the model auto-training pipeline
Built the Data Monitoring pipeline
Worked with leadership team and business team to develop new features",Texas A&M Univeristy,Master of Engineering ,8 years,all in us,Automation,Retail,"Dallas, Tx",,https://www.linkedin.com/in/haonan-howard-wang/
,,,Senior Machine Learning Engineer,Micheals Store,"1. Leaded the REC-API team to build Flask-RESTPlus API to provide recommendation data from MongoDB and Redis to Michaels website.
2. Refactored and enhanced the batch pipeline to process ML jobs via Airflow and PySpark.
3. Designed the framework for AutoML including workflow, frontend UI, backend API, and MongoDB structure using H2O package.
4. Helped Advertisement Team to design the Bidding Engine API with Django.
5. Worked with QA and DevOps team for the performance/stress testing for REC-API and resolved the performance issues.
6. Mentored new teammates and helped onboarding, including setup virtual environment to run unit test and go through the bitbucket repo structure.",,,,,,,,,
,,,Machine Learning Engineer,Walmart Global Tech,"1. Used Machine Learning to build Anomaly Detection tool.
2. Automated data transfer process for Data Scientist and Finance Team.
3. Worked with Data Scientist to build ML Pipeline for Walmart Digital Planning & Analysis (DP&A)",,,,,,,,,
13. Akhil Nagulavancha,"English, Telugu",Yes,Machine Learning Engineer,URBN,"• Developed and Maintained CI/CD solution with Google Cloud Build for Nuuly Rental and Thrift Machine learning workflows and Services transitioning from old Jenkins based solution 
• Enabled Artifact Registry for internal Python Packages and Container images of Nuuly Data Science Team. 
• Maintained and improved Machine Learning recommendations pipeline for Nuuly Thrift and Rental Pipelines hosted through Airflow and Kubeflow on Google Cloud 
• Significantly reduced infrastructure costs of Nuuly ML Engineering infra by timely improvements and ,developing low cost solution.",Indiana Bloomington University,MS Intelligent Systems Engineering,5 years,3 years,Clothing,Consulting,Raleigh-Durham-Chapel,Hyderabad,https://www.linkedin.com/in/akhil-nagulavancha/
,,,Analyst Data Services,TCS,"• Worked on developing ETL data pipelines for power train assembly line components data.
• Implemented ETL schedules for updating data nodes for developing dashboards 
• Developed end to end solution on Palantir Foundry platform solution.",,,,,,,,,
14. Hao Lu,English,,Machine Learning Engineer,TikTok,"Data Trust and Safety, Automated Content Moderation
Create multi-modal models to filter inappropriate content from all TikTok video uploads.",University of Minnesota,"PHD, Cognitive and brain sciences",3 years, all in us,social media,social media,"Bellevue, washington",,https://www.linkedin.com/in/lu-h/
,,,Research Scientist,Meta,"Reality Labs Research, Audio
Developed multi-modal model of human communication behavior for next-gen AR/VR device, including head tracking, eye tracking, speech activity and egocentric video.",,,,,,,,,
15. Kartik Singhal,"English, Hindi",,Senior Machine Learning Engineer,Meta,"Senior Engineer in Search and Marketplace Ads. I work on improving user journeys on Facebook search and marketplace ads product with experience in Query Understanding, Contextual Relevance, Ads Delivery/Quality & Auction",University of Minnesota,MS CS,8 years ,all in us,socila media,E commerce,Greater Seattle Area,Rajasthan,https://www.linkedin.com/in/kartiks93/
,,,Machine Learning Engineer II,Amazon,Working as Machine Learning Engineer in Sponsored Products Search Relevance team at Amazon. My team is responsible for Ads relevance ranking on Amazon Search,,,,,,,,,
,,,Software Development Engineer,Amazon,"– Tech-lead in a new machine learning project for pricing products in Amazon’s private label brands and driving complete project launch.
– Current responsibilities include managing the model implementation, price elasticity analysis, model-training (Using different technologies/languages including Spark, Scala in production and R for prototyping). Driving WW launch timelines including optimization metrics in different countries and model-improvement.
– Part of initial Engineering team (4 Engineers). Responsible for designing 2 major online components of the system and setting up complete online infrastructure which can react to real time user events to update price predictions. Drive the usage of latest technologies like EMR, Lambda functions, Container Services and SageMaker for model serving.
– Ran A/B online experiments against key business metrics to produce validation of new model against status quo.",,,,,,,,,
16. Sujan Panchavarthi,"English, Hindi",,Machine Learning Engineer,Intuit,"•Partnered with a cross-functional team of data scientists to prototype ML models, employing Python, TensorFlow, and PyTorch to deliver high-impact solutions for customer segmentation and targeted marketing campaigns.
•Designed scalable data pipelines for real-time data processing using Apache Spark, SQL and integrated Kafka, identifying key features to optimize model performance for financial forecasting models.
•Automated financial document processing using NLP systems with BERT and GPT models. Led the design, implementation, and deployment of machine learning models and large language model (LLM) applications.
•Implemented a wide range of ML algorithms, including gradient boosting, deep neural networks, support vector machines (SVMs), and k-means clustering for creating predictive models to forecast customer spending patterns, aiding targeted marketing strategies.
•Led the migration of machine learning workflows to AWS, leveraging SageMaker for scalable training and deployment, S3 for data storage, and Lambda for serverless inference, enhancing scalability and reducing operational costs.
•Spearheaded the development of a sophisticated financial analytics dashboard using Tableau, providing real-time insights for strategic decision-making.
•Transitioned prototype models to production by automating training and prediction workflows using Apache Airflow and Kubernetes. Developed CI/CD pipelines for continuous deployment and monitoring of models. 
•Implemented and maintained end-to-end MLOps processes, ensuring seamless deployment, monitoring, and retraining of machine learning models in production environments. Utilized tools like MLflow, Kubeflow, and TFX.
•Conducted regular performance evaluations of ML models using A/B testing to measure the impact of machine learning models on key business metrics, using statistical analysis and hypothesis testing to drive data-driven decisions.",UT Arlington,MSBA,6 years,all in us,software,Pharmaceutical,California,,https://www.linkedin.com/in/sujanpanchavarthi/
,,,Data Scientist,Pfizer,"•Developed predictive models using logistic regression and machine learning to forecast patient responses, resulting in a 20% improvement in personalized treatment efficacy.
•Automated the extraction and processing of clinical data using advanced NLP techniques with NLTK, SpaCy, and IBM Watson, reducing data preprocessing time by 50%.
•Managed and analyzed large-scale healthcare datasets using Hadoop and Kafka, ensuring efficient data flow and reliable storage solutions.
•Spearheaded the adoption of Microsoft Azure Machine Learning for deploying scalable machine learning models in healthcare environments.
•Implemented topic clustering using K-Means and hierarchical clustering to optimize topic categorization, enhancing the accuracy of classification models.
•Designed and applied recurrent neural networks (single and bi-directional LSTMs, deep bi-directional LSTMs, GRUs) and auto-encoders for complex NLP tasks, utilizing transformers (BERT, ALBERT, ULMFit) for enhanced language understanding.
•Conducted genetic data analysis with PCA and time-series techniques, identifying crucial biomarkers for precision medicine initiatives.
•Communicated findings to stakeholders through detailed reports and dynamic visualizations created with Power BI. 
•Utilized convolutional neural networks (CNNs) with PyTorch for comprehensive analysis and improvement of medical imaging processes.
•Developed real-time patient monitoring systems with PySpark to analyze streaming data from IoT medical devices, significantly improving patient care responsiveness.
•Created interactive web applications using Flask and Django for data visualization and model prediction, enhancing accessibility and usability for healthcare professionals.",,,,,,,,,
,,,Machine Learning Engineer,Wayfair,"•Enhanced product recommendation engines using machine learning algorithms like K-means clustering and collaborative filtering, boosting conversion rates by 30%.
•Implemented computer vision models using deep learning for automated image tagging and classification, reducing manual categorization costs by 50%.
•Built real-time customer behaviour tracking systems using Apache Spark Streaming, facilitating personalized marketing and improved customer engagement.
•Developed predictive models for inventory management and pricing strategies using Python and R, leading to a 20% reduction in overstock costs and a 15% increase in margins.
• Leveraged big data tools like Hadoop and Apache Kafka for efficient data processing and analysis of large-scale e-commerce data.
•Established a data governance framework to ensure data integrity and compliance with industry standards, using MongoDB for NoSQL data storage solutions.
•Created dynamic user interfaces for data interaction using technologies like Flask, Django, and Spring MVC, enhancing customer and backend user experiences.
•Performed advanced analytics on customer data to drive decisions in marketing and sales strategies, using statistical methods and machine learning.
•Worked with a team to integrate machine learning models into existing e-commerce platforms, ensuring seamless user experiences and backend functionality.
•Documented and maintained detailed reports on model development, performance, and business impact, providing transparency and insights to stakeholders.
•Optimized supply chain and logistics operations using advanced simulation models and forecasting techniques, improving operational efficiency.
•Implemented front-end features using React to improve user interaction and data visualization on e-commerce platforms.",,,,,,,,,
17. Nitin Nataraj ,"English, Kannada",Yes,"Software Engineer, Machine Learning",o9 Solutions,"1. GenAI, LLMs, LLM Conversational Agents, Full Stack GenAI Engineering
2. Large scale end-to-end AutoML for time series prediction (Python, PySpark, Tensorflow, Kubernetes)",University at Buffalo,MS CS,8 years,3 years,Software,Software,"Dallas, Tx",Bangalore,https://linkedin.com/in/nitin-nataraj-aa37039b/
,,,Applied Machine Learning Intern,Calrifai,"1. Object tracking and detection - Developed a hybrid single-object tracker based on existing research that interleaved detection at regular intervals to combat the problem of tracker drift.

2. Depth sensor noise characterization - Characterized and visualized the temporal noise distributions of depth and confidence maps provided by an industry-grade depth camera. Wrote several helper scripts to obtain and store images from the camera into the appropriate format, keeping in mind the pitfalls of image compression when it comes to storing large, high quality images.

3. Visualization - Extended and modified an existing video/image visualization framework to incorporate several functionalities.",,,,,,,,,
18. Oseme Ochei,English,,Machine Learning Engineer,Freelance,"• Conducted machine learning experiments for the Fund for Alignment Research using PyTorch and Weights and Biases
• Built an end-to-end machine learning pipeline to monitor the state of shelves in Home Depot stores.
• Designed a proof assistant that semi-automatically verifies the correctness of computer programs
• Built an adaptive testing recommendation engine for nurses
• Implemented a GPU version of a CPU only computer vision library
• Built a scraper to parse equity news sites for IPO evaluations
• Wrote a lesson on using bootstrapping to compute Upside Potential Ratios",Duke University,BS CS,5 years,all in us,Freelance,software,"Dallas, Tx",,https://www.linkedin.com/in/oseme-ochei-43767894/
,,,Senior Backend Engineer,Modulate,"• Owned, researched, and improved toxicity detection scoring algorithms at Modulate, combining signals from transcription, emotion, demographics, and other models evaluating multi-participant conversations, to understand when harm is occurring, categorize it, and escalate it with the appropriate severity/confidence.
• Developed novel scoring algorithms and improved existing models to ever more accurately evaluate conversations in voice chat. Models in particular take transcriptions, emotion labels, demographic information, and other signals as inputs in order to classify conversations.
• Ensured high precision of the scoring system in complicated conversational contexts, such as uses of reclaimed language, by maintaining robust and diverse training, evaluation, and test datasets.
• Developed tools to evaluate models on representative production data, allowing Modulate to ship model updates without causing accuracy regressions to existing customers.",,,,,,,,,
,,,Software Engineer,DoltHub,"Dolt adds revision control capabilities and git semantics to SQL databases. I presided over data bounties, contests in which our community members collaborate and compete to construct large and intriguing datasets.
• Reviewed pull requests from bounty participants in our Discord community and resolved ambiguities in contest rules.
• Designed the data bounties, from the contest copy to the sql schemas, and prototyped the collection process to anticipate participant difficulties.
• Wrote programs to facilitate working with and understanding massive datasets.",,,,,,,,,
19. Nick F.,English,,Machine Learning Engineer,ValLin,"Sports Outcome Predictions.
Increased the accuracy of sports outcome predictions by 50% over seven years by employing advanced feature engineering, ensemble learning, and integrating decision trees, logistic regression, and neural networks into sophisticated models.
Reduced model training time by 35% by optimizing data preprocessing pipelines, implementing parallel processing for feature extraction, and leveraging hyperparameter tuning techniques, resulting in more efficient model development cycles.
Deployed over 25 machine learning models with 99.9% uptime using Docker and Kubernetes, enabling seamless scaling. Implemented CI/CD pipelines to streamline deployment processes, along with automated monitoring, anomaly detection, and A/B testing, ensuring continuous model reliability and operational efficiency.
Cut data processing time by 40% by automating data collection, cleaning, and preprocessing with ETL pipelines and parallel processing techniques. Utilized advanced data visualization tools for quicker insights and timely model updates, leading to enhanced decision- making.
Achieved ROI of 0.3% per investment through continuous refinement of predictive models and optimization of data processing pipelines, resulting in enhanced project profitability.
Executed multiple roles, including Machine Learning Engineer, Data Scientist, Full-Stack Developer, Founder. Developed expertise in Machine Learning, Deep Learning, Data Science and Finance leading to the creation of advanced software solutions that evolved from initial data collection to sophisticated ML applications.",Kharkiv Polytechnic Institute,MS Computer Engineering,11 years,7 years,Software,Software,"Dallas, Tx",,https://www.linkedin.com/in/nick-fomichov/
,,,Full-Stack Developer,Runweb,"Completed 6 fully-functional web projects and 1 cross-platform mobile application project successfully , delivering high-quality technical solutions on time and meeting diverse business objectives.
Managed projects from initial client acquisition and negotiations through final project implementation, support, and ongoing development. Led teams, including subcontractors, to ensure completion of specific tasks and overall project goals. Achieved results through effective negotiations, clear communication, and the timely delivery of high-quality services that met project requirements.
Gained extensive experience as a Full-Stack Engineer, Project Manager, Founder, Business Analyst, and Digital Marketer.",,,,,,,,,
20. Kush Gandhi,English,,Machine Learning Engineer,Theta Diagnostics,"• Developing a vision transformer from scratch to classify retinal OCT images for disease detection and prevention
• Benchmarking the created transformer against industry standard TensorFlow and PyTorch implementations
• Integrating a vision transformer to a streamlet app to allow clients to more easily train models on the cloud",UT Austin,BS CS,2 years,all in us,AI,AI,"Austin, Tx",,https://www.linkedin.com/in/kushgandhi1/
,,,Software engineer intern,NearbyNext,"• Implemented features using Flutter such as multi-factor authentication, social media sharing, and user notifications
• Revamped home and filter pages within the app to be more user-friendly and approachable to increase session length
• Developed bugfixes to improve usability, minimize lag by 20%, and increase accuracy of filter and search functionality",,,,,,,,,
,,,Software development intern,Paycom,"• Integrating encryption of client PII data into Paycom’s report builder service using PHP, MySQL, and ReactJS
• Delivering a product that 6,000 Paycom employees will use to create accurate and protected reports for 35,000 clients
• Implemented a preview feature that reduced query reruns by 30% thereby decreasing the database load by ~15-20%
• Developed an in-house Kanban board to organize tasks using ExpressJS, MySQL, and ReactJS resulting in increased productivity and reduced dependencies on external task management software
• Created unit tests using PHPUnit to ensure 100% code coverage for encryption, decryption, and masking functionalities",,,,,,,,,
21. Luis Magana ,English,,Machine learning engineer,Amazon,"- Implemented the use of MPI jobs for large fine tuning jobs of LLMs of 100B+ parameters on Kubeflow reducing training time linearly, and developed training guides for the science team
- Managed the release lifecycle for the MLOps platform for both the underlying infrastructure, and the applications through AWS CDK
- Developed automation and services for onboarding teams and projects ensuring ease of the platform adoption
- Developed a project template for the platform that encompassed all best practices for MLOps, reducing the amount of time it takes to onboard, train and deploy models in the platform
- Designed an MLOps platform for Customer Service Science teams integrating Kubeflow, Sagemaker, and MLFlow helping standardize the model development process across the organization",Univeristy of Illinois Urbana Champaign,MS Data Science,10 years,all in us,E commerce,cloud,"Austin, Tx",,https://www.linkedin.com/in/luis-magana-3b065a4b/
,,,Machine learning engineer,AWS,"- Worked on data intensive applications, IoT, and ML problems using AWS services and Open Source technologies for the U.S. Federal Government and Department of Defense
- Worked directly with customers to develop data models for manufacturing quality control data, helping them gather insights, detect anomalies and improve preemptive actions
- Architect and developed high throughput data pipelines using event driven architectures on the AWS ecosystem like Glue, Lambda, SQS, and Redshift, for IoT and batch data",,,,,,,,,
,,,Machine learning engineer,PWC,"- Enabled Kubeflow as a Continuous Learning Framework for AIDA (AI Driven Annotations) utilizing Argo Events and KNative Events with the capability of processing 100,000+ PDF documents daily per model. 
- Led Kubeflow Pipelines and KFServing integration with the AI-Platform in PwC Labs to drive containerization and scalability for machine learning models across the firm
- Developed an SDK to abstract the usage of data layers (ADLSGen2), and metadata layers (MLMD)
across the life-cycle of machine learning projects
- Led Airflow integrations with the AI-Platform for projects to drive batch inference, and machine
learning orchestration
- Helped with Spark on Kubernetes integration in the AI platform to replace ephemeral HDP
clusters, reduced costs, and increase containerization of big data pipelines",,,,,,,,,
22. Anthony Martinez,English,,Machine learning engineer,JPMorgan Chase & Co,"ML Model delivery as a service

My team is responsible for productionizing batch models. This involves code conversion from sas to pyspark, setting up data quality checks, Pyspark code refactoring, performance tuning, configuring data quality checks, and orchestrating the model execution on a cadence (daily/monthly) etc.",UTD,BS Software Engineering,2 years,all in us,Finance,Finance,"Plano, Tx",,https://www.linkedin.com/in/anthony-martinez-jpmc/
,,,Software engineer intern,JPMorgan Chase & Co,"- Continuation of Summer 2022 internship focusing on MLOps
- Created AWS Lambda Function that reads in survey data from a pre-existing Lambda function and writes to AWS Dynamo Database
- Implemented AWS Lambda function ability to detect when a new survey data file lands in an AWS S3 bucket",,,,,,,,,
23. Nicholas Crothers,English,,Machine Learning engineer,CAE USA,"• Key player in the design and core implementation of a scalable autonomous agent platform running in Kubernetes. Implemented several of the key components in Rust and the Kubernetes architecture. 
• Leveraging and training state-of-the-art text-to-speech and automatic speech recognition deep learning models for problems with domain-specific language
• Key player in the creation of code/MLops standards for the Data Science/Data Engineering team
• Created and improved a data processing pipeline to prepare batches of 100+ GB of geospatial data for ML training
• Wrote several Rust applications/components that use inter-thread communication and networking communication over UDP and TCP",Southern Methodist University,MS CS,2 years,all in us,Defence,Software,"Irving, Tx",,https://www.linkedin.com/in/nicholas-c-crothers/
,,,Software development intern,Harmonic software production studios,"• Developed software as a full-stack developer, primarily using PHP, HTML, and JavaScript
• Contributed to software used internally within the company, primarily hands off
• Collaborated with other developers to develop software used in production by Harmonic’s customers
• Experienced coding principles and workflow used in production environments",,,,,,,,,
24. Fred Ware,English,,Senior Machine Learning Engineer,Apira Technologies,"Executed product development and testing tasks between user experience, graphics, and pipeline teams for product releases.
Researched and updated the synthetic facial dataset generation tool, with different StyleGAN models implemented in PyTorch that generated realistic facial images.
Trained efficient convolutional neural networks (CNNs) with feature pyramid network (FPN) models using Tensorflow for dense facial landmark detection on live camera.
Created and prepared video frame datasets for unsupervise training using supervision-by-registration, an optical flow technique.
Trained neural networks models using supervision-by-registration, to further enhance facial landmark detection in video data.
Performed fine-tuning and testing of internal parameters of end-to-end 3D facial processing pipeline.
Implemented low-level metrics throughout the end-to-end 3D facial processing pipeline.
Executed dataset generation and model training using Docker containers.
Managed reports of model training jobs in MLFlow, Tensorboard, and Weight & Biases. Saved all datasets and trained model content in AWS S3 buckets.
Refined a computer vision gaze detection algorithm for improving 3D eye tracking.
Restructured mesh fitting algorithm for offline generation of shape identity coefficients.
Implemented computer vision and deep learning tools to visually analyze the intermediate results.",Texas A&M ,PHD ,10 years,all in us,Software,Software,"Carollton, Tx",,https://www.linkedin.com/in/fred-w-ware/
25. Chuanliang Jiang,English,,Machine learning engineer lead,JPMorgan Chase & Co,"(1) Adapted and fine-tuned state-of-the-art open-source Large Language Models (Longformer, LLAMA2, Mistral) for a corporate email dataset to efficiently extract negative sentiments from client communications. This initiative involved optimizing model parameters to significantly enhance sentiment analysis accuracy within a specialized domain

(2) Engineered a cutting-edge Retrieval-Augmented Generation (RAG) system leveraging LangChain and Llama-Index technologies, designed to pinpoint and extract negative sentiments from client emails. This development combines the strengths of retrieval and generative models for improved accuracy and relevance in sentiment extraction.

(3) Expertly containerized sophisticated Large Language Models for seamless deployment on Amazon AWS, prioritizing scalability and robustness in production settings. Spearheaded the development of an automated model monitoring framework to diligently track performance metrics, facilitating ongoing accuracy and model integrity over time

(4) Directed a machine learning team in developing AI-driven solutions focused on enhancing the global client experience. This initiative involved identifying key business challenges and deploying advanced machine learning strategies to improve customer interactions and satisfaction on a worldwide scale",Boston College,PHD ,11 years,all in us,Finance,Software,"Plano, Tx",,https://www.linkedin.com/in/chuanliang-jiang-ph-d-290a5b49/
,,,Lead Data Scientist,Mobi Systems,"(1) Develop session-based recommendation systems using graph neural network/reinforcement learning to predict e-commence customer purchase for next basket/items

(2) Lead the project to develop different transformer-based NLP model (zero-shot, few-shot prompt based learning) to detect customers sentiment and churn decision from business unstructured text data

(3) Generate text(completed sentences or paragraph from a few keyword, text summarization) using pretrained model to meet business' requirement

(4) Develop various decision tree based model (catboost, lightboost, xgboost) from tabular formatted structure data to predict client retention rate",,,,,,,,,
,,,Lead Data Scientist,USAA,"Develop cut-edge graph neural networks models for the recommendation system of USAA insurance and bank products. Introduce Graph Neural Networks to address various business problems

Develop a wide range of NLP models for long-length document classification in sentiment analysis, information extraction and text generation (summarization, question answering and chatbot)

Design a non-linear classification algorithms such as XGBoosting, CatBoosting or other desicision-tree based to advance business rules

Mentor Junior/Senior Data Scientists and provide guidance for their model development efforts

Publication: Quantile Aggregation and Combination for Stock Return Prediction. Econometrics Review Jun 2020",,,,,,,,,
26. Yasser T.,English,,Machine learning engineer,KinYu Consulting,AI and machine learning applied to data migration to detect patterns in multinational accounting data; devising accelerated GPU processing features using CUDA to augment deep learning libraries.,UCLA,PHD,11 years,all in us,Consulting,Software,"Dallas, Tx",,https://www.linkedin.com/in/yasser-taima/
,,,"Senior software engineer, machine learning",AerialSphere,"Researched, developed and rolled into production a deep-learning CNN solution to an image registration problem on terabytes of aerial imagery data. Used Pytorch, multithreading and CUDA on large GPUs. Achieved state-of-art results on a novel application, and a 3,000-fold performance improvement on an already mathematically intensive semi-automated solution, drastically reducing processing time and scaling up to full automation.",,,,,,,,,
,,,Machine Learning,At Stealth,"Object recognition and prediction into the future from logs of raw lidar, camera, and radar data into a perception system using traffic movement with annotated semantic maps detailing road geometry, aerial map, crosswalks, and traffic light states. Built a deep learning stack on a large data set of lidar and camera images (100s GB) for object recognition and prediction using Python, PyTorch, C++, and Linux GPU machines on Google Cloud Platform. The system achieved several seconds of motion prediction into the future with high accuracy.",,,,,,,,,
27. Amanda Sutrisno,English,,Machine learning engineer,Lighthouse title insurance company,"- Develops natural language A.I models(LLMs) to extract information from and sort legal documents related to real estate.
- Develops sentence similarity transformer models to compare and group matching legal descriptions of properties, regardless of paraphrasing, and implements a semantic search of properties by legal description using a vector database.
- Responsible for sourcing, cleaning, and developing semi-supervised/unsupervised learning algorithms to obtain training data and minimize manual labeling costs.
- Deploys A.I models and searchable legal document databases on amazon web services.
- Implements error-correction algorithms to detect breaks in a housing title-chain to automatically detect and flag misclassified documents for human correction.",Vanderbilt University,MS Mechanical Engineering,3 years,1 year,Insurance,Education,"Grapevine, Tx",,https://www.linkedin.com/in/amanda-sutrisno-156308126/
28. Vijaya Maguluri,"English, Tamil",Yes,Principal Machine Learning Engineer,CoreLogiv,"Worked in collabration with engineering and data science team to manifest best and cost-effective solutions across the board under data platform for large-scale unstructured data in US Real Estate Economy.
Automated and led solutions for complex OCR and NLP problems in data extraction from large volumes of unstructured texts, images, and video
Actively worked on developing and automating structured solutions to ambiguous problems with cloud-native technologies
Proactively deployed machine learning models with fine-tuning models for performance, reliability, scalability, and accuracy as part of MLOps
Worked on end-to-end classification pipeline for building in-house solutions using GCP AutomL and custom code, generated metrics with precision, recall, and f1 scores
Trained NLP models using GCP and Vertex AI Auto ML to extract specific business data types which leverage transfer learning to work across all document types
Built ensemble classification models that identify keyable and non-keyable document types and compare accuracies with confusion matrix for Tile-based model with string similarity and Full content-based NLP model
Performed various experiments and tests such as Index fields extraction test for Entity Extraction based on AutoML models, metrics calculations for document number, book number, page number, and recording date
Document title extraction test for doc title, Keyable or non-keyable classification test, and Document Type manifest test such as deed category, keyable, nonkeyables
Hands-on development using python (NUMPY, SCIPY, MATPLOTLIB, PANDAS, SCIKIT-LEARN)
Strong in developing solutions using python focused on data science (NUMPY, SCIPY, MATPLOTLIB, PANDAS, SCIKIT-LEARN, SCIKIT-IMAGE, OpenCV)
Experience in developing deep learning models using PyTorch and TensorFlow, especially with OCR and NLP unstructured data",,,16 uears,10 years,Finance,Healthcare,"Irving, Tx",,https://www.linkedin.com/in/vijaya-maguluri-1170b6222/
,,,Senior Data Scientist/ML engineer,Change Healthcare,"Developed classification models to predict the likelihood of customer churn based on customer attributes like customer size, revenue, type of industry, competitor products and growth rates etc. The models deployed in the production environment helped detect churn in advance and aided sales/marketing.
Performed Data wrangling to clean, transform and reshape the data utilizing Numpy and Pandas library.
We have worked with data-sets of varying degrees of size and complexity including both structured and unstructured data and Participated in all phases of Data mining, Data cleaning, Data collection, variable selection, feature engineering, developing models, Validation, Visualization and Performed Gap analysis. 
Developed predictive models on large scale datasets to address various business problems through leveraging advanced statistical modeling, machine learning and deep learning.
Perfectly Utilized machine learning algorithms such as clustering, linear regression, multivariate regression, Naive Bayes, Random Forests, K-means, & KNN for data analysis.
Extensively used Pandas, NumPy, Seaborn, Matplotlib, Scikit-learn, SciPy, NLTK in Python for developing various machine learning algorithms.
Researched extensively on the nature of the customers and designed multiple models to perfectly fit the necessity of the client and Performed Extensive Behavioral modeling and Customer Segmentation to discover behavior patterns of customers by using K-means Clustering.
Designed and implemented a Recommendation system that leveraged Google Analytics data and the machine learning models and utilized Collaborative filtering techniques to recommend products for different customers.
Reinforced the model Performance parameter optimization using Grid search and metric evaluation via regression (RMSE, R2, MSE etc.), classification (Accuracy, precision, recall etc.), threshold calculations",,,,,,,,,
,,,Senior Data Scientist/ML engineer,RailCar Rx,"Championed in analyzing end-user requirements and preparing the data to facilitate analysis(ETL).
Collected data from Informatica warehouse, build a pipeline to get the required data and performed transformations like aggregating different sources, filtering data and mapping to target database.
Developed PySpark modules for machine learning & predictive analytics using HDFS stored data.
Performed data pre-processing, normalization, feature scaling, removed duplicate rows, outliers, aggregated tables and stored in Pandas Dataframes.
Analyzed data using SQL, Python, R, Scala, Apache Spark and presented analytical reports to technical teams.
Built a text classification model using classical machine learning models such as Logistic regression, SVM, KNN, Random Forest, Ensemble methods and deep learning methods like CNN, RNN, LSTM on the dataset for sentiment analysis
Segmented the customers based on demographics using K-means Clustering.
Python, as well as R, are used for programming and constant improvement of the model.
Used cross-validation to test the model with different batches of data, tuned the parameters to find the best parameters for the model and optimized, which eventually boosted the performance.
Designed visualizations using Tableau that drove performance and provide insights.
Used data quality validation techniques to validate the data and identified many anomalies.
Performed K-means clustering to identify outliers and classify unlabeled data.
Worked with sales and marketing team to collaborate and frame the problem, answer important data questions, prototyping and experimenting ML/DL algorithms on the available data and finally integrating into a production system for different business needs.
Worked with Amazon Web Services (EC2/S3) cloud services to do machine learning on big data and integrate with visualization (Tableau) for designing dashboards.",,,,,,,,,
29. Naresh Dhaubanjar,English,,Machine learning engineer,Logix Consulting,"• Developed real-time machine learning predictive models on big data platforms within healthcare industry.
• Built machine learning and statistical predictive models and analytics solutions for fortune 500 companies. 
• Developed business data models and perform data analysis activities to identify relational data issues.
• Lead reliability model developer. Project involved data collection, reliability data analysis, and statistical model generation. 
• Built reliability model simulation database using Python and created web application using Python CGI to store, analyze and visualize models.
• Responsible for full-process software development on a variety of projects involving multiple coding and scripting languages like C, C++, Java, Python, R etc",Georgia Institute of Technology,MS CS,17 years,all in us,Consulting,Consulting,"Irving, Tx",,https://www.linkedin.com/in/naresh-dhaubanjar-85632517/
,,,Spice Modeling Engineer,Logix Consulting,"• Spice modeling and analysis of CMOS transistors for 28nm-120nm technology nodes and maintained these technology models by working in collaboration with process integration team and Advanced CMOS Development team at Texas Instruments Inc. 
• Extracted model parameters of high performance analog/digital CMOS, LDMOS, DEMOS, and DIODE used in Advanced CMOS Technology and Mixed Signal Technology Development. 
• Generated Statistical, Mismatch, Corner and EOL model. 
• Performed quality assurance, documentation and publication of the extracted model for high  performance IC for wireless (OMAP), embedded processors, embedded FLASH, analog and  RF applications. Supported with software development, electronic design automation and data analysis. 
• Performed MOSFET Reliability model analysis and modeling of degradation mechanisms such as Hot  Carrier Injection (HCI) and Negative Bias Temperature Instability (NBTI). 
• Maintained Texas Instruments Inc internal Reliability model and ProPlus Reliability  models. 
• Project Lead:  1. Developed BTI/HCI reliability model extraction flow based on RelXpert User Reliability Interface (URI). Reduced cycle time and cost by 70%. 2. Developed QC flow to QC the internal Reliability model. QC flow reduced the cycle time and cost by 50%. ",,,,,,,,,
30. Chandan Kumar Parida,"English, Hindi",Yes,Machine learning engineer,UnitedHealth,"Design Machine Learning Models for Provider De-Duplication Process
Develop the Machine Learning Model to de-duplicate the Providers from different sources.
Review the current process, model and implement an efficient solutions.
Prepare the Data Pipe Line to consume and cleanse the data from various source systems and define the rules for Provider Integration Process.
Stream line the ETL Process using Spark , Python and Azure Data Bricks",ICFAI University,MS Computer Application,20 year,12 year,Health,Telecommunication,"Mckinney, Tx",Pune,https://www.linkedin.com/in/chandankumarp/
,,,Machine learning engineer,Viacom,"Movie and Series Emotional Arc Clustering and Recommendation
• Download and Gather the Movie and Series Data from OMDB and WikiData subtitles.
• Cleanse and validate the Movie and Series Data using the Python Scripts.
• Used the Window Sliding and Fixed Length chunking Strategy to break the Movie, Episodes, Season and Series script into multiple chunks.
• Derive the Sentimental score of Movies, Episodes, Seasons and Series using LABMT, Frequency vector and Natural Language Processing.
• Plot and Display the Sentimental score or the shape of Movie/Series (Vonnegut Curve) of using MATPLOT. 
• Used Unsupervised Learning to cluster the Movies and Series based on the sentimental score. 
• Used Hierarchical (Agglomerative Clustering) to cluster Movies and Series.
• Used K-Means Clustering to cluster Movies and Series.
• Used Singular Value Decomposition (SVD) as cluster and PCA for the Movies and Series.
• Create Eight different clusters based on Movie, Episodes, Season and Series and display them.
• Find out the underline cluster based on the Movie name.
• Find the top twenty close Movies of a cluster based on the COSIN and Euclidean Distance. 
• Find the top twenty Movies in a cluster based on the Movie reviews.
• Recommend the top twenty Movies based on the combination of the reviews and distance.
• Use Google Open-Refine tool to refine the Movies, Episodes, Seasons and Series Data.",,,,,,,,,
,,,Data Scientist,Florida Insurance ,"• Gather data from various sources like MongoDB, SQL Server and Oracle for analysis.
• Integrate data being collected from various sources using python.
• Processing, cleansing, and verifying the integrity of data used for analysis
• Analysis of the data using python libraries and find the significant patterns and display them using Sea Born 
and Plotly.
• Worked on Natural Language Processing (NLP) to convert the Audio data to Text data.
• Worked on Natural Language Processing (NLP) to convert the Microphone/Speech Data to Text data.
• Worked on Sentimental Analysis using the technologies like Vader, NLTK and ELMO.
• Worked on Transfer Learning to use the predefined model to train on low volume of data using Deep Learning.
• Used Keras to train a model for finding the Sentimental Score of a Speech to text Data.
• Build the model using the LSTM and Recurrent Neural Networks.",,,,,,,,,
31. Venkat Mohan,English,,Senior Machine Learning Engineer,Travelport,"• Communicated and coordinated with other departments to gather business requirements.
• Implemented Machine Learning, Computer Vision, Deep Learning and Neural Networks algorithms using TensorFlow and designed Prediction Model using Data Mining Techniques with help of Python, and Libraries like NumPy, SciPy, Matplotlib, Pandas, scikit-learn.
• Construct the AWS data pipelines using VPC, EC2, S3, Auto Scaling Groups (ASG), EBS, Snowflake, IAM, CloudFormation, Route 53, CloudWatch, Cloud Front, CloudTrail.
• Designed rich data visualizations of outputs of different predictive models into human-readable form with Tableau and Matplotlib
• Used pandas, NumPy, Seaborn, SciPy, matplotlib, sci-kit-learn, NLTK in Python for developing various machine learning algorithms.
• Design and construct of AWS Data pipelines using various resources in AWS including AWS API Gateway to receives response from aws lambda and retrieve data from snowflake using lambda function and convert the response into Json format using Database as Snow Flake, DynamoDB, AWS Lambda function and AWS S3.
• Data preprocessing which includes checking missing values, unnecessary columns and aggregating sales by date was carried out using NumPy and Pandas libraries. 
• Developed web application using python, Django framework, MySQL
• Participated in feature engineering such as performing step regression in selecting features, feature normalization and label encoding with Scikit-learn preprocessing.
• Experimented and built predictive models such as Linear Regression, AR, MA, ARMA, and ARIMA to predict sales amount using Scikit-learn and Stats-model library. 
• Comparing forecast for products of two different categories through time series plots and finding insights by analyzing sales pattern of different products.
• Explored and visualized the data to get descriptive statistics and inferential statistics for better understanding the dataset.",University of the Cumberlands,PHD,4 years,all in us,travel,fintech,"Irving, Tx",,https://www.linkedin.com/in/venkat-mohan-059897241/
,,,machine learning engineer,Broadridge,"• Performed Data Cleaning, Data Exploration, Data Visualization, Feature Selection, and Engineering using Python libraries such as Pandas, Numpy, Sklearn, Matplotlib, and Seaborn.
• Analyzing People Bought things together (Rules and Frequent Item-sets), Popularity model, and Cluster algorithms to assign the user to the segment containing the most similar customers. It then uses the purchases data of the customers in the segment to generate recommendations.
• Using the K-means algorithm to find the customer clusters. customer clusters capturing the affinities among customers and form potential customer and reliable user neighborhood customers. Based on the metrics and the user clusters, then uses a collaborative filtering approach to find the relationship among items for each cluster.
• Utilized Spark, Scala, Hadoop, HQL, VQL, oozie, pySpark, Data Lake, TensorFlow, HBase, Cassandra, Redshift, Mongo DB, Kafka, Kinesis, Spark Streaming, Edward, CUDA, MLLib, AWS, Python, a broad variety of machine learning methods including classifications, regressions, dimensionally reduction etc.
• Performing and finding insights into user-based similarities, item-based similarities, the popularity of the products, association rules, and patterns of frequent items set buying by customers.
• Developing strategies by gaining insight into which items are frequently purchased together by customers using Association rules mining 
• Worked on various machine learning algorithms like Linear regression, logistic regression, Decision trees, random forests, K- means clustering, Support vector machines, XGBoosting on client requirements.
• Application of various machine learning algorithms and statistical modeling like decision trees, text analytics, natural language processing (NLP), supervised and unsupervised, regression models, social network analysis, neural networks, deep learning, SVM, clustering to identify Volume using scikit-learn package in python, Mat lab.",,,,,,,,,
32. Vishnu Reddy,"English, Tamil",Yes,Machine learning engineer,"Raven Software Solutions Inc,","Project: StreamIT – Subscription-based mobile application offering on-demand video streaming services.
• Led end-to-end pipelines using Pandas and Scikit-learn to process 500TB+ of ""StreamIT"" data, effectively identifying anomalies and enhancing content recommendation logic. 
• Developed a deep learning recommendation algorithm using TensorFlow, Keras, and LSTM networks, resulting in a 30% boost in user engagement and aligning business requirements. 
• Deployed and maintained machine learning models on both AWS and Azure cloud platforms, utilizing Docker and Kubernetes for seamless scalability and integration. 
• Employed neural networks and advanced machine learning algorithms for predictive content analytics, anticipating user preferences and ensuring timely content delivery. 
• Implemented LLM-based profiling on 'StreamIT' to optimize content recommendations, resulting in a 25% increase in user content interactions.
• Designed and implemented computer vision algorithms to automate content categorization, elevating the platform's ability to filter and suggest relevant content. 
• Collaborated cross-functionally to ensure that the platform's technical advancements aligned perfectly with business requirements, guaranteeing that ""StreamIT"" met both market demands and internal strategic goals.",University of North Texas,MS CS,4 years,3 years,Software,Engineering services,"Denton, Tx",Chennai,https://www.linkedin.com/in/vishnu-reddy-924589286/
,,,Data Scientist ,KPIT,"roject: ""DeepChurn Insights: Predictive Analysis of Customer Subscription Retention and providing business insights""
• Built efficient data processing pipelines using Python, Hive, and PySpark, processing and analyzing over 1.1M+ customer interactions to extract actionable insights for churn reduction.
• Accelerated development cycles and improved code reliability, resulting in a 15% increase in release delivery speed. 
• Leveraged classification, DNN, and multi-task learning algorithms using TensorFlow and Scikit-Learn to predict customer churn, achieving an accuracy rate of 93% on test data. 
• Orchestrated a CI/CD pipeline using Ansible for streamlined model deployment. Containerized the prediction models using Docker and managed scalable deployment with both Kubernetes and Docker Swarm.
• Utilized AWS Services such as S3 for scalable data storage, Lambda for real-time data processing, and Elastic Search for advanced data analytics. Monitored the system's performance and health using CloudTrail, CloudWatch, and Kibana.
• Automated system configurations and ensured best practices using Chef. Maintained infrastructure-as-code standards using Terraform in YAML scripts, ensuring reproducibility and efficient scalability.",,,,,,,,,
33. Revathi Lalam,"English, Telugu",Yes,Machine learning engineer,Expedia ,"Seasoned machine learning engineer specializing in implementing advanced algorithms such as gradient boosting machines (GBM), neural networks, and natural language processing (NLP) techniques like word embeddings and transformers. Proficient in designing and deploying search relevance models using techniques such as Elasticsearch, ranking algorithms (like BM25), and learning to rank methods. Skilled in developing generative AI models, leveraging architectures like GPT (Generative Pre-trained Transformer) for text generation and understanding",Andhra univerisity,BS EEE,8 years,6 years,travel,software,"Irving, Tx",Chennai,https://www.linkedin.com/in/revathi-lalam-5b66961b5/
,,,Machine learning engineer,Ascendion,"""Experienced machine learning engineer skilled in developing and deploying cutting-edge algorithms and models to solve complex problems. Proficient in various machine learning frameworks and tools, with a strong background in data analysis, feature engineering, and model optimization. Collaborative team player adept at translating business needs into scalable machine learning solutions.""",,,,,,,,,
,,,Machine learning engineer,USAA,"Operationalise machine learning models for Health & Life Insurance including automation.
development and deployment of models, processes for ongoing monitoring and validation.
Productionalize machine learning models in greater scale and more faster using DevOps, Microservices,
Dockers, Airflow , Red hat OpenShift Containers , Kubernetes , Karate , Grafana, Prometheus.
Developed projects utilizing NLP, Python, TensorFlow, AWS and Domino to improve customer experience.
Applied EDA on large data to identify risks using tools including Hadoop,PySpark & Hive.
Supported ELT processes with DataStage, Control-M and other tools.
Assembled data sets and built and maintained analytical tools to meet business needs.
Built Tableau dashboards, automated reporting and ad hoc analysis to support strategic
planning and product growth.",,,,,,,,,
34. Priya E. ,"English, Hindi",Yes,Senior Machine Learning Engineer,Ford Motor Company,"• Analyzed, classified the documents developed the project and deployed it to create a n application namely smart- document-capture to extract the required attributes from document
• Trained Faster R-CNN model using TensorFlow for object detection to extract targeted attribute
• Spacy models were trained as a backup for machine learning ones
• Developed rest APIs using Django rest API framework and customized middleware’s.
• Designed and created MSSQL database to store relevant data for successful implementation of the project
• Deployed the project to production and hosted it in Microsoft azure platform
• Used Pandas, NumPy, Seaborn, SciPy, Matplotlib, Scikit-learn, and NLTK in Python for developing various machine learning algorithms.",Univerisyt of North Texas,MS AI,9 years,7 years,Automobile,Finance,"Carrollton, Tx",Anantpur,https://www.linkedin.com/in/priya1993/
,,,Senior machine Learning Engineer,ABN AMRO Bank ,"• Analyzed, classified the documents developed the project and deployed it to create a n application namely smart- document-capture to extract the required attributes from document
• Performed data analysis on over 200+ bank templates on 3500+ documents and recorded the observations that further helped in the classification of documents using the Machine Learning model
• Trained Faster R-CNN model using TensorFlow for object detection to extract targeted attribute
• Trained Machine learning models using Random Forest classifier, Linear regression & SVM classifier Natural language processing techniques like lemmatization, stemming and tokenization were used to convert the text into a structured form
• Spacy models were trained as a backup for machine learning ones",,,,,,,,,
,,,Senior machine Learning Engineer,Centene Corporation,"• Responsible for analyzing large data sets to develop multiple custom models and algorithms to drive innovative business solutions.
• Perform preliminary data analysis and handle anomalies such as missing, duplicates, outliers, and imputed irrelevant data.
• Remove outliers using Proximity Distance and Density based techniques. 
• Involved in Analysis, Design and Implementation/translation of Business User requirements.
• Experienced in using supervised, unsupervised and regression techniques in building models.
• Developed application to automatically extract address from postal cards",,,,,,,,,
35. Wyatt P.,English,,Lead machine learning engineer,Charles Schwab,"Technical Lead for Capacity Planning models, 
Developed Probabilistic Machine Learning models for time series predictions and anomaly detection
Built Causal Inference Networks from do-calculus, Identified top influencers through partial derivative correlations
Developed Prescriptive Optimizations",University of Connecticut,Chemical Engineering,8 years,all in us,Finance,Mining,"Carrollton, Tx",,https://www.linkedin.com/in/wyatt-p/
,,,Data Scientist II,Freeport-McMoRan,"Develop machine learning models for chemical reagent identification in hydrometallurgy; 
Global Bayesian Optimizaiton, Semi-Supervised Conditional Variational Autoencoder, Hierarchical Clustering, Advanced Algorithms, Probabilistic Graphical Models",,,,,,,,,
36. Aaja Kallungal,"English, Malyalam",,Machine learning engineer,Mr. Cooper,"As a Machine Learning Engineer in Mr. Cooper, I excel in deploying SQL, Python, R and SAS to build and enhance predictive and prescriptive models, leveraging a comprehensive toolkit to transform data into actionable insights. My expertise includes leveraging cutting-edge Generative AI technologies such as Text Bison, Gemini Pro, and Azure Open AI, along with GCP tools like Vertex AI, BigQuery, and Looker Studio, to transform data into actionable insights. Skilled in data mining with proficiency in Python libraries, I contribute to daily operations through Azure DevOps, ensuring agile project progression. My responsibilities also encompass generating creative and novel ideas in prompt engineering and tuning. Furthermore, my role involves creating comprehensive documentation, delivering impactful presentations, and designing interactive dashboards to drive data-driven decision-making.",UTD,MSBA,2 year,all in us,Finance,Finance,"Dalla, Tx",Kerala,https://www.linkedin.com/in/aaja-kallungal/
,,,machine learning engineer intern,Mr. Cooper,"As an intern, I engaged in projects handling extensive datasets with GCP tools like Vertex AI and BigQuery, concentrating on feature engineering and data transformations for machine learning and NLP applications. This role allowed me to develop sophisticated models, transforming intricate data into clear insights, and demonstrated my adeptness at harnessing advanced analytics and cloud technologies.",,,,,,,,,
37. Prashanth Ramavath,"English, telugu",Yes,Machine learning engineer,WeWork,"Use AI to optimize workspace layouts based on usage patterns, implement predictive maintenance, enhance energy management, provide personalized member experiences, and streamline operational processes like billing and security. These AI-driven solutions can significantly improve efficiency, member satisfaction, and overall business performance.",,,7 years,5 years,Officespace,Software,"Dallas, Tx",Hyderabad,https://www.linkedin.com/in/prashanth-ramavath-34b867265/
,,,Machine learning engineer,CSX Technology,"Provide operational processes using AI such as enhance freight scheduling efficiency, predictive maintenance of tracks and equipment, real-time tracking and monitoring of shipments, and optimizing network management for better logistical solutions.",,,,,,,,,
38. Harrison Foster,English,,Senior AI ML Engineer,Lockheed Martin,"- Lead a team comprised of AI/ML and software engineers to develop, integrate, and test a large machine learning project running in a microservice architecture.
- Performed research on weak-supervised learning that culminated in a conference paper for the American Institute of Aeronautics and Astronautics (AIAA) SciTech conference.",Texas A&M,BS CS,5 years,all in us,Defense Tech,Defense tech,"Forth Worth, Tx",,https://www.linkedin.com/in/harrisonfoster/
,,,AI ML Engineer,Lockheed Martin,"- Wrote and productionized a large complex convolutional neural network and created experimental prototypes of other architectures including LSTMs and other CNNs.
- Individually designed and built several sophisticated machine learning tools including a hyperparameter tuning infrastructure, a domain specific language, and more.
- Helped design and implement a variety of machine learning applications including data pipelines, anomaly detection prototypes, APIs, a front-end GUI, and much more.
- Lead quarterly planning meetings by helping to break down large tasks into manageable tasks.
- Implemented cutting-edge algorithms in the field of machine learning by staying informed on the latest ideas from the scientific literature.",,,,,,,,,
39. Usman I.,"English, Urdu",,Senior machine Learning Engineer,Verizon,"As a Machine Learning Engineer at BlueJeans, I contributed to the Version BlueJeans project, delivering advanced AI solutions for video conferencing. This included real-time behavior analysis, voice-to-text translation, and speaker confidence assessment. My role encompassed a technical stack featuring TensorFlow and PyTorch for deep learning, NLP for multilingual communication, and computer vision for engagement insights. I also optimized audio quality and integrated WebRTC for seamless transmission. This project highlights my expertise in enhancing video conferencing with AI-driven solutions.

• Engineered end-to-end solutions with TensorFlow, Keras, and Mxnet, integrating monitoring and automated testing tools.
• Designed and managed MLOps pipelines with Kubernetes (EKS), Airflow, Kubeflow, and MLFlow for seamless model deployment.
• Conducted rigorous model and data evaluations using Pandas, Numpy, Scikit-learn, and NLTK for optimal accuracy and quality.
• Integrated Kafka, Cassandra, and Spark for real-time data processing and scalable analytics.
• Collaborated with application development teams to enhance applications through AI/ML integration, utilizing APIs, Git, and Jira.
• Led core platform component creation and deployment on Azure, GCP, Hadoop, and Kubernetes (EKS) for robust solutions.
• Proficiently navigated Verizon BlueJeans' Adtech tech stack, incorporating tools such as Google Ad Manager and AdSense to maximize ad inventory monetization and ad targeting precision
• Led the integration and fine-tuning of Adtech technologies, including header bidding and data management platforms, to optimize ad delivery and revenue generation within Verizon BlueJeans' video conferencing software.
• Evaluated and incorporated emerging technologies, including Fiddler, DataRobot, Amazon Sagemaker, GoogleAI, and OctoML, to enhance model development processes.",Lahore University of Management Sciences,"MEng, Cs",14 year,4 year,Telecom,retail,"New York, Ny",,https://www.linkedin.com/in/usman-aie/
,,,Data Scientist,Foot Locker,"Our project focused on enhancing retail operations through data science, utilizing TensorFlow and machine learning to understand and segment retail regions for tailored marketing and stocking strategies. We predicted optimal pricing and promotion tactics, improving revenue and customer engagement. Real-time data processing tools, including Kafka, Cassandra, and Spark, were used to optimize local store warehouses for efficient inventory management, enhancing supply chain operations.

- Engineered end-to-end solutions utilizing advanced algorithms and the power of TensorFlow, Keras, and Mxnet, supported by essential tooling for monitoring, logging, automated testing, and performance assessment.
- Innovatively designed and orchestrated Machine Learning Operations (MLOps) pipelines, seamlessly deploying models using Kubernetes (EKS) and managing the process with Airflow, Kubeflow, and MLFlow.
- Proficiently leveraged Adtech solutions such as Google Ad Manager and DoubleClick for Publishers to maximize advertising effectiveness within Footlocker's e- commerce platform
 2
- Managed the implementation and fine-tuning of Adtech tools like AdWords and programmatic advertising platforms to achieve superior ad performance in Footlocker's online retail environmentProficiently integrated a diverse technology stack, including Kafka, Cassandra, and Spark, to enable real-time data processing and scalable analytics.
- Led the creation and deployment of core platform components, leveraging the capabilities of Azure, GCP, Hadoop, and Kubernetes (EKS) for robust and scalable solutions.
- Leveraged the power of Tableau, RapidMiner, KNIME, and Power BI to create insightful visualizations that enhanced data-driven decision-making processes.
- Championed the adoption of advanced analytics and ML technologies such as XGBoost, Caffe, PyTorch, and H2O, elevating the sophistication of model development.",,,,,,,,,
40. Martin Lawler,English,,"AI ML Engineer Sr,",Lockheed Martin,"As an Artificial Intelligence and Machine Learning Engineer Sr I am responsible for continued development of the internal program, that I began, that investigates improving low-fidelity Reynolds Averaged Navier Stokes (RANS)by using Machine Learning. The bulk of this work is handled in a custom self-written and ADP-endorsed code base that utilizes ANY PyTorch or SciKit Learn model designed for tabular data. In this role I have presented to internal customers and programs as well as customers across the DoD landscape. 

I am also responsible for F-35-centric classification models. This work gives me a large exposure to complex and unknown data and therefore I use the same code base that is mentioned above to trial various models and test feasibility/accuracy/fit, etc. This role has given me experience across various PyTorch and SciKit Learn models purely from a ""try it"" perspective which has enabled me to get deeper into Machine Learning metrics, analysis, and ""looking under the hood"" to see why a specific model is doing what it's doing.

This role has taught me that it's not good enough to be good at coding... an engineer must also be good at selling and maintaining the software they write so that it can be leveraged across the enterprise for others to benefit from",Texas State Univeristy,BS Physcis,6 years,all in us,Defence Tech,Defence Tech,"Fort Worth, Tx",,https://www.linkedin.com/in/martinjlawler/
,,,AI ML Engineer,Lockheed Martin,"As an Artificial Intelligence and Machine Learning Engineer I was responsible for investigating and developing a method to predict turbulence closure modeling with data-driven techniques. I employed a PyTorch framework to allow for a Feed Forward Neural Network with engineered features and engineered intermediate features to help guide/correct the supervised model toward customer-ready results in less than a year. This kicked off a brand new internal program that continues, as of writing this, that shows promise for using machine learning to improve low fidelity Reynolds-Averaged Navier Stokes (RANS) simulations.",,,,,,,,,


Name,Languages spoken,Indian experience,Role,Company,job description,University,Course,Work experience,Work experience in the U.S,Industry,Previous industry type,Location,Location from India,
1. Snehith Varma Datla,"English, Hindi",,Data Science Intern,The Hanover Insurance Company,"• My recent internship at Hanover Insurance has been a cornerstone in my academic and professional journey. There, I led a significant project focusing on topic analysis of agent feedback data, applying my expertise in NLP and utilizing cutting-edge pre-trained models from Hugging Face.
• My role involved developing a custom model using TF-IDF vectorization and Cosine Similarity, transforming complex data sets into coherent, actionable insights. This work not only enhanced operational efficiency but also played a key role in decision-making processes across various business units.
• A highlight of my tenure was the recognition of our team's excellence, winning the best Graduate Qualifying Project (GQP) team award. Additionally, being honored as the Most Valuable Player (MVP) of our team was a testament to my commitment and the impact of my contributions.",Worchester Polytech Institute,"Master of Science, MS, Data Science",1 Year 1 Month,10 Months,Insurance,Professional Coaching and Teaching,"Boston, Massachusets, United States",,
2. Venkata Naga Sai Kumar Bysani,"English, Kannada",,Data Science Consultant,The Lego Group,"• Implemented an XG Boost Model to predict sales, streamline supply chain, and enhance inventory planning, and achieved 93% R-squared rate, in collaboration with 4 team members.
• Designed and developed a model using RNN and CNN to forecast annual sales by incorporating external factors with 6% error for Sep 2022.
• Created dashboards with Tableau recognized a decrease in sales of kids' products by 13%, signaling a market shift towards adult products.
• Recognized growth opportunities by analyzing sales data, comprising of 1.3 million transactions, via advanced SQL queries and hypothesis testing methods (t-tests and ANOVA).",Unversity of Connecticut,"Masters, Business Analytics and Project Management",2 Years 6 Months,2 Years 3 Months,Manufacturing,Insurance,"Columbia, South Carolina, United States",,
3. Viraj Thakkar,"English, Hindi",,Data Scientist,Tenaska ,"- Critical contribution in the development and improvement of real‑time optimization and bidding strategies of energy storage batteries in the physical and financial electricity markets of Texas and California.
- Development and maintenance of critical benchmarking metrics and performances. Conducting extensive testing under various configurations and parameters to evaluate new features and propose enhancements, crucially impacting the performance and driving daily operational decisions.
- Predicting natural gas prices and probabilistic time‑series forecasting of real‑time nodal electricity prices using deep learning models",New York University,"Master of Science, MS, Data Science",4 years 8 Months,3 Years 4 Months,Oil and Gas,Higher Education,"Dallas, Texas, United States",,
,,,Data Scientist Intern,Rumo,"-Developed an algorithm to improve fuel consumption efficiency of the RUMO railway line operations in Brazil which can lead up to $200k savings p.a.
-Designed a methodology to find malfunctioning locomotives when the amount of diesel refueled is more than estimated consumption.
-Achieved a recall of 70% for detecting unusual refueling events where fuel consumption of the locomotive is more than the estimated consumption.",,,,,,,,,
4.Sampath Gubbala,"English, Bengali",,Data Scientist,CVS Media Exchange,"• Reports: Created comprehensive closed-loop reports encompassing campaign performance analysis, executive summaries, campaign overviews, media metrics, performance highlights, and strategic recommendations.
• Measurement: Designed and executed A/B tests to assess the impact of various marketing strategies on key performance metrics, leading to a 24% improvement in ad effectiveness.
• Automation: Developed an automated measurement framework tailored to retail media campaigns, optimizing data collection, analysis, and reporting workflows. This initiative resulted in a remarkable reduction of over 50% in manual workload while significantly improving data precision
• Optimization: Enhanced the Measurement script by implementing a more efficient algorithm, minimizing the database connections, adding error handling, exception management, and optimizing database queries, which resulted in reducing runtime by more than 40%, reducing network latency, and enhancing operational efficiency.
• Enhancements: Introduced new KPIs into the existing measurement code, broadening measurement strategies to encompass the on-site channel, Google Ads channel, and off-site Exposed non-targeted segment.
• Statistical Models: Created and Implemented advanced statistical models to analyze customer behavior trends, predict purchasing patterns, and optimize ad targeting, resulting in a 60% increase in targeted marketing effectiveness and a 16% increase in campaign conversion rates.",University of Texas at Dallas,"Master's Degree, Business Analytics",5 Years 9 Months,3 Years 7 Months,Advertising Services,IT Services and IT Consulting,"Dallas, Texas, United States",,
,,,Data Scientist,Verizon,"•Maintenance: Engaged with operational devices, addressing any issues that emerged within the devices. Provided timely bug fixes and updates to ensure seamless operations.
•Anomaly Detection: Developed K-means Clustering models that can learn normal behavior of a network and detect anomalies or unusual patterns that might indicate security breaches, performance issues, or potential failures.
•Automation: Designed and implemented network management tasks, such as configuration changes and updates, using Python, which reduces the likelihood of human errors, resulting in a 20% reduction in manual configuration efforts.
•Optimization: Developed time series forecasting models that can analyze network traffic patterns and predict peak usage times, enabling dynamic allocation of resources for optimal performance.",,,,,,,,,
5. Dongxuan Zhang,"English, Chinese",,Data Scienctist Intern,Dell Technologies,"- Explored the source data for further processing
- Preprocessed the text data with Regex
- Built up Bi-LSTM & GRU Seq2Seq Model for token prediction
- Achieved 43% ExactMatch@1 & Log perplexity of 1.07
- Deployed Smart Compose using FastAPI for Dell internal technician",University of Texas at Austin,"Master of Science, MS, Business Analytics",3 Years 6 Months,2 Years 7 Months,IT Services and IT Consulting,Software Development,"Dallas, Texas, United States",,
,,,Data Scientist,Walmart Global Tech,,,,,,,,,,
6. Raag Patel,"English, Gujrati",,Data Science Intern,Hanesbrands Inc.,"•Partnered with stakeholders to launch a comprehensive data science project. And oversaw the full data science lifecycle, from data exploration to presenting findings to management.
•Applied a quasi-Poisson regression model to assess revenue impacts and broader business
benefits.
•Utilized Python, R, and SQL for diverse data operations.
•Worked on the inception and the implementation of:
 Q Groups:
Segmented SKUs using K-Means clustering and performance criteria.
Optimized SKU groupings based on sales and inventory metrics.
•Breakpoints:
Analyzed SKUs to determine optimal inventory levels.
Offered insights on inventory stocking based on sales metrics.
•Power BI Dashboard:
Developed an interactive Power BI Dashboard, tailored for stakeholder engagement and real-time insights.",Southern Methodist University,"Master of Science, MS, Data Science",8 Months,8 Months,Manufacturing,"Transportation, Logistics, Supply Chain and Storage","Winston-Salem, North Carolina, United States",,
7. Vatsal Nayak,"English, Gujrati",,Data Science Intern,Predactica™,"● Carried out R&D of Explainable AI to increase user understanding and build trust toward model predictions
● Formulized healthcare analytics tool to classify users’ workout intensity level providing actionable insights
● Implemented explainable modeling with SHAP (SHapely Additive exPlanations) and LIME to explain model predictions",University of Texas at Dallas,"Master's Degree, MS, Business Analytics",6 Years 5 Months,4 Years 6 Months,"Technology, Information and Internet",Advertising Services,"Dallas, Texas, United States",,
8. Atul Sanjay,"English, Hindi",,"
Prognostics Data Scientist",Ford Motor Company,"• Own the process for prognostic feature development from conceptual to feature deployment to our production vehicles
• Develop next -gen methodologies for electric/ ICE vehicle prognosis/fault tolerance control and integration
• Develop, validate and implement prognostic algorithms by leveraging connected vehicle data to provide integrated hardware and software prognostics solutions to our customers
• Develop, and implement statistical/predictive models using advanced algorithms on diverse sources of data and testing and validation of models on hardware/software in loop benches, prototype vehicles
• Interact with subject matter experts to understand component/system functions, leverage existing connected vehicle data to model on-board and off-board prognostics algorithms
• Operate cross-functionally to ensure successful code implementation on production vehicles",Trine University,"Master of Science, MS, Information Science",9 Years 8 Months,5 Years 6 Months,Motor Vehicle Manufacturing,Higher Education,"Dallas, Texas, United States",,
9. Deepesh Pamnani,"English, Hindi",,Data Scientist II,Ascentt,Leveraging data-driven insights to drive supply chain optimization initiatives for the automotive sector.,Stevens Institute of Technology,"Master of Science, MS, Computer Science",6 Years,4 Years,IT Services and IT Consulting,Software Development,Dallas-Fort Worth Metroplex,,
,,,Senior Data Scientist,Walmart Global Tech,,,,,,,,,,
10. Vamsi Nellutla,"English, Telugu",,"
Principal Data Scientist",UnitedHealth Group,"Performing player-coach role responsible for leadership, management, and direction to the enterprise Data Science and AI initiatives through Machine Learning, Deep Learning and NLP Predictive Analytics. Responsible for exploring AI options in the market space and educating the enterprise on these opportunities. Strategic guidance through implementation and iteration of Predictive Algorithms for improved program outcomes through tool and resource development.",Northcentral University,"PhD, Data Scient Specialization, Minor in Machine Learning",35 Years 11 Months,33 Years 9 Months,Hospitals and Health Care,IT Services and IT Consulting,Dallas/Fort Worth Area,,
,English,,Founder and President,Dallas Data Science Academy,"Successfully leading the DFW area's premier educational, training, and career development center in Data Science, Machine Learning, and AI fields. **Official Microsoft, IBM and Google Network Partner with BBB A+ Rating for our ethical practices** delivering a wealth of experience in all things data, with rigorous technical and strategic training for motivated QA, BA, PM, and Big Data Professionals as well as Corporations. Rated among Fortune 25 Best Data Science and Analytics Bootcamps in US for 2022, 2023 and 2024.",,,,,,,,,
"11. Vismay H Revankar
",English,,Data scientist,Microsoft,"- Train machine learning models and speech grammars for speech recognition applications used by Fortune 500 clients.
- Work as the lead speech scientist on numerous voice biometrics projects. My role is to train the voice biometrics engine and validate its performance before deployment in production.
- Use advanced NLP techniques to build a name entity recognition (NER) system for a data security application (continuation from my internship).- Train machine learning models and speech grammars for speech recognition applications used by Fortune 500 clients. - Work as the lead speech scientist on numerous voice biometrics projects. My role is to train the voice biometrics engine and validate its performance before deployment in production. - Use advanced NLP techniques to build a name entity recognition (NER) system for a data security application (continuation from my internship).",,,,,,,,,
,,,Data science intern,Microsoft,"- Used advanced NLP techniques to build a name entity recognition (NER) system for a data security application.
- Built a web-application for cross-platform document migration for internal use.
- Tech stack: Java, Python, PyTorch, HuggingFace models",Dalhouise university,,,,,,Canada,,
12. Nishant Upadhyay,"English, hindi",,Data scientist,Epicor,"SQL: Create stored procedures to perform pricing analysis
Ssis package to automate ingestion
Utilize powershell to automatOpenPyxlxls tasks to run stored procedures and emails
Use power automate to set automatic analytical scripts that could run analysis on certain emails and Teams
Maintain and launch sales analytical solution for electrical businesses
Run and launch machine learning algorithms like clustering and regression to develop better pricing and product recommendations
Utilize cross sell algorithms like product association and apriori to create product recommendation algorithms
Develop and maintain reporting scripts that use SQL and Python (OpenPyxl) to launch reporting tools and automate the delivery","University of wisconsin, Madison","Industrial Engineering, Analytics & Data Science",~4 years,~1 year 4 months,Software Development,,"WFH, Wisconsin",Dehradun,
,,,,,,,,,,,,,,
,,,,,,,,,,,,,,
,,,,Hardicon,"Technologies used – MySQL, R, SAP ERP, Power BI, RNN, Time-series, Python, Git, Big Query, Google Cloud, Tesseract, Git, Sqlite3 o Built and maintained existing and new data pipelines with SQL, Python and AWS S3 by integrating data from multiple sources.
o Helped train recurrent neural network (RNN) to forecast propane sales demand, outperforming the existing ARIMA model with an improvement of 8% in accuracy, saving the client more than $500k in distribution costs.
o Utilized logistic regression and random forests with SMOTE to predict customer churn for the propane distribution project.",,,,,,,,,
13. Farbod Tavakkoli,English,,Data scientist,Texas Trees Foundation,"• Conducted data analysis to identify the impact of environmental features on
micro-climatic sensor data
• Established and maintained an organized data warehousing system to
ensure data security, protection, and privacy
• Designed spatial regression, repeated measure, and time-series models for
real-time temperature and air quality data",Southern Methodist university,"PHD, applied science, doctor of philosophy",~12 years,~10 years ,NGO,Retail,"Dallas, texas",Iran,
,,,Data scientist,DriveTime,"• Developed and implemented advanced predictive models, including repeated measure and LightGBM models, for delinquency forecasting based on historical performance
• Achieved a remarkable 14% improvement in accuracy compared to the previous model which is projected to yield annual cost savings of $5-6 million by optimizing workforce planning for the servicing department
• Conducted comprehensive analysis on big data (45 TB), leveraging Azure Automated Machine Learning
• Engineered and maintained databases and wrote queries in Snowflake, ensuring efficient data storage and retrieval",,,,,,,,,
,,,Data scientist,Child Poverty Action lab,"• Conducted analysis to identify key risk factors for gun violence in Dallas using risk terrain models risk terrain models
• Created and designed GitHub pages for weekly and monthly reports",,,,,,,,,
,,,Data scientist,SMU Hunter & Stephanie Hunt Institute for Engineering & Humanity,"• Conducted analysis on consumer expenditure data, developing sustainable solutions for under-resourced communities
• Performed explanatory data analysis, including data cleaning, visualization, feature selection, and PCA",,,,,,,,,
14. Shaw Talebi,English,,Data scientist,Toyota Financial services Corporation,"• Uncovered and corrected issues in production credit risk model that impacted over 70% of accounts and wrote model monitoring scripts to help avoid future failures
• Redeveloped loan originations model for independent dealers, which resulted in a 50% model performance improvement and provided $2.5 million in realized value to business partner",UTD,"Phd, physics",~10 years 5 months,All in US,Moto Financial Services,Automotive,"Dallas, texas",USA,
,,,"
Business & IT Manager",Palomino motors,"• Analyzed marketing and sales reports to inform inventory acquisition, which resulted in a 50% decrease in average inventory age
• Evaluated costs of lead providers through analysis of lead data and close rates, which led to over $2500 in monthly savings",,,,,,,,,
15. Lok Vamsi Anumukonda,"English, telugu",,Lead Data scientist,DataNimbus,"• Launched collaborative efforts with clients in the US and India, conceptualizing and executing innovative data solutions that align with their business goals and data-driven strategies.
• Built and managed customer’s ETL pipelines and cloud platform administration on Databricks and AWS.
• Designed and implemented end-to-end data workflows, from the setup and configuration of a new Delta Lake architecture, data ingestion mechanics, transformations, storage and retrieval for analytics, and produce insights from the resulting data using PySpark and Spark SQL.
• Led the ideation and execution of large-scale ML models and MLOps pipelines, enabling customers with AI-powered solutions that drive operational efficiency and decision-making accuracy.",UTD,"MS-CS, Data science",4 years 3 months,3 years 9 months,Software development,Financial services,"Dallas, texas",Chennai,
,,,Data scientist,Eigen Patterns Inc,"Developed proprietary machine learning algorithms that leverage real- time data, advanced analytics, and agent interfaces to enable scalable and interactive real-time decision-making.
• Engineered the core algorithm by employing statistical techniques in pattern recognition and time series analysis.
• Established simulated datasets and environments to replicate real-time data processing, facilitating performance measurement and accuracy assessment.
• Executed deployment of the platform on scalable AWS clusters, enhancing code efficiency through Python-based multi-processing implementation.",,,,,,,,,
,,,Data science intern,fincovi,"- Designed and built a model for the generation of synthetic wind farm data using the Monte Carlo method in Python. 
- Targeting to increase the probability of achieving a target return and decrease the risk for a portfolio of operational renewable energy assets, such as wind and solar farms.
- Predicted P/L statements, Balance Sheets and other financial documents for these simulated wind farms to check viability.
- Analysed the correlations on a range of portfolios, determining factors, and designed a guide for their optimisation.
- Generated data was used to create efficient frontiers to give insights like what assets to buy/sell in the future given their return and risk profiles.",,,,,,,,,
,,,Data analyst,PayPal,"• Advanced Risk Analytics – part of the team dealing with Resolutions and Protections of PayPal.
• Constructed comprehensive dashboards, executed SQL queries within extensive database systems, and automated dispute/claims resolution processes using analytical and visualization tools, primarily Teradata SQL.
• Leveraged Python, R, SQL, and Tableau extensively to carry out duties.
• Designed Tableau dashboards that proactively identified a potential bug, averting potential monthly losses of up to $1 million.",,,,,,,,,
16. Simran Singh,"English, hindi",,Jr. Data scientist,WorldLink US,"- Conducted extensive testing and evaluation of LLMs including - Llama, MPT and WizardLM models
- Designed and implemented a foundational data model for chatbot functionality, efficiently capturing and organising user interactions, chatbot responses, and contextual data- Conducted extensive testing and evaluation of LLMs including - Llama, MPT and WizardLM models - Designed and implemented a foundational data model for chatbot functionality, efficiently capturing and organising user interactions, chatbot responses, and contextual data
",SMU cox business school,MSBA,4 years 7 months,7 months,IT services and business consulting: Accelerating enterprise transformation through data-led innovation.,Consulting,"dallas, texas",Delhi,
,,,Data analytics intern,WorldLink US,"- Built scalable time series forecasting models based on the market trend to optimize inventory management
- Developed an in-depth understanding of the business processes and data in the corporation and apply the knowledge towards developing and maintaining the Corporate Data Model",,,,,,,,,
17. Ayasha Anupam,"English, hindi",,Data scientist,CVS health,,UTD,MSBA,5 years 2 months,2 years 1 month,healthcare,Information Technology & Services,N/A,India,
,,,Data science intern,eClerx,"▪ Developed time series forecasting models using ARIMAX for the demand planning team. The new model has a lower validation error (reduced MAPE to bring it below 10%) and was used for Q3 forecasting.
▪ Forecasted demand from web visits and calls for the Q3 at a weekly level based on MARCOM (marketing spends) to support the demand planning process for small businesses and direct consumers.
▪ Performed EDA to check for stationarity, seasonality, and trend, to detect outliers, for feature selection (XGBOOST, Boruta), and feature engineering. Ran multiple iterations by trying out different combinations of the variables.
▪ Ran simulations for various scenarios with the marketing team - tried different combinations of spending and pricing to predict sales.",,,,,,,,,
18. Prat Shinge,"English, hindi, Marathi",,Lead Data scientist,Nike,"- Built cross platform demand prediction model to aid GTM and bot mitigation
teams.
- Built product similarity model for recommendations and assortment planning.
- Provided deeper consumer insights using NLP on product reviews.
- Secured projects aligning business needs & technical expertise.",Binghamton University,"MS, Industrial and Systems Engineering",~7 years 8 months,7 years 6 months,Retail,Retail,New York,Mumbai,
,,,Sr. Data scientist,Nike,"- Increased process efficiency and transparency for stakeholders to accurately track booked orders.
- Designed KPIs for collaborator brands (Travis Scott, Drake etc) aiding in contract renewal decisions.",,,,,,,,,
,,,Sr. Data scientist,Circle K,"•Led a team of 6 data scientists in deploying localized pricing strategies to 12 global business units, resulting in a potential margin uplift of $140M.
• Overhauled data pipelines and refactored the code base for age-restricted categories, improving efficiency and accuracy.
• Conducted exploration of short-term demand forecasting models to determine the optimal time window for implementing price changes.
• Acted as a technology liaison, collaborating with stakeholders to gather business requirements and effectively communicate the benefits and functionalities of data products.",,,,,,,,,
,,,Data scientist,Circle K,"• Summary: Cluster stores, prepare data, model elasticity, optimize price, measure success
• Used PCA and k-means to cluster stores based on site, transactional, and customer demographics data, identifying similar local markets within each business unit.
• Employed time series methods and log regression models to estimate the relationship between sales and price variation for each SKU x Cluster, achieving less than 10% MAPE.
• Significantly reduced modeling time by 75% through optimization of the elasticity modeling pipeline, allowing for scheduled and efficient execution of DataBricks jobs.
• Developed an automated price optimization input module that structured business constraints into process-oriented formats using Spark, Python, and SQL, resulting in a 90% reduction in process time.
• Utilized SQL and Python for in-depth analyses, measuring the impact of price changes on business priorities such as units sold, revenue, and margin, by comparing treatment and control stores.",,,,,,,,,
,,,Data scientist,Capital one,"Languages/Tools: Python, SQL, Spark, Snowflake, AWS (Redshift, EMR), Git.
Projects: Account charge off prediction, loss forecasting data migration (credit card). 
• To enable analysis, extracted terabytes of transaction data from multiple sources using SQL. Used PySpark and Hadoop to create feature extraction pipelines for account charge off prediction.
• Engineered features, explored feature importance, addressed class imbalance, built classification models, and enhanced model accuracy through a modular data pipeline for predicting account charge off risk.
• Facilitated high-volume dimensional data migration from Teradata to Snowflake for multiple international credit card processes. Developed, converted, and refactored SQL queries, while automating ETL pipelines in Python.
• Ensured data integrity by automating dataset comparison and generating discrepancy reports using Python.
• Improved efficiency by automating manual data pulls for credit card loss forecasting models, resulting in reduced data processing time.",,,,,,,,,
,,,Data scientist,Fortress Development Group,"Languages/Tools: Python, R, SQL, Google Cloud Platform BigQuery, Git, Tableau.
Projects: Algorithmic Real Estate, Property price prediction and predictive maintenance.
• Contributed to property acquisition decisions by constructing the back-end of a mobile application that predicts real estate prices, employing predictive machine learning and neural network models.
• Processed unstructured real estate data from various sources, performing data cleansing and transformation to generate structured data products.",,,,,,,,,
,,,Data analyst,New York city transit,"Languages/Tools: Python, R, Apache Zeppelin, Tableau, MS Excel, Linux.
Projects: Improve arrival time predictions of Bus-Time mobile application.
• Enhanced the accuracy of predictions for the MTA Bus-Time mobile application by 6% by creating predictive models and feature extraction systems through automated data pipelines built in R.
• Expedited the execution time of model runs through SparkR parallelization in Apache Zeppelin.
• Determined quality of bus arrival-time predictions by performing exploratory data analysis and feature engineering.
• Extracted and transformed terabytes of real-time bus-arrival data using data filters built in R and SQL.
• Communicated data insights to managerial staff through Tableau dashboards and well-documented reports.Languages/Tools: Python, R, Apache Zeppelin, Tableau, MS Excel, Linux. Projects: Improve arrival time predictions of Bus-Time mobile application. • Enhanced the accuracy of predictions for the MTA Bus-Time mobile application by 6% by creating predictive models and feature extraction systems through automated data pipelines built in R. • Expedited the execution time of model runs through SparkR parallelization in Apache Zeppelin. • Determined quality of bus arrival-time predictions by performing exploratory data analysis and feature engineering. • Extracted and transformed terabytes of real-time bus-arrival data using data filters built in R and SQL. • Communicated data insights to managerial staff through Tableau dashboards and well-documented reports.",,,,,,,,,
19. Nate Litton ,English,,VP and chief data & analytics officer,Toyota,"• Lead a 600+ person team overseeing all AI, data, and analytics strategy, roadmap, and execution.
• Implemented consumer-focused advanced AI and machine learning solutions, achieving significant enterprise value KPI targets
• Consolidated multiple disparate data sources into a centralized Snowflake data platform, improving scalability, speed, and accessibility
• Led data talent transformation, significantly reducing reliance on vendor outsourcing",Texas A&M,"phd, statistics",15 years,all in us,automobile,Consulting,"Plano, texas",USA,
,,,,,"• Modernized data engineering and AI practices by growing talent, streamlining core processes, and consolidating tools and platforms.
• Enhanced data governance and stewardship, reducing data management costs and ensuring regulatory compliance",,,,,,,,,
,,,GM,,"• Transformed data and analytics practice with effective cloud migration strategies for on-premise databases and information delivery.
• Established the Data & Analytics Institute to enhance technical talent and literacy through certification programs, mandatory training, and community-building events. ",,,,,,,,,
,,,,,"• Developed and managed residual value and credit loss forecasting models for consumer portfolios
• Enhanced dynamic routing and advanced intelligence for the fleet management and mobility services platform in the Toyota Connected division",,,,,,,,,
,,,Lead data scientist,Right place consulting,"• Built and led a core data science and AI development team supporting Mercedes Mobility in North America and Germany.
• Developed predictive models, optimization engines, and machine learning algorithms using Python",,,,,,,,,
20. Madhusree Chowdhury,"English, hindi, bengali",,Data scientist,Health Data Analytics Institute,,UCONN,MSBA,2 years 3 months,2 years 3 months,healthcare,N/A,Calcutta,,
,,,Data science intern,Health Data Analytics Institute,"-Assisting the Algorithm Development team by predicting binary target variables of various clinical endpoints (Mortality, Sepsis, Acute Kidney disease, Respiratory failure etc.) using predictive models such as XGBoost, LightGBM, glmnet on Medicare data with the features including ICD10, CPT codes etc.
-Performed feature selection and automated model calibration using Brier Score decomposition in R.",,,,,,,,,
21. Sneha Rani,"English, hindi",,Data science intern,Lenevo,"- Engineered an advanced R Shiny application integrating Facebook Graph APIs to automate and visualize social media analytics.
- Empowered small businesses with actionable insights by harnessing predictive analytics and sophisticated data visualization techniques.
- Spearheaded initiatives to drive data-informed decision-making and optimize marketing strategies for enhanced business performance.",North Carolina State University,"M.S, phd, statistics, technology management",~5 years 1 month,2 months,Electronics applicans and tech,Rayleigh,Mumbai,,
,,YES,Assistant Manager - Sales & Marketing Analytics,Welspun group,"● Drove Market expansion: Collaborated with cross-functional teams, leveraging data modeling techniques for market expansion, resulting in $50M revenue in North America with an 18% YoY growth.
● Product Strategy Analytics: Implemented marketing mix modeling and ROI analysis for forecasting sales of new products like weighted blankets and antibacterial linens.
● Optimized B2B Product Portfolio: Streamlined product SKUs for B2B clients using Demand Forecasting, Ensemble methods, & Clustering, reducing production costs by 15%.
● Enhanced ARIMA/Time Series Forecasting models for inventory management, reducing overstock by 20%, and improving operational efficiency by 10%.
● Influenced data-driven decisions, boosting lead conversion rates by 15% & enhancing customer acquisition cost efficiency by 25% in B2B marketing campaigns/trade shows.",,,,,,,,,
22. Sampath Gubbala ,"English, tamil",,Data scientist,CVS media exchange,"Reports: Created comprehensive closed-loop reports encompassing campaign performance analysis, executive summaries, campaign overviews, media metrics, performance highlights, and strategic recommendations.

Measurement: Designed and executed A/B tests to assess the impact of various marketing strategies on key performance metrics, leading to a 24% improvement in ad effectiveness.

Automation: Developed an automated measurement framework tailored to retail media campaigns, optimizing data collection, analysis, and reporting workflows. This initiative resulted in a remarkable reduction of over 50% in manual workload while significantly improving data precision

Optimization: Enhanced the Measurement script by implementing a more efficient algorithm, minimizing the database connections, adding error handling, exception management, and optimizing database queries, which resulted in reducing runtime by more than 40%, reducing network latency, and enhancing operational efficiency.

Enhancements: Introduced new KPIs into the existing measurement code, broadening measurement strategies to encompass the on-site channel, Google Ads channel, and off-site Exposed non-targeted segment.

Statistical Models: Created and Implemented advanced statistical models to analyze customer behavior trends, predict purchasing patterns, and optimize ad targeting, resulting in a 60% increase in targeted marketing effectiveness and a 16% increase in campaign conversion rates.",UTD,MSBA,5 years 4 months,2 years,Advertising Services ,Entertainment providers,"Dallas, texas",Chennai,
,,,Data scientist,Netflix,"Maintenance: Engaged with operational devices, addressing any issues that emerged within the devices. Provided timely bug fixes and updates to ensure seamless operations.

Anomaly Detection: Developed K-means Clustering models that can learn normal behavior of a network and detect anomalies or unusual patterns that might indicate security breaches, performance issues, or potential failures.

Automation: Designed and implemented network management tasks, such as configuration changes and updates, using Python, which reduces the likelihood of human errors, resulting in a 20% reduction in manual configuration efforts.

Optimization: Developed time series forecasting models that can analyze network traffic patterns and predict peak usage times, enabling dynamic allocation of resources for optimal performance.",,,,,,E-commerce,,,
,,YES,Data analyst,Amazon,"Analysis: Analyzed large e-commerce historical sales datasets to identify trends and Conduct a comprehensive inventory analysis to identify demand patterns and optimize stock levels. Implemented a demand forecasting model to reduce stockouts, minimize excess inventory, and identify slow-moving and obsolete inventory items, leading to a 27% reduction in carrying costs and increased warehouse space.

Dashboards: Utilized tools like MS Excel, Tableau, Python, and Amazon QuickSight to create interactive dashboards that present inventory insights to stakeholders.

Brand Gap Analysis: Performed brand gap analysis for Amazon's external selection, which aids in the onboarding of thousands of sellers each month.

Automation: Developed a categorizer tool that increased the rate of categorizing items from 400 to 3000 per hour while increasing accuracy from 70% to 92 percent.

Optimization: Designed seller-based forecast models, dashboards, and reports to predict key metrics, which resulted in reducing manual workload by more than 50%.

Mentored: Trained and Monitored new employees until they were proficient in their skill set.",Grand Valley state university,MS. biostatistics,~6 years 7 months,US citizen,Furniture and Home Furnishings Manufacturing,,Chicago,USA,
23. Levi Rosendall ,English,,"Founder
",Reinforce Advertising,,,,,,,,,,
,,,Data scientist,Steelcase,"Work with the Data Science Practice to deliver novel data-driven insights to internal business partners. Developed Data Science pipelines to inform pricing, as well as to generate leads for internal and external sales teams. Serve as an active data consultant within Steelcase.",,,,,,,,,
24. Vishal Morde,"English, Gujarathi",,head of data science,Apple,"- Developed end-to-end data solutions for financial products (Apple Card, Cash, Pay Later), payment services (Apple Pay, Tap to Pay), and subscription products (AppStore, Music, TV+) generating $XBn+ incremental revenue. Skills: Executive Leadership · Talent Management · Cross-functional Team Leadership · FinTech · Payments · Commerce · Go-to-Market Strategy · Predictive Modeling · Product Analytics · Causal Inference · Data Science · Operational Analysis · Marketing Analytics · Machine Learning · Artificial Intelligence (AI) · A/B Testing · Deep Learning · Large Language Models (LLM) · Time Series Forecasting · Business Analysis · Big Data
- Leveraged next-gen experimentation frameworks to optimize existing 30+ product features to fuel growth (1.3x sign-ups) and profitability (1.2x margin)
- Architected and deployed 20+ ML models to optimize funnel conversion, ranking and search relevance, payment authorization, fraud detection, risk mitigation, and churn prevention 
- Evangelized Generative AI frameworks and leveraged GPT-based models to create seamless customer experience and improve CSAT while reducing operational cost ",Northwestern University- Kellogg school of mgt.,MBA,19 years ,19 years,Computers and Electronics Manufacturing,Internet Marketplace Platforms,"San Francisco, Bay area",USa,
,,,head of data science,Uber | financial planning,"- Launched 10+ in-app product features to accelerate growth, create seamless personalized experiences, and reduce customer churn while generating $1Bn+ incremental revenue
- Architected 20+ time-series forecasting models, customer lifetime value (CLV) models, and causal inference studies for optimal capital allocation of $2Bn marketing and operations budget
- Advised C-level executives by streamlining financial data, building insightful data products, and democratizing product P&Ls, and accelerating Uber’s path to profitability. Skills: Data Science · Analytics · Marketing Analytics · Operational Analysis · Predictive Analytics · Predictive Modeling · Deep Learning · Python · R Programming · SQL · Recommender Systems · Artificial Neural Networks · Chatbot Development",,,,,,,,,
,,,head of data science,Barclays,"As co-founder of the Data Science program at Barclays, I built industry-leading Machine Learning and Applied AI products/solutions delivering on $100MM annual profit.

• Spearheaded a center-of-excellence for Artificial Intelligence and Machine Learning initiatives by leading a cross-functional team of 35+ data scientists, data engineers, software developers, and business analysts 
• Serve as the business owner for Big Data platform for coordinating with Technology, Governance, and other analytics teams for organizing, democratizing and monetizing internal/external data assets
• Managed $15MM annual budget for building new-age analytic capabilities on proprietary Hadoop platform and accelerating deployment of Data Science capabilities
• Recruited top Data Science talent to drive high-potential AI initiatives in deep learning, recommendation systems, next-best-action systems, graph theory, chat-bots, NLP, and computer vision",,,,,Financial Services,,,,
,,,"Director, product analytics",Barclays,"• Managed customer analytics initiatives for credit card rewards, product upgrades and rebrand/conversion marketing programs to generate $20MM in annual profit.   Strategic Data Analysis · Business Strategy · Digital Strategy · SQL · SAS
• Developed a comprehensive business case and successfully launched a new credit card product (Aviator Silver) for American Airlines co-brand partnership
• Designed champion/challenger strategies to test effectiveness of marketing programs and to improve long-term customer loyalty and engagement
• Launched ‘Ideas and Innovation Forum’ to promote innovative thinking, to facilitate knowledge transfer and to gain knowledge of state-of-the-art analytical solutions to solve complex business problems",,,,,,,,,
,,,Data science manager,Discover Financial services,"• Developed cardmember pricing strategies to drive profitable receivable growth. 
Analyze customer performance, explain trends in key metrics, and make strategic recommendations to change the business model to achieve profit maximization. 
• Conducted cost/benefit studies to analyze business profitability by customer segments and products. 
• Implemented new marketing strategies by leading cross-functional team involving Marketing, Customer Service, Risk, Business Technology and Finance areas. 
• Prepared and delivered results to senior leadership team along with actionable recommendations. Skills: Pricing Strategy · Product Analytics · Product Development · Product Marketing · Pricing Analysis · Financial Analysis · Financial Modeling · Consumer Lending · Credit Cards",,,,,,,,,
,,,Sr. Data scientist,HSBC,"• Developed predictive models, customer segmentation schemes, and ad-hoc diagnostic studies for $48Bn mortgage portfolio resulting in $4MM cost savings
• Led cross-functional teams to develop and implement credit risk management strategies for a sub-prime mortgage portfolio with $48Bn in receivables
• Identified different risk levels for delinquent customers by developing segmentation models to save $4MM in delinquency and charge-off• Developed predictive models, customer segmentation schemes, and ad-hoc diagnostic studies for $48Bn mortgage portfolio resulting in $4MM cost savings • Led cross-functional teams to develop and implement credit risk management strategies for a sub-prime mortgage portfolio with $48Bn in receivables • Identified different risk levels for delinquent customers by developing segmentation models to save $4MM in delinquency and charge-off
Skills: Credit Risk · Risk Management · Predictive Modeling · Predictive Analytics · Regression Models · Cluster Analysis · SQL · SAS (Programming Language) · SAS E-Miner",,,,,,,,,
,,,Data scientist,HSBC,"• Developed loss forecasting models by collaborating with Operations, Finance and external vendors such as Moody’s Economy.com 
• Analyzed delinquency trends and evaluated the impact of the deterioration in certain real estate markets",,,,,,,,,
25. Mathew Blasa,English,,Lead data scientist,Aspire 360,,Texas A&M,MS-Statistics,~13 years ,All in US,IT services and Business consulting,Home improvement company,"Dallas, texas",USA,
,,,Sr. Data scientist,The home depot,"Led a team of data scientists to build, create, and test models used in recommendation system for the HD website. Responsibilities included project management of multiple ML projects, deployment of models, and managing development workflows.

Other Projects and Responsibilities
o Mentored 4 junior data scientists and produced high-quality work;
o Identified opportunities based on regional and temporal data that provided actionable internal insights;
o Designed and implemented a hierarchical framework to better fill the data gap as well as validate data reliability.",,,,,,,,,
,,,Solution architect,Brinks home security,"At Brinks Home, I wore multiple hats: data modeler, data engineer, and data governance analyst. I worked closely with Sales, Marketing, and Finance, to create data and machine learning models from user requirements, documentation, improve data quality, and provide support for data engineering efforts.

This included user acceptance testing of data models and quality testing for data pipelines and ML models",,,,,,,,,
26. Nagalakshmi Reddy Erigala,"English, telugu",,Data analyst,Camping world,,UTD,MSBA,5 years 2 months,4 years,Retail,N/A,"Charlotte, North carolina",Hyderabad,
,,,Data science intern,Camping world,"• Developed a dynamic message scrolling feature in PowerBI, integrating SharePoint data with the Enterprise Reporting Dashboard, enhancing stake holders' engagement by 48%.
• Spearheaded seamless migration of marketing data from Acxiom to Snowflake, using Snowflake for SQL queries and dbt for ETL pipelines. This collaboration resulted in a 30% boost in data management efficiency, maintaining over 95% dataset accuracy, crucial for marketing insights' integrity.
• Managed seamless migration from legacy database to Snowflake, employing Jira for project oversight. Ensured 98% data integrity across SQL Server, Snowflake, Excel, and Power BI through continuous data validation.
• Conducted in-depth data analysis on turnover patterns and employee feedback, leading to actionable recommendations that resulted in a 10% increase in employee retention, effectively demonstrating the impact of data-driven decision-making on enhancing HR strategies.",,,,,,,,,
27. Wei Chen,"English, ",,Head of Machine Learning,Stealth startup,,,,,,,,,,
,,,Senior Data Scientist,Netflix,"• Developed and implemented advanced recommendation algorithms, enhancing user engagement and retention by over 25%
• Led the development of a real-time anomaly detection system, enabling proactive identification and resolution of critical issues
• Collaborated with product and engineering teams to define and execute data-driven experiments, driving key product improvements",Carnegie Mellon University,MSCS,~11 years 3 months,All in US,startup,Entertainment providers,California,USA,
,,,Senior Data Scientist,Google,"• Designed and deployed large-scale machine learning models for ad targeting and optimization, resulting in a 15% increase in click-through rates
• Mentored junior data scientists, providing technical guidance and fostering professional growth",,,,,,,,,
,,,Data Scientist,Google,"• Conducted in-depth analysis of user behavior data, uncovering actionable insights that informed product strategy and development",,,,,,,,,
,,,Data Scientist,Toyota,"• Developed predictive maintenance models for connected vehicles, reducing maintenance costs by 20% and improving customer satisfaction
• Collaborated with cross-functional teams to integrate data science solutions into production systems, ensuring seamless deployment and scalability
• Conducted workshops and training sessions to promote data literacy and foster a data-driven culture across the organization",,,,,,,,,
,,,Sr. Data analyst,Capital One,"• Led complex data analysis projects to uncover opportunities for growth and optimize financial performance in the credit card division
• Collaborated with cross-functional teams, including risk management, to develop and implement data-driven strategies for customer retention.",,,,,,,,,
,,,Data analyst,Capital One,"• Performed data analysis to identify trends and patterns in customer behavior
• Collaborated with marketing teams to support data-driven customer acquisition strategies",,,,,,,,,
"28. Ram Chandra 
 ","English, hindi",,"Director of Data science, Insights and Data science",Toyota,"In my current role at Toyota, I've strategically aligned data science with business goals, implemented advanced MLOps in AWS and GCP, and led the development of 200+ models generating over $500M in benefits. I've also expanded our team group of specialists spanned across customer data science, marketing data science, sales data science and ML Engineering and Mlops. I have championed major initiatives that enhance all stages of customer journey, business transformations and drive decisive actions across the company.","IIT, Kanpur","Mtech, engg",19 years,13 years,Motor Vehicle Manufacturing,Cognizant company,"Plano, texas",Delhi,
,,,"Principal Data scientist, enterprise data science",Toyota,"In my previous role, I expanded Toyota's customer-centric model portfolio to over 100 models in production, greatly enhancing marketing efforts and generating over $100M in annual revenue. I developed 'SMART ETA' model, which predicted vehicle delivery times and reduced customer wait time by 50%, which led business to commit to 10 additional use cases. I co-engineered an AWS-based data science platform, streamlining experimentation and migrating 100+ models for improved scalability. Additionally, I established a comprehensive ML engineering and MLOps framework that promoted standardized AI practices and advocated successfully for the creation of 20 new data scientist positions to bolster our capabilities.",,,,,,,,,
,,,"Lead data scientist, Customer one (C360)",Toyota,"I led the creation of a highly adopted retention tool (LEO, Loyalty Engagement Opportunity), achieving 97% dealer uptake in 90 days, saving $125M in the first year, and projecting a $350M revenue increase. I also developed 20 models predicting customer spend, influencing over $350M in retention strategies, and standardized data science processes with 'INETMODS', enhancing efficiency across Toyota.",,,,,,,,,
29. Zoey L.,"English, chinese",,Data scientist,GM financial,,Duke University,"Master's statistical science, statistics",1 year and 9 months,1 year and 5 months,Financial Services,Bosch company,"Dallas, texas",China,
,,,Data science intern,GM financial,"Built dealer recommendation system from scratch using Natural Language Processing in Python.
Visualized dashboard to showcase and compare different methods I adopted",,,,,,,,,
30. Akhila Chowdary N. ,"English, hindi",,Data scientist,Capital One,Leading 0 -> 1 operational reporting analytics & ML roadmap of HR data in collaboration with product and engineering teamsLeading 0 -> 1 operational reporting analytics & ML roadmap of HR data in collaboration with product and engineering teams,UTD,MSBA,4 years and 1 month,2 years and 3 months,Financial Services,Environmental Services,"Plano, texas",Delhi,
,,,Data scientist,WM,"Built and maintained data pipelines and visualizations that support the self-service, customer support, and fulfillment audit",,,,,,,,,
31. Prateesh Reddy Patolla,"English, telugu",,Data scientist,Toyota,"• Spearheaded a $150 million every year optimization initiative at Toyota, from designing architecture proof-of-concept (POC) to deployment stages and further enhancing it by adding demand forecasting.

• Utilized A/B testing and causal inference methods to inform critical business decisions during the pilot phase of projects that generated millions showcasing the impact of data-driven decision-making at scale.

• Implemented data quality checks, great expectations, and data validation processes, ensuring consistency, and integrity of data for downstream analytics and reporting purposes","Indiana university, bloomington",MSDS,3 years and 4 months,1 year 11 months,Motor Vehicle Manufacturing,E-commerce,"Plano, texas",Hyderabad,
,,,Data science intern,Amazon,"• Low-frequency Alexa questions had higher confidence intervals/margin of error. Performed Stratified sampling using various distributions and compared them using spark in AWS. The result led to a change in Alexa tables’ data pipeline.

• Performed the Re-training for the categorizer model with improved accuracy which is the machine learning model which categorizes Alexa questions into various subcategories like Weather, Knowledge, and Skills.

• Created a dashboard for historical comparison of Alexa’s successful answering metric with the 2023 target and baseline which is now being used in Alexa-wide weekly webinars to discuss the progress of Alexa performance.",,,,,,,,,
32. Sharvari Jadhav ,"English, Marathi",,Data scientist,Elsevier,"• Assessed correlation between number of unique specialty exams taken by students and mean HESI exit exam scores using EDA, proving effectiveness of specialty exams
• Applied sentiment analysis on tweets relevant to top 10 research papers helping researchers keep up with trends
• Prepared search algorithm using Python to flag culturally insensitive questions reducing manual work by 90%
• Piloted a way to match question bank to chapter text using NLP(Scikit-Learn) helping clients to build test easily",UTD,MSMIS,5 years 6 months,4 years 2 months,IT Services and IT Consulting,telecom,"Dallas, texas",Mumbai,
33. Atul Sanjay,English,,Prognostic Data scientist,Ford Motor company,"• Own the process for prognostic feature development from conceptual to feature deployment to our production vehicles
• Develop next -gen methodologies for electric/ ICE vehicle prognosis/fault tolerance control and integration
• Develop, validate and implement prognostic algorithms by leveraging connected vehicle data to provide integrated hardware and software prognostics solutions to our customers
• Develop, and implement statistical/predictive models using advanced algorithms on diverse sources of data and testing and validation of models on hardware/software in loop benches, prototype vehicles
• Interact with subject matter experts to understand component/system functions, leverage existing connected vehicle data to model on-board and off-board prognostics algorithms
• Operate cross-functionally to ensure successful code implementation on production vehicles• Own the process for prognostic feature development from conceptual to feature deployment to our production vehicles • Develop next -gen methodologies for electric/ ICE vehicle prognosis/fault tolerance control and integration • Develop, validate and implement prognostic algorithms by leveraging connected vehicle data to provide integrated hardware and software prognostics solutions to our customers • Develop, and implement statistical/predictive models using advanced algorithms on diverse sources of data and testing and validation of models on hardware/software in loop benches, prototype vehicles • Interact with subject matter experts to understand component/system functions, leverage existing connected vehicle data to model on-board and off-board prognostics algorithms • Operate cross-functionally to ensure successful code implementation on production vehicles",Trine University,MSIS,7 years 6 months,3 years 4 months,Motor Vehicle Manufacturing,IT Services and IT Consulting,"Dallas, texas",Mumbai,
34. Kyle Manning,English,,Data scientist,SBIA- Sports Betting Innovative Analytics,"- Apply machine learning techniques to sports
- Build models for predicting outcomes in various betting markets
- Utilize Python data science libraries for modeling and general data work
- Use MongoDB for querying and performing complex aggregates",Rice university,"BA, statistics and economics",3 years 6 months,All in US,Sport Internet marketplace,Software Development,"houston, texas",USA,
,,,Data Science Intern,"Lone Wolf Technologies 
","- Researched and developed a real estate agent recommendation system to assist in brokerage recruiting
- Assisted in creation of an end-to-end data science pipeline with cleaning, aggregation, clustering, and prediction scripts
- Cleaned, aggregated, and performed feature selection on real estate listing data using Python",,,,,,,,,
35. Viraj Thakkar,"english, hindi",,Data scientist,Tenaska,"- Critical contribution in the development and improvement of real‑time optimization and bidding strategies of energy storage batteries in the physical and financial electricity markets of Texas and California.
- Development and maintenance of critical benchmarking metrics and performances. Conducting extensive testing under various configurations and parameters to evaluate new features and propose enhancements, crucially impacting the performance and driving daily operational decisions.
- Predicting natural gas prices and probabilistic time‑series forecasting of real‑time nodal electricity prices using deep learning models",NYU,MSDS,3 years 1 month,1 year and 9 month,Oil and Gas,"Transportation, Logistics, Supply Chain and Storage","dallas, texas",Mumbai,
,,,Data Scientist Intern,"

Rumo","-Developed an algorithm to improve fuel consumption efficiency of the RUMO railway line operations in Brazil which can lead up to $200k savings p.a.
-Designed a methodology to find malfunctioning locomotives when the amount of diesel refueled is more than estimated consumption.
-Achieved a recall of 70% for detecting unusual refueling events where fuel consumption of the locomotive is more than the estimated consumption.",,,,,,,,,
36. Danish Khan,English,,Data scientist,MTX group,"Georgia DECAL CAPS Payment Solution: Python, SQL, NoSQL, Azure, AWS, Oracle, Salesforce

• Redesigned data architecture for the State of Georgia DECAL, enhancing efficiency for data size ~10+ Billion records
• Developed a reusable data migration ETL Pipeline from Azure SQL to the Salesforce platform that MTX was building
• Collaborated with Georgia Cybersecurity for the secure transmission of high-risk PII data, ensuring data security
• Validated live payment data, resulting in 100% accuracy in invoice/payment generations
• Achieved similar results for WI DSPS, NYC DCLA, and other government clients achieving 9.8/10 in overall CSAT ratings

Revenue Forecast: Python, SQL, Salesforce, BigQuery, Airbyte

• Designed a data integration pipeline from the Salesforce Beans HR Time Management System to Google BigQuery
• Orchestrated it to run 4 times daily according to different global timezones with 100% accuracy ~150 million rows
• Created a dynamic dashboard on the DataX platform highlighting key metrics subdivided by projects, regions, skillsets, title, etc
• Analyzed the TMS Data for real-time forecasting gathering actionable insights and enhancing global project run rates by ~8%
• Collaborated in decision-making with leadership during organizational restructuring, resulting in cost-cutting by ~12%

Sports Science: Python, SQL, BigQuery, Selenium, NoSQL, PyTorch, GCP Kubernetes

• Trained/Fine-tuned a custom YOLOX player/object detection model for FC Dallas with 98% mAP for detecting players
• Implemented advanced FairMOT player tracking for soccer players with a MOTA score of 61%
• Developed an attendance prediction model for FC Dallas with ~88% accuracy
• Scraped NCAA basketball player data using Python, and Selenium on Google Kubernetes engine ~ 800 Million rows
• Created a player similarity model that outputted players similar to a corresponding NBA player achieving ~93% accuracy",UB,MSDS,4 years 9 months,4 years 2 months,Information Technology & Services,IT consulting and IT business,"dallas, texas",Delhi,
,,,AI Intern,MTX group,"COVID-19 Dashboard: Python, SQL, Selenium, GCP Big Query, Looker ML

• Performed Data Exploration Analysis on global COVID-19 datasets & generated synthetic data sets ~1 Billion rows
• Developed a ~2% error-rate univariate LSTM model as a POC for COVID-19 to predict trends for the Govt. of NYC
• Analyzed feature importance affecting COVID-19-related death rates and highlighting key areas for rapid improvement
• Helped in conducting contact tracing analysis, generating targeted surveys, and creating Looker visualizations",,,,,,,,,
,,YES,TCS,ML intern,"Data Alchemy:- 
Performed data cleaning, wrangling, and exploratory data analysis (EDA). Applied predictive models to datasets, unraveling valuable insights and trends.

Virtual Self-Driving Car:
Pioneered the development of a real-time virtual self-driving car through deep Q learning.
Engineered on Python within the Spyder IDE, leveraging the prowess of Numpy and PyTorch ML library.
Implemented an Artificial Neural Network-based algorithm for decision-making and obstacle avoidance. Achieved seamless navigation, reducing decision errors by an impressive 50% over time.",,,,,,,,,
37. Vatsal Nayak,"English, marathi",,Data scientist,PMG,"Forecasting
● Anomaly Detection
● Diminishing returns
● Creative Insights",UTD,MSBA,6 years and 3 months,4 years and 4 months,Advertising Services,"Technology, Information and Internet","Dallas, texas",USA,
,,,Data Science Intern,Predactica™ ,"
● Carried out R&D of Explainable AI to increase user understanding and build trust toward model predictions
● Formulized healthcare analytics tool to classify users’ workout intensity level providing actionable insights
● Implemented explainable modeling with SHAP (SHapely Additive exPlanations) and LIME to explain model predictions",,,,,,,,,
,,,Data analytics intern,CMCI,"● Performed market research to develop the market research report facilitating decision making 
● Developed Power BI dashboard to visualize and understand the global market presence
● Implemented cloud-based facial recognition system with the help of AWS Rekognition APIs",,,,,,,,,
38. Ravi Raj C.,"English, Kannada",,Data scientist,CBRE,,UTD,MSBA,4 years  10 months,2 years 2 months,Real Estate,IT Services and IT Consulting,"Dallas, texas",Bangalore,
,,,Data science intern,,"Areas of Work: Microsoft Azure Studio, Natural Language Processing, Text Summarization
Key Projects:
- Working on an invoice abstraction project to generate models for various templates for vendors.
- Also working in parallel on a text interchangeability feature to replace similar meaning words with one
single synonym.
- Working on an NLP pipeline for next word prediction and sentence completion.",,,,,,,,,
,,YES,Data Analyst,Oracle center,"Areas of work: Machine Learning, Natural Language Processing, Cluster Analysis 
Key Projects:
- Modeled a Phrase extraction pipeline using Natural Language Processing to identify relevant keywords based on Business Unit requirements.
- Optimized text search response time by 25% through two levels of keyword matching and parallel processing.
- Deployed a continuous learning system that provides a real-time solution-specific prediction for early incident detection with 90% accuracy.
- Cluster Analysis on client feedback data highlighting features of key parameters that are affected, along with a PowerBI dashboard.
- Built a recommendation system with 95% accuracy, that predicts files to be changed to implement Change Requests.
- Collaborated with users for different projects to evaluate project efficiency and reduction in effort.",,,,,,,,,
39. Suyash,"English, hindi, marathi",,Senior Data Scientist,Discover financial services,"
- Independently conducted data analysis with machine learning, presented findings to the VP leading to approval for A/B test. Streamlining Employment Verification reduced friction and boosted conversion by 5%, adding $114MM annually.
- Built decision trees to identify predictors of defaulting on payments and derive insights. Recommended credit tightening rules on identified customer segments. Resulted in a 15% reduction in losses, as demonstrated by performance metrics.
- Funnel analysis of new Automated Loan System found bugs with Chase Customers on MAC, bug fix implemented by engineering team, improved user experience, user growth and added $3MM in originations.
- Lead collaboration to build use cases, gathered requirements, built wireframes, and migrated legacy codes from SAS, to design 10+ dashboards for stakeholders, streamlined monitoring, cutting manual reporting time by 5 Hrs/Week.
- Weekly Reporting and analytics of verification customers 
- Monthly Reporting and analytics of verification customers",UTD,MSBA,1 year 10 months,4 years and 4 months,Financial services,Information Services,"Chicago, illinois",Pune,
,,,Data scientist Intern,Kaizen Analytix,"- I leveraged SQL Alchemy to extract and analyze SEC data, generating insightful reports for our CEO highlighting the top investors in cloud technologies. As a tech consultancy, this effort paved the way for identifying and capitalizing on fresh business prospects. Subsequently, our sales team achieved the successful acquisition of two new clients, further solidifying the growth of our rapidly-expanding consulting firm.
- Developed an algorithm to cluster user sessions into high and low intent categories, using cosine similarity as a proxy for city distance, resulting in improved personalization and user experience for MakeMyTrip website.
- Built ETL pipelines and deployed fraud detection model on AWS Sagemaker; added High-Risk Flag on top of 2-FA
- Designed Prophet + LSTM hybrid time-series prediction model for Toyota, enhanced sales forecasting, and achieved an 8.48% reduction in prediction errors from previous models.
- Subscription Retention rate analysis for an Indian OTT, change in marketing strategy resulted in an 8% LTV increase",,,,,,,,,
40. Sameeullah Babar,English,,Data scientist,Interpolar Inc,"Led development of predictive models which increased customer engagement by 20% and generated a 10% increase in sales
Developed and deployed advanced machine learning and statistical models optimizing pricing strategies, resulting in an 18% increase in profit margins
Collaborated with marketing to analyze consumer behavior and implement targeted campaigns, leading to a 35% increase in click-through rates
Designed and configured ETL processes on abstract data from a broad range of systems to conduct special research requests
Created informative and visually appealing data visualizations and dashboards to communicate findings to non-technical stakeholders and colleagues",UTD,MSBA,9 years and 9 months,All in US,"Technology, Information and Internet",N/A,"Dallas, texas",USA,
41. Justin Thomson ,English,,Data scientist,Quantum Integrators,"• Designed demand forecast ML models using Vertex AI after performing ETL, feature engineering, clustering and other statistical analysis using Python and Excel leading to 30% improvement in forecast accuracy.
• Created a demand forecast model using Prophet in Python and created a stock allocation algorithm to improve unhealthy stock.
• Performed exploratory data analysis on data extracted and loaded from multiple sources and fed it into feature engineering algorithms, clustering analysis and regression models.
• Leveraged predictive and inferential advanced statistical and machine learning techniques to solve business problems such as regional stock balancing, inventory management and safety stock analysis.
• Maintained ETL data pipelines for data from warehouse management system to Google Cloud Platform and into SAP.",UTD,MSBA,13 years and 6 months,3 years,IT Services and IT Consulting,Retail,"Dallas, texas",Maharashtra,
,,,Data scientist,GameStop,"• Created demand forecast model for Gamestop using Prophet for 36 million product location combination.
• Implemented SAP UDF model and forecast for 13000 products and 3000 stores using clustering algorithms in Python.
• Created regional stock balancing and stock replenishment model using Excel and Alteryx.
• Automated data pipelines for ETL and forecasting models using SQL queries.
• Designed and maintained dashboards in PowerBI
• Automated business reports using SQL in Google BigQuery.• Created demand forecast model for Gamestop using Prophet for 36 million product location combination. • Implemented SAP UDF model and forecast for 13000 products and 3000 stores using clustering algorithms in Python. • Created regional stock balancing and stock replenishment model using Excel and Alteryx. • Automated data pipelines for ETL and forecasting models using SQL queries. • Designed and maintained dashboards in PowerBI • Automated business reports using SQL in Google BigQuery.",,,,,,,,,
"42. Jiahao Z.
 ","English, Chinese",,Data scientist,Walmart Global tech,"Data Scientist and Machine Learning Engineer on projects in the area of operations, and inventory optimization.
Role encompassing laying out DS roadmap for projects, and work with business, product and engineering while overseeing work of data scientist on the project and contributing as IC.

Developed time series/classification models of varied complexities from regression to deep learning. Integrated CI/CD and MLOps with projects from scratch.

Projects: Fresh Sales Tool, Own Your Inventory, Club Pick Up.",Texas A&M,"MS, econometrics and quantitative economics",3 years 10 months,All in US,Software Development,N/A,"Dallas, texas",China,
43. Sagar Sanghavi ,"English, Hindi, Marathi",,Data scientist,Walmart,"• Developed Gen AI chat bot to answer business question on Sam’s club membership, in-club and online data
• Analyzed costs associated in shipping a product to calculate profitability and grouped money losing products to identified opportunities for improvement by influencing procurement, product price and shipping fee
• Managed a team of 2 Data Scientists to lead Sam’s membership, Ecommerce Sales and Fraud stakeholder asks
• Developed membership revenue, sales revenue and profit forecasts for next 5 years that included impact of making changes to Member Shipping policy by integrating inputs from Churn prediction model that I developed",UTD,MSBA,8 years 8 months,7 years,Retail,Software Development,"Dallas, texas","Mumbai, MAH",
,,,Data scientist,Meta,"• Developed road map for WhatsApp for Business app (biggest business messaging app) which has over 180M
monthly active users to drive customer onboarding, engagement, and retention
• Defined top line metrics for WhatsApp Business app and developed forecasts for leadership/external reporting
• Designed AB tests, defined success criteria and analyzed post launch metrics for new features like Multi Device
extension which increased the adoption for the feature from 10% to 17%
• Performed analyses on daily Business usage data on app to collaborate/support Product Manager and other
cross functional partners to make data driven product decisions",,,,,,,,,
,,,ML engineer,Tiger Analytics,"• Used Docker to create images of existing code which was uploaded to AWS Sagemaker
• Deployed existing code in Sagemaker and coverted sklearn models to Sagemaker models",,,,,Business Consulting and Services,,,,
,,,Sr Data scientist,Nielson,"• Assisted Product Leadership in scoping, development and execution of new research plans and methodologies by trend analyses, data integration, automation, generalization, harmonization
• Developed new methodologies to measure cross-platform audience on new digital devices and platforms, leveraging data from multiple sources by applying statistical techniques
• Evaluated quality and accuracy of demographic data from these sources, using statistical models and existing Nielsen data assets
• Owned analyses for the Methods group by doing product analyses, handling client inquires, scoping impact of changing methodologies, standards, and best practices
• Collaborated with cross-functional teams to design, implement, and test new consumer and audience measurement methodologies
• Developed code, automated methodologies and translated code from R in Python, Py-Spark and Spark-SQL",,,,,Software Development,,,,
,,,Data scientist engineer,Aplha Ori technology,"• Worked with project managers of different business divisions to generate ideas on how to use data to make processes more efficient by deriving intelligence from the data
• Assisted in scoping and designing analytic projects and solutions, bringing in and testing innovative ideas for out-of-box solutions and created multiple Proof of Concepts
• Trained and tested the various machine learning techniques on data to investigate credence to hypotheses on different business challenges and designed algorithms do solve different business use cases
• Worked with technology team to support machine learning algorithms in big data platform to solve business problems by deploying production level code in parallel processing environment
• Executed analytic projects ranging from small to large both individually or as part of a project team
• Developed Predictive Maintenance algorithm to decrease downtime of different industrial machines• Worked with project managers of different business divisions to generate ideas on how to use data to make processes more efficient by deriving intelligence from the data • Assisted in scoping and designing analytic projects and solutions, bringing in and testing innovative ideas for out-of-box solutions and created multiple Proof of Concepts • Trained and tested the various machine learning techniques on data to investigate credence to hypotheses on different business challenges and designed algorithms do solve different business use cases • Worked with technology team to support machine learning algorithms in big data platform to solve business problems by deploying production level code in parallel processing environment • Executed analytic projects ranging from small to large both individually or as part of a project team • Developed Predictive Maintenance algorithm to decrease downtime of different industrial machines",,,,,Software Development,,,,
,,,Data science intern,Progress,"• Managed data aspects of a customer engagement by handling of huge client data greater than 10GB at times and reported discrepancies in data back to the client and came up with techniques to clean the data 
• Developed python script for cleaning and preprocessing of client data to get it in format consumed by data pipeline and automated it leading to decrease in effort of engineering team from 4-6 days to less 3-5 hours 
• Developed and deployed production level code to implement scalable supervised and unsupervised machine learning techniques in parallel processing frameworks like Spark ML or Dask infrastructure in python 
• Collaborated with different clients to solve their use case and deliver results for different phases within timeline
• Identified anomalies on time series sensor data from different equipment data to define machine state and developed algorithm to calculate risk score and remaining usable life of the equipment to prevent failure
• Developed binary search to tune the parameters of an estimator and increased the model prediction by 1.7%
• Helped the company migrate to deep learning by implementing Tensor Flow and used LSTM for model training which led to an increase of 3% in the model accuracy on different client datasets which are over 1TB in size
• Developed code for ensemble of scalable machine learning techniques(random forest, gradient boosted trees and so on) in Spark ML (pyspark and scala-spark)",,,,,Software Development,,,,
44. Swapnika Amancha ,"English, Tamil",,Solomon associates,AI engineer,,UTD,MSBA,6 years 7 months,1 year and 3 months,Oil and Gas,healthcare,"Dallas, texas",Chennai,
,,,Solomon associates,Data science intern,"Fine tuned large language models for domain-specific data, achieving a 95% accuracy rate in classification task. This enhancement streamlined benchmarking industry processes, resulting in faster outcomes.Fine tuned large language models for domain-specific data, achieving a 95% accuracy rate in classification task. This enhancement streamlined benchmarking industry processes, resulting in faster outcomes.
",,,,,,,,,
45. Sehjbir Singh Randhawa,"English, hindi",,Vanguard,Sr data scientist,,UTD,MSBA,8 years and 4 months,6 years and 4 months,Financial Services,Telecommunications,"plano, texas",Delhi,
,,,,Ericsson,"- Developed scientific methods, processes and systems to extract knowledge or insights to drive the future of applied analytics. 
- Mined and analyzed data from company database to drive optimization and improvement of product development and business strategies. 
- Developed custom data models and algorithms to apply to data sets. 
- Assessed the effectiveness of new data sources and data gathering techniques. 
- Used predictive modeling to enhance customer experiences.
- Defined how to instrument, prioritize and store data that powers AI/ML solutions. 
- Designed and implemented scalable and durable data models 
- Evolved and optimized data and data pipeline architecture, as well as optimized data flow and collection for multi-functional teams. 
- Supported data science teams, partners on data initiatives and ensure efficient data and model architecture is designed and implemented successfully and efficiently. 
- Developed end-to-end automation of data pipelines, making datasets readily-consumable by the data science teams or downstream AI/ML applications. 
- Empowered junior teams members and lead by example.",,,,,,,,,
,,,Data scientist Co-op,Ericsson,"Provided data analytics expertise
- Built machine learning models, APIs and analytics Platform for Ericsson
- Prototyped in Python, Pyspark and scripting in R",,,,,,,,,
46. Prasun Pokharel ,English,,Data scientist,Merck,"As a Data Scientist at Merck in Dallas, TX, I have been instrumental in enhancing fraud detection and loan default prediction through advanced machine learning techniques. I addressed highly imbalanced datasets using undersampling, oversampling with SMOTE, and cost-sensitive algorithms with Python Scikit-learn. My role involved writing complex Spark SQL queries and developing MapReduce/Spark Python modules for predictive analytics on AWS Hadoop. I ensured data quality and integrity through extensive data cleaning with Pandas and Numpy, and I performed feature engineering, including feature intersection generation, normalization, and label encoding. I significantly improved predictive model performance by utilizing algorithms such as Random Forest, Gradient Boosting, Naïve Bayes, and XGBoost. I also conducted real-time analysis with Spark and prepared data for Tableau dashboards using Alteryx and Teradata SQL Workbench.

Key Contributions:

- Enhanced fraud detection accuracy using advanced resampling techniques and cost-sensitive algorithms.
- Developed and optimized Spark SQL queries and MapReduce/Spark Python modules, boosting data processing efficiency on AWS Hadoop.
- Improved data quality and consistency through rigorous data cleaning and feature engineering practices.
- Achieved high predictive performance with machine learning models, applying Random Forest, Gradient Boosting, and XGBoost.
- Conducted real-time loan default analysis using big data tools like Spark and Mllib on AWS.
Streamlined data preparation for Tableau dashboards, enabling efficient data visualization and insights delivery.",University of the cumberlands,MSDS,7 years 6 months ,All in US,Pharmaceutical Manufacturing,IT Services and IT Consulting,"Irving, texas",India,
,,,Data scientist,master card,"I was a Data Analyst/Data Scientist at Mastercard in San Francisco. I played a pivotal role in translating application requirements into comprehensive data models and supporting the standardization of data-related documentation. Collaborating with the Data Engineer team, I facilitated data acquisition by extracting historical and real-time data using tools such as Sqoop, Pig, Flume, Hive, MapReduce, and HDFS. I utilized Hive to write user-defined functions for data manipulation and leveraged Python libraries like pandas and numpy for data cleaning and feature engineering. I applied clustering algorithms, such as Hierarchical and K-means, and performed advanced time series analysis using ARMA and ARIMA models. My responsibilities included designing and maintaining a robust Tableau report repository, creating dynamic visualizations, delivering actionable insights to executive teams, and driving data-driven decision-making.

Key Contributions:

- Translated complex application requirements into detailed data models, enhancing data standardization and application efficiency.
- Facilitated data acquisition and extraction processes using advanced Hadoop tools, improving data availability and integration.
- Developed user-defined functions in Hive and performed data cleaning and feature engineering with Python, ensuring data accuracy and quality.
- Applied clustering algorithms and time series analysis for demand forecasting, providing critical insights for strategic planning.
- Designed and maintained a comprehensive Tableau report repository, creating dynamic visualizations that supported business intelligence initiatives.
- Delivered actionable research results and recommendations to executive teams, driving priority project implementations and strategic decisions.
- Implemented advanced Tableau features and published workbooks with row-level security, ensuring secure and efficient data visualization.",,,,,IT Services and IT Consulting,,,,
,,,Data analyst,Ford motor company,"As a Data Integration and Reporting Specialist, I designed and implemented robust ETL solutions using SSIS to ensure accurate and efficient data flow into data warehouses and marts. Leveraging Microsoft SQL Server 2008 R2, I developed and optimized complex SQL queries, stored procedures, and views to meet diverse reporting needs. I engineered various SSIS packages utilizing transformations like Pivot, Fuzzy Lookup, and Aggregate to streamline data migration from SAS to SQL Server. My role involved crafting and deploying comprehensive financial and performance reports using SSRS, which included parameterized and ad-hoc reports distributed via mailing server subscriptions and SharePoint. Additionally, I utilized SAS for advanced data analysis and statistical modeling, providing critical insights for mortgage products through methods like regression analysis and cluster analysis.

Key Contributions:

- Designed and optimized ETL processes using SSIS, enhancing data accuracy and workflow efficiency.

- Developed and maintained complex SQL queries and stored procedures, ensuring high-performance data retrieval.
- Created dynamic and parameterized reports in SSRS, facilitating detailed financial analysis and strategic decision-making.
- Migrated data seamlessly from SAS to SQL Server, improving data accessibility and integration.

- Conducted advanced statistical analyses with SAS, supporting mortgage product research and development.
- Engineered performance reports that provided crucial business insights, driving organizational growth and profitability.",,,,,Automobile,,,,
"47. Li Wang, Ph.D.",English,,Data scientist,Vanguard,,UTD,MSBA,2 years and 4 months,All in US,Financial Services,Bank,"Dallas, texas",,
,,,Financial Quantitative officer,Comerica bank,"* Spearheaded the development of an early warning ML/DL model relying solely on 2B transaction data to predict defaults a year ahead.
* Amplified model performance by 29% via sophisticated feature extraction strategy and diverse algorithms like XGBoost, RF and NN on AWS.
* Implementing and monitoring loan-level credit risk rating models and Pre-provision Net Revenue models. 
* Testing and monitoring the loanable amounts against securities-backed portfolios. 
* Coordinated event communications and announcements as Communications Director for the Comerica Quantitative Professionals Network.",,,,,Bank,Retail,,,
,,,Data Scientist,DriveTime,"* Developed an ML model to forecast loan reinstatement and designed business strategies in collaboration with stakeholders.
* Executed ETL for 370,000 samples in Snowflake, built data processing pipeline, performed EDA, modeling & visualization in Python
* Explored moles in Azure autoML, and deployed outperformed lightGBM model with feature selection and hyper-parameter tuning.
* Powerfully rank-ordered the customers with the model, spotlighting the top 10% of accounts with a 71% reinstatement rate. 
* Elevated the reinstatement rate, boosting re-marketing efficiency and curtailing communication expenses",,,,,Retail,healthcare,,,
,,,Data Scientist,SAANS health,"* Provided actionable insights for Life Sciences industries, optimizing drug market positioning and enhancing ROI.
* Mapping patients' disease journey with sequential pattern mining to anticipate subsequent treatment and outcome.
* Utilized SQL to generate datasets from claim database, deployed ML models for Line of Therapy Algorithm in R/Python.
* Leveraged Natural Language Processing techniques, specifically topic modeling, to glean patient insights from online reviews.",,,,,healthcare,,,,
48. Jingjing Zheng,"English, chinese",,Data Scientist,Trinity industries,,Steven's Institute of technology,MS Financial engineering,5 years 1 month,4 years 7 months,Truck Transportation,"Technology, Information and Internet","Dallas, texas",China,
,,,Data Scientist,Prodapt,"• End to end data science pipeline building with H2O and airflow. Including data extraction, data analysis, feature engineering, ai modeling, validation reports generation and automation.
• Implemented Python to build machine learning models, including clustering, classifier, NLP, deep learning and GenAI models like VAE
• Improved precision by 20% by data analysis and feature engineering
• Improved total model performance by integrating different type of data like public weather API to pipeline
• Preprocessed large dataset with Hive, Oracle, saleforce, cloud storage and bigquery with api in Python.
• Model interpretation with SHAP, LIME and Eli5
• API integration of REST, endpoint. And optimize API calls by multiprocessing and async.
• Cloud management through Google cloud storage, cloud function, bigquery, kubernetes.",,,,,,,,,
"49. Ashwin Ravishankar
",English,,Data scientist,Agility Health,"● Enhancing the Team Health Radar project by leveraging AI insights through competency correlation and cluster analysis, identifying top drivers for team performance optimization. 
● Automated AI Insights to pinpoint key improvement areas across teams, utilizing historical data and machine learning to discover patterns related to performance indicators, based on quarterly assessments.",UTD,MSCS,1 year 2 months,All in US,healthcare,IT Services and IT Consulting,"Dallas, texas",USA,
,,,Full stack developer,iOpen innovations,"● Developed and implemented advanced Machine Learning algorithms using Python to accurately detect hotel room presence, resulting in a 90% decrease in false alarms.
● Utilized React JS to create a responsive web application and optimize the front-end architecture.",,,,,IT Services and IT Consulting,,,,
,,,ML intern,Techminds group LLC,"● Generated advanced predictive and interactive data models using Python leveraging libraries including Tensorflow, Pandas, Plotly, and SciKit Learn to derive actionable insights from company datasets.",,,,,IT Services and IT Consulting,,,,
50. Jianli Zhou,English,,Data scientist,Lantern Pharma,"* Leverage machine learning, statistics, genetics, and cancer genomics to identify gene signatures and select unique sets of oncology patients who can benefit from the drugs/treatment
* Develop preclinical study plans and manage projects conducted by contract research organizations such as ReproCELL USA
* Generate insights from in silico analysis and preclinical studies to move drugs through development pipelines
* Prepare abstracts and manuscripts for key oncology conferences and publication
* Support the principal software architecture in constructing and maintaining the AI-based oncology drug platform using specializations in data sciences and biology",UTD,MSITM,14 years 3 months,All in US,healthcare,healthcare,"Dallas, texas",USA,
,,,Data scientist and platform development intern,Lantern Pharma,"* Developed a data analysis pipeline to speed up drug target discovery and guide preclinical studies
* Conducted cancer genomic data and mutational signature analysis to help select potential patient groups that would respond better to certain cancer therapies",,,,,,,,,
51. Harish Verlekar,"English, marathi",,Data scientist,Bungee Tech ,- Building and designing the Product Matching pipeline by using state-of-the-art Natural Language Processing and Computer Vision models. - Constructing ETL pipelines powered by PySpark to crunch and pipe data from various data sources. - Define metrics and track various KPI's owing to measuring the progress of the project. - Work and communicate with multiple stakeholders to drive the successful execution of the project.,"UT, arlington",MSCS,4 years and 8 months,3 years and 10 months,"Technology, Information and Internet",N/A,"Seatle, washington",Maharashtra,
,,,Data scientist intern,Bungee Tech ,"- Built Data-Pipeline for retail data which includes NLP and Image models using Unsupervised Learning.
- Focused on experimenting and developing R&D business use-cases by leveraging state-of-the-art Deep Learning models.
- Used AWS and Azure cloud services to build, validate and deploy models adhering to CI/CD.",,,,,,,,,

Name,Languages spoken,Indian Experience,Role,Company,job description,University,Course,Work experience,Work experience in the U.S,Industry,Previous industry type,Location,Location from India,Linked Profile (from 6th no.)
1. Nitika Sharma ,"English, Hindi",,Business Intelligence Engineer ,Amazon,"Business Intelligence Engineer Intern | Industry: Retail | AWS Redshift, Spark, Amazon Web Services, Advanced SQL, Data Grip, Data Net
• Designed and Implemented a real-time data pipeline to process semi-structured data by integrating more than 100 million
records for 3 different regions using Data Net and Amazon Redshift.
• Executed a project to create metrics to check the capacity constraints of 12 Supply chain lanes across United States region.
• Partnered with Product Managers to understand and implement new specifications in data transformation and analysis.
• Successfully spearheaded and deployed the dashboard for analysis and forecasting of package flows and decreased the under
biasness of package flow by 20%.",University of Texas at Dallas,"Master's Degree, MS, Business Analytics",4 years ad 6 months,1 Years 11 Months,E-commerce and Software Development,Financial services,"Dallas, Texas, United States",Delhi,
,,,Data manager,Moody's investor services,"• Collaborated with Managing Directors & Senior Vice Presidents to perform a comprehensive analysis of customer needs to identify diverse data domains and complex processes to optimize overall business operations.
• Orchestrated the creation and mapping of data attributes to facilitate the digitalization of Moody's complete workflow.",,,,,,,,,
,,,,,,,,,,,,,,
2. Soumyashree Javali,"English, Kannada",,Senior Analyst- Business Intelligence,DaVita Kidney Care,,University of Texas at Dallas,"Master's Degree, Information Technology and Management",4 Years 6 Months,1 Year 9 Months,Hospitals and Health Care,Business Consulting and Services,"Denver, Colorado, United States",Bangalore,
,,,Business Intelligence Analyst,"DeWolff, Boberg & Associates","• Increased efficiency of employee performance and reduced attrition by 65% bymanaging client’s Database for
the in-house application called Worksite.
• Built ETL jobs to integrate data from clients into SQL server using TALEND and performed
data transformations on critical parameters.
• Collaborated with the Managing consultants on client’s requirements and built Stored Procedures using
T-SQL to calculate KPI for each client to visualize the data and generate reports on Worksite.",,,,,,,,,
3. Kyung Seob,"English, Korean",,"
Business Intelligence Developer",Altair Global,"• Client Data Database Extraction/Visualization based of clients’ request, including Fiscal Year-base Dashboard, Status Report, and Statistical Analysis Report
• SQL Server’s Database Pipeline Development/Maintenance/Optimization for both designated client report and General Purpose Data Structure
• Business Intelligence Transformation (Microsoft PowerBI) in progress",University of Texas at Dallas,"Master's Degree, MS, Business Analytics",3 Years 3 Months,1 Year 7 Months,Human Resources Services,Computer and Network Security,"Frisco, Texas, United States",USA,
,,,"
Data Product Engineer",Imperva,"• Analyzed Algorithm of System Resource Grapher tool with Data Analysis, and contributed the new feature’s ideation to upcoming version of GTI(Get Tech Info, Server-side) Grapher Tools
• Established VM Testing Environment of Products (3 Products, Full documentation built) to produce the analysis data security structure to Internal Trainee and Customers/Clients
• Supported Clients’ Security issues and Products’ errors with Product Support Division, resulting in 0% Of Clients’ security breaches",,,,,,,,,
4. Natalie Boll,English,,"
Business Intelligence Analyst Intern",PPI,"As a Business Intelligence Analyst for PPI I create tools for forecasting and pace, KPI and SIOP reporting, backlog, and general business information.",University of Iowa,Business Analytics and Information Systems,1 Year 3 Months,US Citizen,Mining,,"Pella, Iowa, United States",USA,
5. Diana Francisco Almeida,English,,Senior Business Intelligence Developer,Mutual of Omaha,"• Identified business information needs and system requirements across many Strategic Business Units (SBUs).
• Led MAPS testing team, promoting continuous improvement and effective project execution. 
• Led projects by identifying and developing cost-effective solutions, procedures, reporting, and analysis tools to meet business intelligence objectives.
• Managed and contributed to data and quality standards, controls, procedures, and documentation.",Westcliff University,"Master of Business Administration, MBA, Data Driven Decision Making",6 Years 1 Month,2 Years 8 Months,Financial Services,Wireless Services,"Omaha, Nebraska, United States",USA,
,,,Business Systems Consultant,GP Mobile,"• Conducted Proof of Concept (POC) for F&A automation projects, presented evaluations and recommendations, contributing to 90% of implementation.
• Conducted gap analysis, defined future state, and implemented process improvement to reduce repetitive manual operations by 60%.
• Developed process maps for highly complex and visible projects in Finance, Actuarial, and MAPS.
• Contributed to discussions on project progress and risk mitigation strategies with the project leadership.
• Coached team members and stakeholders on process improvement strategies.",,,,,,,,,
6. Shubham Tripathi ,"English, hindi",,"Manager, Fraud Management",TD,,,,,,,,,,https://www.linkedin.com/in/shubham-tripathi-/
,,,Business Intelligence Intern,Siemens Digital industries software,"● Developed ETL (Extract, Transform, and Load) pipelines using the Pentaho Data Integration tool to transfer data from the current on-premises Vertica data warehouse to a cloud-based data warehouse solution
● Worked with business stakeholders to identify data requirements and provide data insights to support
decision-making
● Built analytical reports and dashboards using various BI tools including Power BI and Tableau● Developed ETL (Extract, Transform, and Load) pipelines using the Pentaho Data Integration tool to transfer data from the current on-premises Vertica data warehouse to a cloud-based data warehouse solution ● Worked with business stakeholders to identify data requirements and provide data insights to support decision-making ● Built analytical reports and dashboards using various BI tools including Power BI and Tableau
",UTD,MSITM,4 years,1 year and 5 months,Banking,Software Development,"Dallas, texas ",Delhi,
7. Vamsi Krishna Kanderi Murali,"English, tamil",,Business Intelligence Engineer,Gainwell Technologies,Product Analytics and Management team,UTD,MSBA,3 years 1 month,10 months,IT Services and IT Consulting,N/A,"Dallas, texas ",Chennai,https://www.linkedin.com/in/vamsikanderi/
,,,Data science intern,Gainwell Technologies,"• Optimized SQL queries using efficient indexing utilizing Python and PySpark to tackle patient data access bottlenecks, achieving a 40% faster retrieval from clinical, billing, and electronic health record systems (EHR)
• Predicted disease prognosis from EHR data leveraging XGBoost and logistic regression algorithms using python, yielding a 15% increase in F1-score and saving an estimated $150K annually in healthcare costs",,,,,,,,,
8. Chakshu Bansal,"English, hindi",,Business intelligence analyst,American Airlines,"Leveraged SQL and Alteryx to perform ETL operations, creating comprehensive Power BI reports that enhanced
contract negotiations, contributing to a 20% increase in successful deals.
• Conducted in-depth analysis of the AAdvantage loyalty program, leading to a 15% surge in program engagement
through strategic recommendations and tactical launches.
• Elevated the Power Bi and Tableau dashboards crafting engaging custom visuals and precise measures.
Additionally, utilized Python and R for data manipulation and analysis, enhancing the depth of insights derived
from the data to thoroughly examine Corporate Sales or Agency sales performance across various channels and
areas, aiding in informed decision-making and strategic planning.
• Automated sales reports using Databricks, Azure Data Factory and Paginated reports, reducing report generation
time by 40%.
• Developed robust data validation processes in SQL, ensuring high data integrity and reliability for strategic decision-making.",USF,MSBAIS,8 years 8 months,1 year and 10 months,Airlines and Aviation,Retail,N/A,Chandigarh,https://www.linkedin.com/in/chakshu-bansal-039aa935/
,,,Data analyst intern,Costco,"• Initiated to create a Power BI report to show effective license position findings identified by publishers which was used 
to identify the optimization opportunities and highlight cost avoidance. This report was used by all Costco teams.
• Imported, transformed, and rationalized data from multiple data sources and operationalized data by loading, 
validating, and reviewing on a timely basis while normalizing data where and when needed.
• Comparative review of overlapping data sets, which includes, identifying data anomalies, identifying data-related issues 
and sources, Supporting troubleshooting of root causes and resolution of discrepancies• Initiated to create a Power BI report to show effective license position findings identified by publishers which was used to identify the optimization opportunities and highlight cost avoidance. This report was used by all Costco teams. • Imported, transformed, and rationalized data from multiple data sources and operationalized data by loading, validating, and reviewing on a timely basis while normalizing data where and when needed. • Comparative review of overlapping data sets, which includes, identifying data anomalies, identifying data-related issues and sources, Supporting troubleshooting of root causes and resolution of discrepancies",,,,,,,,,
9. Catherine Ganduri ,English,,"Business Intelligence Analyst

",Texas Commission on Environmental Quality ·,"• Proficiently utilized Crystal Reports and SQL to generate insightful reports, resulting in a significant 30% increase in data-driven decision-making efficiency through the creation of 50 reports. • Played a pivotal role in ensuring seamless data sharing as part of the Enterprise Reporting Team, achieving a 95% success rate in addressing customer inquiries, leading to a 20% improvement in data sharing efficiency. • Leveraged technical skills and data analysis proficiency to maintain and develop recurring reports, fostering a notable 40% increase in data comprehension and informed decision-making within the organization through the successful maintenance and improvement of 25 recurring reports. • Acquired skills as a GIS Analyst, specializing in advanced geospatial data analysis techniques, data visualization, and proficiency in geospatial data analysis highlighting a strong commitment to continuous learning and skill development.",UTD,MSBA,3 years and 4 months,1 year and 3 months,Environmental Services,IT consulting and IT services ,"Austin, texas",Hyderabad,https://www.linkedin.com/in/catherine-ganduri/
,,YES,Data Engineer,TCS,"
• Responsible for gathering and documenting metadata for more than 500 data elements related to critical business operations, data quality, finance metrics, and reporting.
• Successfully led cross-functional team projects aimed at improving data quality and consistency, resulting in a notable 15% reduction in data errors through the implementation of Data Mapping and Validation strategies.
• Certified data for remediation, external board reporting, policy implementations, and process improvements, ensuring a 20% increase in data reliability.
• Contributed to Tableau dashboard creation, connecting to the Global Operating System (GOS), and extracting data from various sources to uncover actionable insights for strategic decision-making and process optimization.",,,,,,,,,
10. Vishnuvardhan Veluru,"English, tamil",,"Analytics and Business Intelligence Manager
",Allied Helath ,"● Developed data ecosystem of 20+ data sources and end to end machine learning models for sales forecasting. ● Automated data storing and processing of 5GB+ data per day using Databricks and Amazon Web Services. ● Designed real-time Online analytical processing system and decreased customer acquisition costs by 26%. ● Programmed mathematical models using Causal Inference that effected in increased sales to retention ratio by 13%. ● Optimized customer acquisition methodologies with linear programming using GUROBI,CPLEX models for 1300 points. ● Performed retention analysis using data mining techniques to generate an additional 1.6 million dollars in net revenue. ● Generated ad hoc analyses with accuracy to identify trends, patterns, and insights that drive 5 million business value. ● Created Key Performance Indicator metrics to communicate performance and improvements to stake holders.",UNT ,MSDS,4 years and 10 months,2 years and 8 months,Healthcare,retail,"Richardson, texas",Chennai,https://www.linkedin.com/in/vishnuvardhanveluru/
,,,"Data Scientist 
",Edible Arrangements,"● Developed Mixed Marketing models using Bayesian Statistics for forecasting, effected in increased capital profit by 3%.
● Designed streaming data pipelines for ETL process of large volumes of data using Hadoop Ecosystem and Bigquery.
● Executed A/B testing to address complex business problems utilizing ML techniques and predictive analyses.
● Developed CPLEX optimization model to define the best combination of area codes for optimized delivery routes.
● Applied data mining and machine learning modelling using PySpark and Colab to generate customer segmentation.
● Formulated optimized objective functions with defined constraints, improving customer-to-sales agent ratio and enhancing customer satisfaction by 16%.
● Implemented machine learning models for process simulation resulted in improved operational efficiency by 23%.
● Designed data visualization dashboards using Tableau to Interpret results and communicate to senior management.",,,,,,,,,
11. Ramakrishna Chepuri ,"English, telugu",,Business intelligence developer,Globe LifeGlobe Life,"• Orchestrated data integration processes using DBeaver, achieving a 30% reduction in ETL (Extract, Transform, Load) processing time, enhancing operational efficiency.
• Managed Redshift database performance tuning initiatives, resulting in a 20% improvement in query execution times, enabling faster analytics and reporting.
• Designed and deployed Tableau dashboards that facilitated real-time data visualization and decision-making, contributing to a 15% increase in management visibility into key business metrics.
• Migrated Tableau dashboards to AWS QuickSight, enhancing metrics tracking and data accessibility.",UTD,MSBA,5 years and 9 months,1 year and 2 months,Insurace,Biotechnology Research,"McKinney, Texas",Hyderabad,https://www.linkedin.com/in/ramakrishna-chepuri/
,,,Data Analyst Engineer,MilliporeSigma,"• Conducted correlation analysis between lead time and conversion rate using SQL for data manipulation, Python for statistical analysis, and visualized insights in Tableau, advocating for an aggressive inventory strategy to mitigate potential loss in sales and revenue.
• Orchestrated the transition from Proof of Concept to Industrialization. Conducted data ingestion of 4 datasets into Palantir, implementing manipulations and visualizations for enhanced insights.
• Decreased deployment time by 1-2 weeks through collaboration with stakeholders across cross-functional teams, developing a smooth change management process in JIRA for analyzing impacts from source systems and presenting optimal solutions.
• Developed automated data pipelines to streamline data processing workflows, reducing manual effort by 40% and increasing data accuracy.
• Implemented data quality checks and validation processes to ensure integrity and reliability of data used in decision-making.
• Created comprehensive documentation and training materials for end-users, facilitating a smoother transition to new data systems and tools.
• Collaborated with data engineering and IT teams to optimize database performance and ensure seamless data integration across systems.
• Analyzed historical sales data to identify trends and patterns, providing actionable insights that informed marketing and sales strategies.
• Engaged in continuous improvement initiatives, identifying opportunities for process enhancements and driving implementation to achieve better efficiency and effectiveness in data operations.",,,,,,,,,
,,,Data Analyst Intern,MilliporeSigma,"• Conducted cluster analysis in Tableau, segmenting customers and providing insights for targeted marketing strategies, resulting in a 15% increase in campaign effectiveness.
• Analyzed pricing strategies in Excel, revealing significant sales growth and margin impacts, contributing to a 10% increase in quarterly sales.
• Developed Tableau dashboards covering global sales, customer insights, and product analytics, enhancing decision-making and reducing reporting time by 30%.
• Deployed multiple Tableau dashboards, resolving data accuracy issues and increasing user engagement by 20%.
• Built retention and churn analysis dashboards in Excel, aiding in the identification of key retention strategies.
• Utilized Python Selenium for web scraping to analyze competitor data, providing actionable insights for competitive analysis.
• Identified $2M in potential annual sales opportunities through comprehensive gap analysis of product and customer data.",,,,,,,,,
,,YES,Sr Business Intelligence Engineer,"Mettler-Toledo International, Inc"," • Led BI initiatives for multiple business units including Finance, Sales, and Operations, achieving a 15% average growth in revenue over 2 years.
• Implemented comprehensive BI solutions using Tableau and Power BI, resulting in a 25% increase in executive dashboard utilization.
• Optimized ETL processes, reducing data processing time by 30% and improving data accuracy by 20%.
• Collaborated with cross-functional teams to align BI strategies with business objectives, resulting in a 10% improvement in operational efficiency.",,,,,,,,,
12. Shivangi Tyagi ,"English, hindi",,Business Intelligence Analyst,Paramount,"• Improved monthly subscriber engagement by 8%, developed a Content Discovery Attribution Model aimed to identify the top performing Paramount+ features using data visualization and SQL to further present go-to engagement strategies
• Accelerated the revenue growth by 13%, launched a Revenue Attribution Model for attributing the user’s subscription revenue based on their platform and content engagement, playing a key role in the organization’s financial and broadcasting decisions
• Reduced user dormancy by 4% through conducting a deep dive of >20M user behavior and collaborating with product, marketing, and sales team to synthesize strategies to increase the content consumption on Paramount+",University of cinncinati,MSBA,7 years and 9 months,3 years and 3 months,Entertainment Providers,Business Consulting and Services,USA,Delhi,https://www.linkedin.com/in/shivangi-tyagi/
,,,Senior Product Analyst,"
LatentView Analytics"," • Increased customer operations satisfaction rating by 11%, worked for Microsoft as part of their Business Planning team to conduct usability studies on customer interaction with the Microsoft Edge browser improving user experience
• Responsible for adhoc analysis of performance of volume and other business metrics by extensively using SQL to query data, for specific events like Russia’s war on Ukraine, marketing initiatives, School Holidays
• Developed 5+ interactive dashboards on PowerBI and Excel which automated 90% of adhoc reporting and data requests",,,,,,,,,
,,,Senior Consultant - Marketing Analytics,"
Vonage"," • Led the team to track the outreach of 1000+ marketing campaigns on multiple channels to build a Multi Touch Attribution Model by analyzing unstructured data of 5 million records using tools such as AWS Sagemaker, Snowflake, SQL and Python
• Created live dashboards in Tableau to track KPIs for key marketing campaigns to get actionable insights
• Identified and ranked the best performing campaigns and presented recommendations to VP-Marketing",,,,,,,,,
13. Samhitha Bhat ,English,,Business Intelligence Developer,NXP semiconductors,,UTD,MSBA,4 years,2 years and 9 months,Semiconductor Manufacturing,Semiconductor Manufacturing,"Austin, texas",Bangalore,https://www.linkedin.com/in/samhithabhat/details/experience/
,,,Business Planning Analyst,"
ASML ·
","- Support the implementation of a portfolio management strategy for non-PGP projects
- Monitor 2022 objective KPI status via project tracking tools/visualizations
- Maintain SharePoint site content and return to office roster
- Contribute to automation efforts for time writing approvals and data management- Support the implementation of a portfolio management strategy for non-PGP projects - Monitor 2022 objective KPI status via project tracking tools/visualizations - Maintain SharePoint site content and return to office roster - Contribute to automation efforts for time writing approvals and data management
",,,,,,,,,
,,,Business Intelligence Engineer,NXP semiconductors,"1. Helped improve the factory’s capacity utilization by optimizing factory release schedule using ANOVA, t-test, and hierarchical clustering
2. Developed statistics and key metrics to facilitate diffusion grouping analysis using techniques of advanced analytics
3. Set up the Teradata environment to explore, clean, and prepare structured and unstructured big data for analysis and reporting",,,,,,,,,
14. Mankirat Singh,"English, punjabi",YES,Business intelligence analyst,"Mad About EPL 
","Analyzed website traffic of about 1,500,000 users’ engagement, and relevant metrics to identify trends, patterns. • Leveraged Google Analytics for insights increasing user engagement by 20% through targeted content optimization and segmentation strategies. • Conducted A/B tests on article formats, contributing to a 10% improvement in click-through rates and regular competitor analysis to maintain competitor edge in the football and sports website niche.Analyzed website traffic of about 1,500,000 users’ engagement, and relevant metrics to identify trends, patterns. • Leveraged Google Analytics for insights increasing user engagement by 20% through targeted content optimization and segmentation strategies. • Conducted A/B tests on article formats, contributing to a 10% improvement in click-through rates and regular competitor analysis to maintain competitor edge in the football and sports website niche.",UTD,MSBA,1 year and 5 months,1 year 3 months,Spectator Sports,,"Dallas, texas",Delhi,https://www.linkedin.com/in/mankiratsingh7/
15. Austin Smith,English,,"

Business Intelligence Analyst

",Core-Mark International,- Front-End development of Power BI applications - Project management duties of applications in development - Updating current business applications- Front-End development of Power BI applications - Project management duties of applications in development - Updating current business applications,Texas state university,"MS, Market research and state analysis",4 years and 1 month,All in US,Wholesale,N/A,"Westlake, texas",USA,
,,,"
Marketing Analyst
",Core-Mark International,"- Create and distribute Focused Marketing Initiative plans (FMI). Purpose of FMI's is to drive sales and expand market share.
- Plans include new marketing programs, retail adjustments, space optimization among other suggestions to store owners.",,,,,,,,,
16. Borel T.,English,,Business Intelligence Developer,Ascension,"Built and owned 25+ Tableau dashboards containing complex calculated fields for advanced data visualization of Patient metrics and segmentation. This includes Safety and Compliance, Patient Analytics, Case Sentiment, and Regional Hospitalization Metrics dashboards.

Migrated over 30TB of hyper extracts from Azure Storage to Dremio decreasing pipeline loads and refresh cycles by 38% for all Patient and Compliance dashboards in Tableau Server and Salesforce.

Optimized Legacy SQL queries to improve query performance and reduce SQL analysis run times by 25%.

Worked with large datasets with 50+ Million rows, creating efficient queries to join, segment, and analyze data for ad hoc analyses, weekly and monthly patient reports, and cycled views to be used as extracts for BI dashboards.

Worked through 2-week agile sprints, managing ad hoc requests, balancing priorities, and presenting findings and completed initiatives/projects as required.

Partnered with Data Engineers to create, manage, and maintain Azure and dbt pipelines from ingesting primary data sources to the processing and housing in Snowflake and Dremio for sql analysis, querying, and segmentation.",UNT,BSDS,4 years and 4 months,All in US,Hospitals and Health Care,Automobile,"Dallas, texas",USA,
,,,Data analyst,Toyota motor sales & marketing corp,"Designed and maintained complex SQL queries used in the development of customer reporting tables, complex segmentation, and stored procedures for data analysis and extraction used in automated reports, reducing reporting errors by over 20%.

Assisted in the development of a Python based analytics tool for analysis of our media source pipeline to effectively document, review, and visualize lead generation and conversion metrics for marketing and external clients.

Utilized advanced Excel functions to analyze survey, product, and marketing data from multiple sources.

Utilize DBT to convert raw, unstructured data into structured datasets, implement and manage data models, and guarantee accurate data transformation; enabling efficient analysis and reporting in alignment with business needs.

Worked cross-functionally with sales, product, and marketing stakeholders to plan, develop, design, and manage KPIs, metric reports, and dashboards in Tableau.

Participated in daily scrum meetings, enhancing team communication and project transparency, reducing project delays

Manage multiple ad-hoc projects simultaneously. Balancing deadlines, gathering requirements, leading meetings, and presenting results across multiple teams.",,,,,,,,,
17. Meihua Yu,"English, chinese",,Sr Business Intelligence Engineer,Ally Financial,,UTD,MSBA,9 years and 9 months,3 years and 6 months,Financial services,Advertising Services,"Dallas, texas",China,https://www.linkedin.com/in/meihuayu/
,,,Business Intelligence Engineer,"
Wpromote ·","● Designed data pipeline and automated processes by using Funnel, Domo, Python and Apps Script to extract data from various resources (AWS, Google AdWords, Facebook Manager, Google Sheets, etc.) to BigQuery, helping reporting solution team to leverage recurrent reporting(daily/weekly/monthly) in direct response
● Translated business problem statements and tech specs into analysis requirements by writing SQL queries and creating data models to clean, manipulate and aggregate data for multiple eCommerce and lead source clients, automating data validation and testing process to ensure data consistency and accuracy 
● Worked closely with IT and data engineering team to migrate data from Google Cloud Platform to clients
● Supported marketing team to publish and improve dashboards that convey key performance indicators and trends in Looker",,,,,,,,,
,,,Data Analyst,"
Loopback Analytics 
","• Wrote stored procedure by using JavaScript in Snowflake to connect Jira to Power BI, creating dynamic dashboards to extract insights for internal team and external clients • Worked with sales team to answer industry research questions by querying database in SQL Server and Snowflake and translating business needs into insightful dashboards • Collaborated with data engineers to ensure highest data integrity and accuracy for clients’ requests",,,,,,,,,
18. Diana Francisco Almeida ,English,,Senior Business Intelligence Developer ,Mutual of Omaha,"• Identified business information needs and system requirements across many Strategic Business Units (SBUs).
• Led MAPS testing team, promoting continuous improvement and effective project execution. 
• Led projects by identifying and developing cost-effective solutions, procedures, reporting, and analysis tools to meet business intelligence objectives.
• Managed and contributed to data and quality standards, controls, procedures, and documentation.",UTD,MSITM,8 years and 2 months,4 years and 9 months,Financial Services,Wireless Services,"Omaha, Nebraska",Mumbai,https://www.linkedin.com/in/almeida-diana/
,,,Business Systems Consultant II,Mutual of Omaha,"• Conducted Proof of Concept (POC) for F&A automation projects, presented evaluations and recommendations, contributing to 90% of implementation.
• Conducted gap analysis, defined future state, and implemented process improvement to reduce repetitive manual operations by 60%.
• Developed process maps for highly complex and visible projects in Finance, Actuarial, and MAPS.
• Contributed to discussions on project progress and risk mitigation strategies with the project leadership.
• Coached team members and stakeholders on process improvement strategies.",,,,,,,,,
,,,Data analyst intern,GP Mobile,"• Developed and Managed ETL operations for advancing SQL Server databases to Azure SQL Data Warehouse.
• Enforced Agile Scrum, Kanban, and DMAIC principles, resulting in a 30% improvement in team performance.
• Assisted Product Owners with backlog refinement and establishing acceptance criteria.
• Created KPI alerts in Power BI for sales team, resulting in a 12% increase in revenue.
• Developed Python code to automate the manual process of disputing missing transactions by retrieving data from an API.",,,,,,,,,
19. Ted Andersson,English,,Business Intelligence Analyst,rewardStyle,"Dive into messy and often incomplete data from multiple databases, including SQL and NoSQL
Build sophisticated statistical models in R and Python
Present findings and analysis to business stakeholders, who then turn the insights into actionable strategy 
Developed and deployed an anomaly detection algorithm that proactively identifies pixel tracking errors
Developed social network model for thousands of influencers 
Developed and deployed multiple classification algorithms into production",,,,,Software Development,,,,
,,,"Data ScientistManager, Insights & Instrumentation",Wolters Kluwer Tax & Accounting US,"Developed and deployed a high accuracy forecasting algorithm used to predict call volume in all the major blocks of North American business
Delivered a correlation analysis model to sales leadership which suggests high-value opportunities for upselling in already existing customers
Automate web ticket matches with a knowledge base article repository of more than 45,000 articles
Built a proof of concept chatbot leveraging graph database technology with elastic search to quickly identify the most relevant knowledge base article to a customer. Accuracy gains were more than 60% over the production bot
Automated survey classification using natural language processing to enable call centers to proactively identify customer pain points",,,,,,,,,
20. Hamzah Lydick,"English,",,"Associate, Business Analytics & Intelligence
",ORIX Corporation USAORIX Corporation USA,"• The sole onshore Power BI Developer leading a team of 4 offshore Power BI Developers
• Collaborate with business stakeholders and analysts to understand reporting requirements and translate them into Power BI solutions
• Design and develop interactive dashboards, reports, and data visualizations using Power BI to provide actionable insights to stakeholders
• Responsible for BI team database schemas and the development of all fact and dimension views, including the migration of these views from development to test and production utilizing Visual Studio and Azure DevOps Repos and Pipelines
• Create data models using Power BI Desktop, ensuring data accuracy and efficient data retrieval.
• Utilize DAX to create complex measures and calculated columns for customized business metrics and KPIs
• Conduct data cleansing and transformation starting with SQL, then Power Query Editor in Power BI to ensure data integrity and consistency
• Work closely with data engineers and database administrators to optimize data sources for optimal performance in Power BI
• Implement row-level security and data security measures to restrict data access based on user roles and permissions
• Collaborate with cross-functional teams to troubleshoot and resolve issues related to Power BI reports and data connectivity
• Stay up to date with the latest Power BI features and best practices to continuously enhance reporting capabilities and user experience
• Provide training and support to offshore developers and to end-users on Power BI tools and functionalities","Texas A&M, commerce",MSBA,7 years,all in us,Financial Services,Hospitals and Health Care,"Dallas, texas",USA,https://www.linkedin.com/in/hamzahlydick/
,,,Reporting Analyst IIReporting Analyst II,"
Pioneer Natural Resources Company","• Supported the Supply Chain Management team in developing and monitoring KPIs to benchmark activities and proactively identified changes in the business
• Utilized advanced SQL with Microsoft Azure Databases and Oracle relational databases, including querying of TIBCO data virtualization views
• Developed Power BI Dashboards with extensive use of DAX and advanced data modeling techniques
• Introduced and implemented proper data modeling techniques into Power BI reporting and enhanced the analytics processes of SCM teams by introducing the PBI Analyze in Excel functionality
• Performed extraction, transformation, and loading (ETL) of structured and unstructured data with Alteryx
• Introduced data management best practices with a focus on data integrity, governance, and efficiency
• Led the cleanup of the SCM Reporting Analytics team SQL database schema design",,,,,Hospitals and Health Care,Motor Vehicle Manufacturing,,,
,,,Reporting and Analytics Analyst,"AccentCare, Inc.","
• Developed and prepared, forecast, profitability and pricing reporting
• Automated manually compiled Excel reporting with Power Pivot Data Models 
• Created, maintained, and administered Qlik, Tableau and Power BI Dashboards
• Regularly audited data to ensure accuracy and identify discrepancies between sources
• Advanced use of SQL with SSMS and the Microsoft relational database",,,,,,,,,
,,,Business intelligence analyst,Caliber collision,"• Managed ERP, financial planning, budgeting, operating plan variance analysis, financial reporting, data analytics systems, and special projects assigned
• Built data models in Visual Studio SSAS Tabular, Power BI and Power Pivot, along with advanced use of SQL and the DAX languages
• Conducted trend analysis of key performance indicators including all areas of revenue, cost of sales, expenses and capital expenditures and analyzing causes of unexpected variance
• Developed financial models and analyzed complex financial information and reports to support strategic initiatives
• Performed system maintenance, user support, upgrade activities, planning, testing, implementations and integrations
• Assessed opportunities to integrate 3rd party data to drive key metrics",,,,,,,,,
21. Aaqib Mohammed Mohiuddin,"English, Hindi",,Business intelligence analyst,Kemper,,University of Illinois at Chicago,BS Information and Decision Sciences,2 years 6 months,all in us,Insurance,Personal care,"Irving, Tx",,
"22. Pranati Thakare
","English, Hindi, Marathi",Yes,Business intelligence analyst,SmartestEnergy ,,UTD,MSBA,4 years 3 months,2 year 2 months,Energy,Energy,"Dallas, Tx",,
23. Edison (Xiaochen) Li,"English, Chinese",,Business Intelligence Engineer,Republic Finance,,Southern Methodist University,MSBA,4 year 4 months,all in us,Finance,Finance,"Dallas, Tx",,
24. Eileen Hua,"English, Chinese",,Business Intelligence Analyst,Caris Life Sciences ,,UTD,MSBA,3 year 7 months,all in us,Health/Medical,Health,"Dallas, Tx",,
,,,Data Analyst,Zoetis ,"The world’s leading animal health company, previously Pfizer animal health
Achieved a 25% increase in work efficiency through the implementation of data cleaning and pipeline automation",,,,,,,,,
25. Jared Wilson,English,,Business Intelligence Developer,Smart Start Inc.,,Western Governors University,BS Information Techonolgy Management,17 years 5 months,all in us,Technology,Fuel/energy,"Garland, Tx",,
,,,Senior Data Analyst,Genesis Physicians Group,"•Build, fix, modify SQL reports in ssrs/SQL report builder environment vis-a-vis SharePoint platform.
•Responsible for essential dba functions, such as backups (full, differential) and permissions for staff.",,,,,,,,,
,,,Business Analyst,Exigo Office Inc. ,"•Use SQL to understand and resolve data issues via ad hoc queries.
•C# used in visual studio to understand what code was doing and answer questions and/or make light edits/fixes.
• Interpret and analyze data to relay in between clients and programmers.
• Project Management skills developed on several occasions; assisted from start to completion of many projects.
• Tested changes/implementations made by programmers to verify satisfactory results: includes test case writing.
• Assist department manager with daily operations (reports, subject matter expertise, ticket escalations, etc)
• Interacting with other departments to resolve client’s issues as needed.
• Assisted with training of new hires; guided them through custom company platform and basic operations.
• Effectively the front-line with trouble tickets for my department; mitigate and distribute based on procedures in place.",,,,,,,,,
26. Mounish K.,"English, Telugu",Yes,Business Intelligence Analyst,Stretto,,University of North Texas,MSBA,8 years 2 months,4 years 3 months,Finance/Technology,Media,"Dallas, Tx",,
,,,Data Analyst Intern,Comscore Inc. ,"• Designed automated tools using SQL/Redshift for Custom Team and Digital TV industry for segmentation and analyzing the data for the client ad-campaign
• Worked on AWS S3 cloud handling large client data from multi-sources using PostgreSQL on Greenplum and Python
• Designed Tableau dashboards to track resource allocation to the projects and interpret the team’s revenue share across verticals
• Worked on migrating complex Alteryx’s workflows into functional PostgreSQL codebase using amazon redshift cloud for segmentation and analyzing data for client ad-campaign
• Developed scripts to automate the execution of ETL using shell scripts under Unix environment",,,,,,,,,
,,,Salesforce Data Analyst ,Accenture,"• Gained extensive domain knowledge and skillset to customize Salesforce CRM application, and build customer portal, reports, and dashboards on Tableau for tracking customer data
• Involved in end to end development & enhancement project using Agile and SDLC methodologies
• Performed ad-hoc analysis and reporting using Salesforce queries on Dashboards
• Developed test cases and plans to complete the unit testing and support System testing",,,,,,,,,
27. Gargy Parhy,English,,Sr. Business Intelligence Analyst,Deloitte,,University of Houston-Clear Lake,,8 years,all in us,Consulting,Medical,"Prosper, Tx",,
28. Gautam Chandrasekhar,"English, Kannada",Yes,Business intelligence analyst,AWS,,Texas A&M Commerce,MS ITM,5 years,2 years 5 months,Cloud,Airline,"Forth Worth, Tx",,
,,,Data Analyst Intern,Rollo Insurance ,"•Reduced client churn from 13% to 8% by conducting exploratory data analysis to determine retention trends of clients 
•Cleaned and preprocessed dataset containing 129567 records and 19 attributes of client policy data using Python
•Generated BI Dashboard to help identify and compile a list of policies most at risk of cancellation with potential savings of $175,000 per annum
•Achieved 85% approx. prediction accuracy by deploying Logistic Regression, Random Forest, and XGBoost for each data set to select the best classifier 
•Evaluated model accuracy by executing feature selection with k-fold cross-validation to validate the model selection",,,,,,,,,
,,,Business Analyst,Unilever,"• Designed interactive BI dashboard for stakeholders providing efficient analysis of expiry stock in depots 
• Slashed 2 FTE of manpower by automating production booking operations using Handheld terminals /bar-code scanners 
• Generated a profit of $150000 by delivering ‘Service from Anywhere’ project, with depots able to service many customers across India; Transition from tax-free to GST regime implemented in India in July’17 
• Reduced 10 days of effort by automating factory operations with Robotic Process Automation (RPA) using UiPath ",,,,,,,,,
,,,Business Analyst Trainee,Unilever,"• Analyzed data and documented asset module in SAP ERP to revamp current design saving 2 hours of manual efforts
• Implemented SAP WMS (Warehouse Management System) in 4 Unilever factories 
• Trained 15+ employees on SAP WMS(Warehouse Management System) and created training material for them",,,,,,,,,
29. Parth Gupta ,"English, hindi",Yes,Business Intelligence Engineer,Amazon,,UTD,MSBA,9 years,4 years,E commerce,travel,"Dallas, Tx",,
30. Oluwatomisin Akinbo,English,,Business intelligence analyst,Memorial Sloan Kettering Cancer Center,,Michigan Technological University,MS Applied Economics,6 years,2 years 5 months,Health/Medical,Retail,"New York, Ny",,
,,,Data Analyst,Kadef groups,"• Used correlation and regression analysis to analyze large datasets and retail metrics, market trends, pricing strategies, created sales forecasts, and made recommendations to optimize sales activities
• Monitored and analyzed customer activity, clients service and market trends, translated results, asides providing actionable insights and recommendations to guide the sales, marketing teams and stakeholders
• Analyzed, collected and examined data, then used the information gathered to create coherent, intelligent reports, and made presentations to team and management using interactive dashboards
• Performed Exploratory Data Analysis, trying to find trends and clusters.
• Developed Tableau visualizations and dashboards from extracted reports using Tableau Desktop 
• Created BI reports in pivot charts, graph, and other visualization format to analyze trends",,,,,,,,,
,,,Data Analyst Intern,IITA,"• Gathered field data, interpreted the statistics, wrote reports, and designed interactive charts and graphs on the efficacy of Nodumax (a newly introduced inoculant) on 8 types of legumes
• Maintained accurate and updated records of all samples to improve work efficiency and final outputs.
• Used SQL to maintain the database of incoming samples and test results while using advanced excel to draw useful information for decision-making processes
• Presented daily analyst performance reports to the management team using PowerPoint and Excel Pivot tables.",,,,,,,,,
31. Aahliyah Jackson,English,,Business intelligence analyst ,Dallas Mavericks ,,Texas Christian University,MSBA,2 years 4 months,all in us,Sport,Logistics,"Dallas, Tx",,
32. Bharath Kumar Natarajan,"English, Kannada",Yes,Business Intelligence Engineer,Amazon,,UTD,MS ITM,7 years 6 months,3 years 11 months,E commerce,Health,"Dallas, Tx",,
33. Chitra Muthusubramanian,"English, Kannada",Yes,Business Intelligence Manager,Ally,,University of Madras,BE,25 years,10 years,Finance ,Telecom,"Dallas, Tx",,
,,,Data analytics manager,Infosys,"Lead a team of data analysts to deliver high quality reporting solutions and insights for major Telecom companies using Palantir and PowerBI. 
 Provide mentorship, guidance, and career development for the teams. 
 Partner with multiple business teams to identify data analytic needs, ensure data driven answers are 
 provided and recommended. 
 Assess new projects, create sow, develop roadmap, create a team, and manage delivery teams from 
 end to end.",,,,,,,,,
34. Pranav Kaul,"English, Hindi",Yes,Business Intelligence Developer,Autodesk,,UTD,MSBA,7 years,2 years,Software,Consulting,"Dallas, Tx",,
,,,Analyst Intern,EY,"• Worked on the development of an analytical profit and loss application to improve client’s profit on their products.
• Presented data architecture and key requirements required to build the application.
• Developed and executed front-end web application using HTML, CSS, and Bootstrap.
• Established approval workflow of sales channel and logical data model of the application.",,,,,,,,,
,,,Data analyst intern,ICC Loyalty,"- Used company’s data inventory to optimise campaigns, report on results, and drive shopping innovations on the loyalty platforms.
- Reviewed historical sales trends, researched demand drivers, and developed reports.
- Created presentations as well as technical architectures for the newly launched products.
- Managed new product launches to ensure items are live on site with all major components scheduled for launch dates.",,,,,,,,,
35. Chaksu Bansal ,"English, Hindi",Yes,Business intelligence analyst,American Airlines,"Leveraged SQL and Alteryx to perform ETL operations, creating comprehensive Power BI reports that enhanced
contract negotiations, contributing to a 20% increase in successful deals.
• Conducted in-depth analysis of the AAdvantage loyalty program, leading to a 15% surge in program engagement
through strategic recommendations and tactical launches.
• Elevated the Power Bi and Tableau dashboards crafting engaging custom visuals and precise measures.
Additionally, utilized Python and R for data manipulation and analysis, enhancing the depth of insights derived
from the data to thoroughly examine Corporate Sales or Agency sales performance across various channels and
areas, aiding in informed decision-making and strategic planning.
• Automated sales reports using Databricks, Azure Data Factory and Paginated reports, reducing report generation
time by 40%.
• Developed robust data validation processes in SQL, ensuring high data integrity and reliability for strategic decision-making.",University of South Florida,MSBA,7 years,3 years,Airline,Retail,"Irving, Tx",,
,,,Data analyst intern,Costco IT,"• Initiated to create a Power BI report to show effective license position findings identified by publishers which was used 
to identify the optimization opportunities and highlight cost avoidance. This report was used by all Costco teams.
• Imported, transformed, and rationalized data from multiple data sources and operationalized data by loading, 
validating, and reviewing on a timely basis while normalizing data where and when needed.
• Comparative review of overlapping data sets, which includes, identifying data anomalies, identifying data-related issues 
and sources, Supporting troubleshooting of root causes and resolution of discrepancies",,,,,,,,,
,,,Business Analyst ,Infosys,"• Lead 8 member team in Japan to review the current technical systems at a fortune-500 automobile client; Performed gap analysis and documented requirements generating a business worth $1.2M.
• Extraction, analysis, maintenance of data pipeline in SQL Server & SAP DB of pricing and sales information, leading to increase in data pipeline process optimization by 10%.
• Designed reports on incoming orders and outgoing shipments, and implemented visualization using Tableau, and database tools such as MySQL and SQL Server Management Studio, resulting in 25% improvement in planning the lead time.",,,,,,,,,
,,,Senior Analyst,Infosys,"• Implemented machine learning models using Python and Azure ML for the sales teams to develop the inventory and sales report which helped in increasing sales by 15%. 
• Extracted and analyzed performance metrics to identify key issues; developed reports using Tableau which helped increase the profit to the company, driving effective technical and business decisions",,,,,,,,,
,,,Data Analyst,Accenture,"• Formulated business rules such as triggers, check constraints, logs and relationships on SQL Server database system to avoid update and delete conflicts reducing errors by 40%
• Created, analyzed, and optimized SQL queries, reducing processing time for large datasets by 30%.
• Employ Tableau best practices formulating reports, developing SQL queries, and designing tableau dashboards; improved data quality and reporting accuracy by 35%",,,,,,,,,
36. Dhivakar Rangarajan,"English, Tamil",Yes,Business Intelligence Engineer,Amazon,,UTD,MSBA,8 years,5 years,E commerce ,Automobile ,,,
,,,Business Analyst Intern,Copart,"• Designed the Global Revenue Dashboard for countries from multiple continents by gathering data from multiple databases and streamlined the incremental load process to generate reports and automated it to be received by the Executive Panel on a daily basis

• Created 3 Tableau Dashboards with interactive views , trend lines , action filters ,parameter control and sets as part of calculating the Spain Employee Productivity for Yard Managers to asses sales and operation metrics based on daily , monthly , quarterly and yearly reports

• Worked from end-to-end project to see trends on how many Leads are getting converted to Opportunities; data extraction from Salesforce using python and streamlined the entire delta load using ETL, created executive dashboard and storylines in Tableau for the office of CFO

• Designed and created a validation framework which checks data from various stages right from data generation , intermediate table load and the final fact table load for various application using ETL and automated the reports to be received by respective teams on a daily basis

• Extracted necessary JSON files from Twilio application and created data model for the final fact table load , automated the process to load the tables on a 10 minute refresh , and created reports for assessing the Employee Productivity based on the reports designed in Tableau

• Saved 90,000+ USD from company’s annual subscription to Pentaho ETL jobs my migrating ETL code of over 200+ jobs from Enterprise edition to Community edition and did data validation at various stages of data flow and pushed the new code it to production servers",,,,,,,,,
,,,Business Analyst,TCS,"•Experienced in analyzing the data generated by the business process, defining the granularity, source to target mapping of data elements, design database systems and create reports for real-time and offline analytics

•Gathered business and functional requirements for developing new data validation framework which checked for Record Count validation by writing generic Shell scripts which compares the counts processed within a job from source and target table load

•Created 40+ interactive Tableau Workbooks indicating 20+ metrics for Spend Analytics for individual customer based on adhoc request

•Designed and implemented data warehouse architecture for corporate circulation data warehouse. Subsequent data marts, extracts and reports were sourced from the architecture of conformed facts and dimensions

• Worked in Business Intelligence domain as a ETL developer for 3 years and 3 months 

• Have designed complex jobs in IBM Infosphere Datastage and Informatica to handle huge amount of data and parallel process them .Have also worked in migration of ETL code from Informatica to Datastage

• Migrated approximately 600+ jobs from Informatica to IBM Datastage. Unit tested all 600 jobs and deployed them in production server

• Worked in different warehousing appliances such as IBM DB2,Netezza , Sql Server and Oracle as well 

• Have insights in Hadoop to load huge amount of data and proficient enough to extract data using Spark . 

• Have indepth knowledge in Shell Scripting which has helped me to automate most of our processes which runs on batch 

• Migrated 8 years of transactional data from multiple databases to Hadoop system by creating pig script from scratch and also completely automating the process through customized shell scripts",,,,,,,,,
37. Avik Kohli,"English, Hindi",Yes,Business intelligence analyst,Mouser Electronics,,UTD,MS ITM,10 years,8 years,electronics,Finance,"Mansfield, Tx",,
,,,Data Management Analyst,US Bank,"Data Management and Reporting.
• Processed access management-related operations and other recurring data cleanup tasks using Oracle SQL Developer, Microsoft Excel, and Oracle Identity Management platform.
• Created flat files using SQL and MS Excel to run a variety of access management requests to modify access for users, roles, and entitlements on Oracle Identity Management. Achieved a 98% SLA for all requests assigned to me during my time with the Bank.",,,,,,,,,
,,,Consulting Data Analyst,Kforce Inc,"Data Analytics Consultant at U.S. Bank
• Performed data cleanup and report automation for the Identity Access and Management team using Oracle SQL Server and Oracle Identity Management platform. 
• Generated scheduled and ad hoc reports for stakeholders to monitor access management processes using SQL, GitLab, and Rundeck.

Data Analytics Consultant at Kemper Insurance 
• Led data migration efforts after the acquisition of American Access Casualty Insurance company by Kemper Insurance.
• Led the data mapping process to map Kemper’s data with that of American Access Casualty Insurance which enabled data migration.

Consulting Data Analyst at USAA
• Created the base transaction file for a 6-year compliance look-back.
• Created Tableau dashboards to automate compliance reports. Used SAS and SQL queries.
• Performed analytics on harvested USAA banking data hosted in Snowflake to facilitate the achievement of compliance goals.",,,,,,,,,
,,,Business Aanlyst ,Amazon,"• Identified gaps in operations and created SQL generated
reports to reduce incorrect call transfers to my stakeholder team
by 85% which improved associate productivity.
• Created metrics around operational processes using data to
enable process optimization.
• Generated advanced operational dashboards with quick filters,
parameters and calculated fields using SQL and Tableau that
were used by the senior leadership team in their daily and
weekly business reviews.
• Managed timely flow of business intelligence information to
users by overseeing the complete ETL process in SQL.
• Synthesized current business intelligence or trend data to
support recommendations for action.",,,,,,,,,
,,,Data Quality Analyst,Accenture,"• Performed data quality analysis on a Big Data migration project hosted on AWS cloud to optimize data collection procedures
• Designed important dashboards in Tableau and QlikView for data reporting
• Built and maintained SQL scripts and complex SQL queries for data extraction and analysis to ensure data integrity between the Hadoop data and the application database",,,,,,,,,
38. Bhanu Kola Sree,"Hindi, Tamil",yes,Business Intelligence consultant,Andelyn Biosciences,"• Designed, developed, tested, and maintained Tableau functional reports based on user requirements.
• Developed various Tableau data visualization using cross tabs, Heat maps, Box and Whisker Charts and many more.
• Built and published customized interactive Tableau reports and dashboards along with data refresh scheduling using Tableau Desktop and Tableau Server.
• Perform analysis for senior leadership and provide solutions for data related queries.
• Lead the development of new Power BI reports to provide real-time insights based on requirements.
• Designed and modeled data warehouse and data mart structures using ER Studio.
• Design and develop automated scripts for report migration from reporting browser platform and client tools.
• Implemented data blending to blend data from different data sources.
• Responsible for providing quality formal and informal documentation of business objects tableau reporting migration.
• Designed and implemented data models and dashboards in Power BI using data from AWS Redshift.
• Responsible for creating calculated fields and hierarchies using Tableau Desktop.
• Utilize business analytics to create performance analysis reports and compile data to drive process improvement opportunities.
• Designed and implemented data lake architectures using Power BI and Azure Data Services.
• Designed and developed Power BI reports and dashboards using an Agile SDLC approach.
• Proficiency in creating Ad-hoc Reports, Drill-Down, Drill-Through, Cascaded, Matrix, Sub-reports, Pie Chart Reports and Tabular Reports for different business domains depending on the specifications and requests.
• Made Power BI reports more interactive and activate by using story telling features such as bookmarks, selection panes, drill-through filters and created many custom visualizations.
• Extract and organize datasets using Excel to create business models and compile data for the organization’s risk index.",Sree Vidyanikethan Degree College,BS Computer Science ,5 years,10 months,Biotech,Consulting,"Irving, Tx",,
,,,Data Analyst,Morgan Stanley,"• Developed several parameterized dynamic dashboards, scorecards, with drill down and drill through capabilities.
• Designed rich dashboards with Power BI and referred user stories to create compelling dashboards to deliver actionable insights.
• While designing the Power BI reports and dashboards, the measures are created using DAX programming language. Writing all the calculations using DAX formulas.
• Experience in Power Query in Power BI to Pivot and Un-pivot the data model for data cleansing and data massaging.
• Migrated existing self-service reports and ad hoc reports to Power BI.
• Implemented several MDX and DAX functions for various fact calculations for efficient data visualization in Power BI.
• Implemented data governance and data quality best practices using ER Studio's data management features.
• Used SSRS to create, execute and deliver tabular matrix and chart reports.
• Used SSIS to create ETL packages .dtsx files to validate, extract, transform and load data to data warehouse databases.
• Created data visualizations and reports in Power BI to surface insights from data lake datasets.
• Developed ETL processes and data models using an iterative SDLC methodology.
• Created packages in SSIS and SSRS with error handling.
• Developed and maintained ETL (Data Extraction, Transformation and Loading) mappings using SSIS to extract the data from multiple source systems that comprise databases like Oracle 10g, Power Query, flat files to the Staging area, EDW and then to the Data Marts.
• Implemented data visualizations and reports in Power BI using Redshift data, including geospatial and predictive analytics.
• Designed rich dashboards with Power BI and referred user stories to create compelling dashboards to deliver actionable insights.
• Implemented data governance and security best practices for Power BI data lakes.
• Involved in developing complex Azure analysis services tabular databases.",,,,,,,,,
,,,Data Analyst,AIG,"• Understand the Requirements and Functionality of the application from specifications.
• Provide guidance to IT Infrastructure and Application teams on Architecture’s Frameworks, Patterns, Best Practices, and Programming concepts.
• Used Power BI, Power Pivot to develop data analysis prototype, and used Power View and Power Map to visualize reports.
• Developed ETL processes to ingest and transform data from various sources into the data lake.
• Published Power BI Reports in the required originations and Made Power BI Dashboards available in Web clients and mobile apps.
• Hands on experience in Performance Tuning, Query Optimization.
• Strong Knowledge of Power BI to import data from various sources such as SQL Server, Azure SQL DB, SQL Server Analysis Services (Tabular Model), MS Excel etc.
• Scheduled Automatic refresh and scheduling refresh in Power BI service.
• Developed SSIS Packages to Extract, Transform and Load (ETL) data into the Data warehouse from SQL Server.
• Participated in code reviews and provided feedback to peers on Power BI development best practice.
• Utilized ER Studio's data profiling and data validation capabilities to ensure data accuracy and consistency in Power BI reports.
• Developed paginated reports as per the requirements using different charts. 
• Performed Parallel Testing or Production Testing, which ensures that the new system will perform correctly in a production environment and interface correctly with other production systems.
• Connected Tableau visualizations to AWS Redshift data warehouse for interactive reporting and analysis.
• Mastered the ability to design and deploy rich Graphic visualizations with Drill Down and Drop-down menu option and Parameters using Tableau.
• Created different KPI using calculated key figures and parameters.
• Hands on experience with API gateway and Dynamo DB",,,,,,,,,
,,,Data Analyst,DHL Supply Chain,"• Created dashboards for analyzing POS data using Tableau 10.x.
• Consistently attended meetings with the client subject matter experts to acquire functional business requirements.
• Developed case studies to understand new product launch, promotion effectiveness, trend detections, Seasonal forecasting.
• Implemented data blending and joining across multiple Redshift datasets in Tableau.
• Created Scatter Plots, Stacked Bars, bullet charts, Heat Maps, Filled Maps and Symbol Maps according to deliverable specifications.
• Expert level capability in Tableau calculations and applying complex, compound calculations to large, complex data sets.
• Created custom function's Date range, Time functions, array functions, and Conditional formatting functions in the reports.
• Scheduled extract refresh for weekly and monthly reports.
• Worked on workbook Permissions, Ownerships and User filters.",,,,,,,,,
,,,Business Analyst,FactSet,"• Execute and maintain reports for external clients and internal support.
• Support ad-hoc data analysis requests from business owners and support management team.
• Develop and maintain databases necessary for projects and development functions.
• Develop graphs, reports, and presentation for project results.
• Used Oracle SQL*Plus tool for running SQL scripts containing statements and queries.
• Designed and developed all the Tables and Views for the system in Oracle.
• Acting as Tableau SME for other Tableau users across the enterprise.
• Designed a dashboard that is easy for the clients to use and to analyze their growth and predict the requirements for the future.
• Perform basic statistical analysis create and present quality dashboards.
• Communicate analysis effectively to internal team and clients.
• Wrote triggers, menus, and stored procedures in PL/SQL/TSQL
• Data loading and Extracting function using Oracle SQL Developer.
• Organized and reported training statistics to company-wide management.
• Coordinated with third-party contractors to update and maintain CEPs and CSPs for the company website.",,,,,,,,,
39. Pryde Nyakudya,English,,Senior Business Intelligence Developer,Amivero,"• Tasked with creating and maintaining Tableau Suite housing reports with active immigration statistics. 
• Created reports to fulfill Congress Level report requests. 
• Worked with business stakeholders and participated in requirement gathering sessions to understand the business needs. 
• Managed project lifecycle using JIRA and Github. 
• Responsible for creating dashboards and overall creation of data visualizations. 
• Created dashboard designing with effective data visualization of large data volumes from various data sources (SQL server, oracle, spreadsheets etc). 
• Developed Tableau data visualization using Cross Map, Scatter Plots, Geographic Map, Pie Charts and Bar Charts, Page Trails, and Density Chart. 
• Prepared Dashboards using calculations, parameters in Tableau and created calculated fields, groups, sets and hierarchies etc. 
• Used Oracle, SQL server as data sources for designing Tableau Reports and Dashboards. 
• Provided customer support to Tableau users and Wrote Custom SQL to support business requirements. 
• Expert level capability in Tableau calculations and applied complex, compound calculations to large, complex data sets.",Havant College,BS Information Technology,10 years,all in us,Technology Solutions,Consulting,"Dalls, Tx",USA,
,,,Tableau Developer,Safelite Solutions,"• Created Rich dashboards using Tableau Dashboard and prepared user stories to create compelling dashboards to deliver actionable insights.
• Connected Tableau server with share-point portal and setup auto refresh feature.
• Created visualization for logistics calculation and department spend analysis.
• Generated the test plan specifying an overview of testing approach, testing strategy, roles, responsibilities and its scope
• Created Test Scripts, Test hierarchy to represent the features and functionality that need to be test in the application.
• Performed Parallel Testing or Production Testing, which ensures that the new system will perform correctly in a production environment and interface correctly with other production systems.
• Participated in the User Acceptance Warranty Testing. Involved in doing security and negative testing of the application.
• Designed, developed and supported BI solutions, Involved in Debugging and monitoring, and troubleshooting issues.
• Implemented advanced geographic mapping techniques and use custom images and geo coding to build spatial visualizations of non-geographic data.
Performed development activities from gathering requirements and designing solutions, through developing code / reports, to testing and release / deployment.",,,,,,,,,
40. Zach Cunningham,English,,VP Analytics & Business Intelligence,Remington Hotels,"VICE PRESIDENT OF ANALYTICS & BUSINESS INTELLIGENCE (March 2022 - current)

SENIOR DIRECTOR OF ANALYTICS & BUSINESS INTELLIGENCE (October 2019 - February 2022)

DIRECTOR OF ANALYTICS (August 2018 - September 2019)

- Leadership role tasked with supervising and training analysts with a focus on improving skills sets, industry specific knowledge, and consistently exceeding company goals
- Cross-department exposure and responsibilities have led to improved consolidation and collaboration between Revenue Management, Sales and Marketing, Operations, HR, and Accounting.
- Led the creation and development of the company's BI systems and is responsible for database management, data handling, and other technical processes
- Works side by side with other senior level members to develop and implement high level strategies, affecting approximately $1B of revenue across more than 20 states.",Millsaps College,MBA,30 years,all in us,Hotel,Finance,"Dallas, Tx",USA,
.,,,Founder & Senior Portfolio Manager,Ultima Financial,"- Acts as manager and analyst to privately owned equity portfolio 
- Utilizes several research and analytical tools including MarketHub and Bloomberg
- Releases quarterly and annual performance reports on equity portfolio
- Provides external financial and strategic consulting services to clients 
- Develops written and oral reports to clients providing analysis and recommendations",,,,,,,,,
,,,Portfolio Manager and Lead Analyst for the Louis Wilson Fund,Mllsaps College,"- Performed comprehensive financial analyses of current and prospective holdings
- Created complex Excel spreadsheets detailing company financials
- Delivered written and oral reports fully describing all aspects of a given company 
- Produced professional PowerPoint presentations as visual aids to oral presentations 
- Provided leadership to the fund, helping to delegate responsibilities and set goals",,,,,,,,,
,,,Wealth Management Analyst,Merill Lynch,"- Assisted associates and partners in managing client accounts
- Created and updated complex Excel spreadsheets containing sensitive financial information
- Enhanced financial research skills through the Bloomberg terminal and other databases
- Attended meetings with partners to discuss and predict market trends",,,,,,,,,
41. Chandler F.,English,,Business Intelligence Engineer,AT&T,Power BI and SQL developer for the Wireline Transformation and Supply Chain organization,UTD,"MSBA, MBA",8 years,all in us,Telecom,Airline ,"Dallas, Tx",USA,
,,,"Quality Career Foundations Program (QCFP | Analytics | Project Management 
",Boeing,"Initiated a strategic partnership with Boeing Global Services (BGS) supplier quality, establishing a 
centralized Tableau server space for team data visualizations to enable data-driven decision-making and 
streamlined communication with leadership

Re-engineered two dashboards, created an active directory for user access management, and generated
new business client with incoming backlog of 5 projects

Spearheaded the digitalization of organizational KPI scorecard automation, employing advanced SQL and ETL processing for database manipulation, integrating primary and secondary sources with Excel Power Query to streamline senior quality leadership decision making processes

Coordinated the development and execution of the 777 Quality Oobeya room, consulting with director to map out requirements and specifications instituting a phased implementation plan, coupled with a robust sustainment plan 

Developed enhanced data visualizations with advanced Python programming to streamline cross
functional key performance indicators (KPIs) needed for Oobeya and adapted for leader’s management,
creating standardized metrics used to improve operational excellence and increased leader efficiency by 25%

Led a Lean/5S workshop of 20 quality data professionals and analysts spanning all commercial airplane
programs to optimize the Total Quality Tableau server, resulting in a 12% increase of server capacity",,,,,,,,,
42. Nagaveni Mamillapalli,"English, Telugu",Yes,Business Intelligence Analyst,Community Health Connections,"QA opportunity analyses generated by team members for accuracy and adherence to
established standards.
• Proactively identify and address data-related challenges and bottlenecks, employing analytical
thinking and problem-solving skills to develop effective solutions.
• Demonstrate precision with data input and output.
• Adapt to a fast-paced environment and changing priorities.
• Respond to new or re-opened requests and escalations in a timely fashion.
• Program and maintain report forms, formats, information dashboards, data generators, canned
reports and other end-user information portals or resources.
• Understand underlying database structures and data flows for troubleshooting and resolving
data issues related to data syncs, imports, normalization, etc.
• Train end-users on optimal use of reports and dashboards to support data driven business
decisions.
• Create and maintain management reports and dashboards; Able to run ad hoc analysis.
• Strong written and verbal communication skills, with demonstrated ability to effectively
communicate technical concepts to a diverse range of stakeholders.
• Ability to work independently and manage/prioritize multiple tasks at once, often with urgent
deadlines.
• Develop Tableau dashboards and reports for data analytics.
• Healthcare industry experience and knowledge necessary to extract and work within the data to
return the requested reports at various levels for both internal and external clients.
• Collect, clean, and preprocess data from various sources.
• Create data visualizations and presentations to communicate findings effectively.
• Perform exploratory data analysis to identify trends, patterns, and insights.
• Document all processes and research.
• Participate in meetings with multiple internal and external stakeholders to gather requirements,
identify data conversion needs, provide ongoing updates, and ensure business needs are met.",The university of Memphis,MS Data Science,4 years,1 years 8 months,Health,Health,"Denton, Tx",Hyderabad,
,,,Data Analyst,Humana,"• Involve in requirements gathering, design, development, and testing production of an application using the Agile model.
• Support technical team members for technologies such as Microsoft Excel, R, and Python.
• Increase customer visibility by developing real-time insights for salespeople and sales managers using Tableau, Matplotlib, ggplot2, and SciPy to boost revenue by 10%.
• Identifying new market opportunities that led to a 15% increase in revenue and market share within the first quarter of implementation.
• Create reports using SQL to extract the data and use Excel to format the data for analysis, manipulation, and dissemination to business users.
• Involving requirements gathering and source data analysis identifying business rules for data migration and developing the data warehouse.
• Develop a database in MySQL to manipulate data with monthly updates and create reports in Crystal Reports.
• Working autonomously, exhibiting excellent communication skills, and demonstrating problem-solving abilities.",,,,,,,,,
,,,Data Analyst,Macro Software Solutions,"• Performed system analysis and understood the deliverables within SDLC using Waterfall methodology. 
• Used R statistical software for effective analysis by hypothesis testing to validate data and interpretations.
• Reduced data processing time by 50% through the implementation of automated data pipelines and optimized algorithms.
• Leveraged PyCharm as a dedicated IDE for Python development, offering advanced coding assistance, code navigation, and integrated testing capabilities.
• Worked on data cleaning, data mining, and data wrangling with unorganized, inconsistent, and incorrect data by NumPy, and Pandas in Python.
• Utilized Power BI to create various analytical dashboards that help business users get a quick insight into the data.
• Performed data analysis and data profiling using complex SQL queries on various source systems including SQL Server. 
• Conducted data analysis and trend interpretation for developing statistical process control methods in support of aviation information.
• Spearheaded a major pricing restructure by redirecting focus on consumer willingness to pay instead of product cost and implemented a three-tiered pricing model which increased average sales by 35% and margin by 12%.",,,,,,,,,
43. Katta Charan,"English, Tamil",Yes,Business Intelligence Analyst,Eminence Technology Solutions Inc,"Optimized data extraction, transformation, and loading processes using SQL, improving performance and 
ensuring data integrity.
• Employed SQL on relational databases like Snowflake and Oracle to mine and analyze large-scale datasets, 
enhancing data retrieval and processing.
• Implemented predictive modeling and machine learning algorithms to solve complex business problems and 
enhance operational processes.
• Involved analyzing datasets to identify and evaluate risk factors affecting patient care and financial outcomes.
• Designed and maintained logical and physical data models to optimize data management, utilizing Amazon S3, 
EC2, and Redshift for efficient data storage and processing.
• Developed and deployed advanced data visualizations and dashboards in Tableau, facilitating data-driven 
decision-making across the organization.",University of North Texas,MSBA,5 years,1 year 1 month,Technology solution,SOftware,"Irving, Tx",Hyderabad,
,,,Business Analyst,PER SFT,"Spearheaded the development and maintenance of BI tools and SOPs, utilizing SQL, Power BI, and advanced 
Excel to improve data accuracy and compliance.
Led initiatives to optimize financial health monitoring at project and program levels through data analysis, 
contributing to enhanced decision-making processes.
 Collaborated closely with Business Intelligence and Data Management teams to assess and fulfill emerging data 
needs, streamlining data collection and analysis procedures.
Acted as a liaison between clients and engineering teams, ensuring swift resolution of issues and enhancement 
of product features based on data-driven insights.
Proficient in handling large datasets, developing SOPs, and improving data management tools and processes
Engaged with business users to provide technical guidance on Power BI Desktop and Service, ensuring optimal report design and implementation.
Developed a variety of Power BI reports, including vertical, cross tab, and those with drillings and sorting features.",,,,,,,,,
44. Justin George,English,,Senior Business Intelligence Analyst,Ascend Learning,"Analyzed complex datasets to identify opportunities or solutions, provide strategic insights, improve efficiencies, and enhance client experience.

Designed, developed, and monitored Tableau dashboards containing relevant KPIs to evaluate and benchmark trends of internal performance and performance of customers using our products. 

Maintained Tableau dashboards for senior leadership which gave daily insights into the company's financial performance, attaining of sales opportunities, and utilization of the company's product portfolio. 

Developed automated ETL processes using Microsoft SQL Server Management Studio and Integration Services that supplied datasets to new and existing dashboards and client-specific reports.

Performed and owned recurring and ad-hoc business intelligence tasks and projects - using subject matter expertise to consolidate reporting from multiple internal databases and external datasets.

Collaborated with teams to better understand their goals and develop data-driven solutions; managing the project from requirements gathering to final implementation.",University of Florida,BS Food and Resource Economics,10 Years,all in us,ED Tech,Auto,"Atlants, Ga",USA,
,,,Supervisor - Performance and Reporting,Mercedes-Benz USA,"Led a team of two data analysts to generate insightful reporting on sales and supply chain data within the organization.

Communicated points of interest found in reports and deeper analysis to management colleagues in field offices.

Drove the adoption of the analytics culture at the company by creating self-service dashboards in
Tableau to facilitate ad hoc analyses.",,,,,,,,,
,,,Specialist - Analytics and Performance,Mercedes-Benz USA,"Analyzed both structured and unstructured data sets to identify opportunities, provide insights to
stakeholders, develop standardized reporting, and create predictive models.

Supported junior analysts through ensuring best practices and regularly checking the accuracy of reports and other deliverables.

Created predictive models in Alteryx through the use of data regarding customer vehicle service
behavior and vehicle service lifecycles to anticipate the next service visit for active customers.

Performed ad hoc analyses to discover and communicate essential insights to inspire revenue growth.

Provided data support to the parts wholesaling business by building, developing, and maintaining highly collaborative working relationships with product owners and other stakeholders.

Supported vehicle parts supply chain by analyzing inventory, delivery schedules, and costs of
transporting parts.

Developed automated reporting using SQL queries in IBM Cognos and Tableau dashboards to
assist in data-driven decision-making.

Led new data initiatives by connecting with vendors and coordinating test implementations of
new technologies.

Ensured all team deliverables maintain a high degree of accuracy.",,,,,,,,,
,,,Analyst - After Sales Business Performance,Mercedes-Benz USA,"Assisted in preparing revenue plans (Market Forum, OP, 1st-3rd Expectations) based on trends, MRA data, and future expectations. Analyzed financial results vs plan.

Created standard reports to monitor key metrics and fulfill customers' needs efficiently and effectively.

Utilized data visualization and data blending tools - Tableau and Alteryx - to solve complex analytics
questions and create tools to be used by business owners.

Updated Customer Services KPIs for After Sales weekly status report, EM Meetings, & other presentations.

Performed daily, weekly, monthly Customer Pay Parts Purchases reporting and analysis; internally & externally. Served as the point of contact for field personnel.

Worked with Service, Parts Marketing, and Accessories Marketing to analyze revenue and profit impact of various initiatives for inclusion in revenue plans.

Supported ASBD leadership in establishing annual dealer objectives to enable Regions to better measure and manage dealer performance.

Cooperated with IT on data analysis.",,,,,,,,,
,,,Senior financial Analyst,Verizon,"Responsible for detailed analysis of compensation data and payments to ensure accuracy and compliance with compensation plans. Timely completion of audit/discrepancy reports. Research and resolve all compensation issues in a timely and accurate manner. Update compensation system as required based on research and analysis. Detailed explanations to customer regarding payment and/or compensation statement. Completed payment analysis reports as necessary.

Responded to inquiries from the field regarding compensation. Reconciled and resolved discrepancies. Responded to internal Commission inquiries. Assisted Management with complex compensation issues as necessary.

Demonstrated an advanced knowledge of incentive management, financial, accounting, and additional support systems.

Demonstrated understanding of systems and inter-dependencies of processes to drive the business toward the development of systems that enable process improvement.

Identified improvement opportunities in this area and contributed to the design and implementation of new processes or procedures as a result of identifying improvement opportunities.

Ensured that incoming and outgoing transaction processes were controlled, effective, and efficient. Found innovative ways to manage our complex set of transactions through the system. Made system/ processes more efficient and scalable, and worked to ensure the highest level of quality of our operations and minimize operational risk.",,,,,,,,,
45. Derrick Boateng,English,,Business Intelligence Developer,Loloi Rugs,"In charge with creating and delivering actionable insights that influence business decisions in the areas of strategy, business planning, competition, KPI development, and new/existing initiatives for analysis and operational optimization. In addition to the data and analysis collected and presented to the supported business, I exceeded expectations by using statistical analyses to identify drivers and create strategic recommendations, presenting these to key partners. Integrate knowledge of business and functional priorities to act as a key contributor in a complex and crucial environment.

- Conducted advanced analysis based on provided requirements, utilizing extremely large datasets and complex business requirements on KPIs and objectives established by the stakeholder. Implemented data quality checks that reduced compliance-related errors by 75%, ensuring regulatory compliance and avoiding potential fines.
- Designed a performance dashboard that highlighted process bottlenecks, resulting in a 20% reduction in operational delays.
- Optimized data extraction and report generation, reducing monthly reporting time by 40%, leading to more timely decision-making.
- Automated daily data report delivery process in Power BI, reducing the workload of the DMG team by 20%. 
- Implemented demand forecasting models that reduced excess inventory by 25%, saving the company $100,000 in carrying costs.",UT Arlington,BS Biology,7 years,all in us,Rug,Paint,"Dallas, Tx",USA,
,,,SSIS/Tableau Developer,Sherwin-Williams,"Adopted best practices and procedures to assure effective management of human resource data for six customer service centers in Albuquerque, Atlanta, Chicago, Houston, Phoenix, and San Antonio. Liaised and worked closely with different departments to initiate surveys and examine employees’ data in order to improve existing work and employee training structure. Provided support to teams in developing better understanding related to business and data requirements, also constantly generated visualizations for initial concepts and prototypes that presented to the business and clients. Consult with business leaders to negotiate union benefits and contracts

- Developed new Reports / Dashboards/Story using Tableau and relevant data sources (Oracle, Excel, SQL Server, Python, C++, Teradata, Data warehouse etc.).
- Developed interactive dashboards that led to a 50% increase in user engagement and a 20% rise in user-generated queries.
- Created SSIS package for loading the data coming from various interfaces like OMS, Orders, Adjustments and Objectives with multiple transformation in SSIS to collect data from various sources using python for ETL 
- Streamlined ETL processes, reducing data loading time by 60% and enabling daily updates instead of weekly refreshes.",,,,,,,,,
,,,Business Intelligence Developer,McLane Company,"Designed dashboards, defined procedures, automated systems, and supported leaders in making informed decisions that aided in augmenting workflow and enhancing company reporting standards. Extracted and validated data accuracy using SQL queries and scripts. Utilized SQL to created stored procedures and used Oracle Cloud Integrator to integrate data. Prepared and delivered presentations with end users and received feedback on all completed dashboards.

- Designed new reports and wrote technical documentation, gathered requirements, analyzed data, developed and built SSRS reports and dashboard, supported more than 20 client companies’ general business reports. 
- Analyzed sales data to identify underserved market segments, resulting in a targeted marketing campaign that led to a 15% increase in sales.
- Developed different type of reports including: Sales Report, Client Contact Report, Accounting Statement Report, Employee/benefits census report, Benefits statements report, Enrollment count summary report, Billing report and file transfer reports by using Power BI and SQL Server 2012.
- Created customer segmentation models that improved targeted marketing efforts, leading to a 12% increase in customer engagement.",,,,,,,,,
46. Rahul Eti,"English, Telugu",Yes,Business Intelligence Analyst,KKR,".Leading a project to enhance cross-selling and upselling strategies for customers. By integrating customer insights with economic data and employing recommendation algorithms, the project aims to forecast needs, maximize revenue, and improve KPIs, including conversion rates, revenue impact, retention rates, decision turnaround time, and recommendation accuracy.",University of North Texas,MSBA,6 years,3 years,Finance,Software,"Frisco, Tx",Hyderabad,
47. Mensur Ahemed,English,,Business Intelligence Analyst,Blue Cross Blue Shield of Texas,"• Understand the real end-user needs and analyzing their requirements on different platforms performing a cost-benefit analysis and Risk analysis.
• Recorded, tracked and manage meeting minutes and action items for requirement-gathering and status-reporting meetings. 
• Extracted in developing and building Web Parts using SharePoint object model and SharePoint.
• Managed SQL for querying and analysis purposes on various source tables and conditions applied.
• Monitors and reports on Jira User Stories and Bugs to ensure all fields are labelled correctly and up to date including status & assignee etc.
• Generate financial and customer reports for managers using Tableau and Excel to improve finance tracking and customer support.
• Executed and worked on converting business requirements into UML diagrams using Rational Rose and MS Visio and also managing and tracking those requirements.
• Performed with the scrum development to understand building SQL micro services in MySQL.
• Migrated SQL codes to Cloudera Impala as a part of SQL Server Reporting Services (SSRS) and Power BI report migration. 
• Generated, Monitored and Maintained the financial dashboard by utilizing SSAS & PowerPivot tools. 
• Set up Server based data sources and Mentored business power & Microsoft Teams users to create reports/dashboards using tableau desktop. 
• Management in Microsoft Suite various kind of tools such as MS Office, MS Access, MS Visio, Microsoft Excel (VLOOKUP, Pivot Tables), Word, PowerPoint, Share point & MS Project.
• Confluence to provide necessary online documentation to enhance the communication of the team and link the JIRA issues with online documentation.
• Worked with different Database management system like MySQL, MS SQL Server & PostgreSQL.",Western Governors University,BS Data Analytics,5 years,all in us,Health Insurance,Finance,"Dallas, Tx",USA,
,,,Power BI Developer,BNY Mellon,"• Automate numerous manual tasks and reports using BI, SQL queries, functions which cut the cost and time by 90 percent.
• Create various events like Broadcasting reports and emails, FTP Schedulers, Timeline and Decision-making events in BI.
• Deploy and support the Reports, Dashboards and ETL Transformations through various phases of Software Development Lifecycle (SDLC) and manage product delivery by agile methodology.
• Utilized advance features of Tableau software like to link data from different connections together on one dashboard and to filter data in multiple views at once.
• Participate in sessions with management, SME, vendors, users, and other stakeholders for open and pending issues, involved in reviewing/analyzing business requirement documents (BRD)/ functional specifications/use cases.
• Define, designed, and built BI dashboards, reports, and metrics to meet the needs of Credible and Partner stakeholders.
• Maintaining various kind of Microsoft suite tools MS Office, MS Access, MS Visio, Microsoft Excel (VLOOKUP, Pivot Tables), Word, PowerPoint, Share point, MS Project.
• Used of JIRA and Confluence to track user stories.
• Wrote complex SQL queries using joins, subqueries, views, and stored procedures to retrieve data from the database like MS SQL Server, MySQL, PostgreSQL.
• Created Complex ETL Packages using SQL Server Integration Services (SSIS) to extract data from staging tables to partitioned tables with incremental load.
• Developed, Maintained, and Monitored all import/export and Data Transformation into the Staging and Production environments.
• Created Stored Procedures to transform the Data and worked extensively in PostgreSQL for various needs of the transformations while loading the data.
• Created Drill-down and Sub-Report using SQL Server Reporting Services (SSRS). Monitored the performance of the reports.
• Documented all the work and all the process of integration and reporting services for further references.",,,,,,,,,
48. Rohit T.,"English, Tamil",Yes,Business Intelligence Developer,Charter Communication,"• Visualized ETL dataset using Microsoft Power BI, DAX, Power Query and SQL, designed, and built dashboards used to monitor performance metrics.
• Created interactive dashboards and reports using SQL and Python, providing business owners with real-time insights into key performance indicators.
• Conducted data validation and quality checks using SQL and Python, ensuring the accuracy and integrity of the data used in analysis and reporting.
• Designed OLAP cubes and implemented tabular data modeling for accurate representation of business requirements.
• Used Power BI and Power BI report builder to develop and consolidate multiple reports, dashboards, and data visuals.
• Automating report delivery of reports to different users in MicroStrategy using schedules, events, and subscription
• Successfully handled large datasets, applying optimization strategies for efficient data modeling and analysis.
• Analysed the Business Reporting needs and carried out POC’s to study the feasibility of implementation with existing architecture.
• Support and drive the underlying MicroStrategy architecture.
• Designed an enterprise-wide BI system that enabled data-driven decision-making across the organization.
• Transform high-level specifications into usable ongoing MicroStrategy reports and dossiers used by finance, marketing, operations and executives to support business management
• Evaluate current and emerging BI industry trends and best practices when designing BI solutions
• Performed all sorts of ETL and metrics aggregations at the report level in Power BI using power query
• Collaborate with the Data Engineering team to help define ETL requirements needed for data projects.
• Conducted Exploratory Data Analysis (EDA) to understand the statistical distribution.",University of Centeral Missouri,MS IT,7 years,2 years,Telecom,Software Solutions,"Little Elm, Tx",Hyderabad,
,,,Data Analyst/ Business Intelligence Developer,JH Softech,"• Worked with business leaders to build dashboards on ThoughtSpot and PowerBI to analyze data 
• Built ETL jobs in Talend and Airflow based on business reqiuirements. 
• Built Python REST API services using flask and SQLAlchemy to perform CRUD operations on 
databases. 
• Wrote nightly data transformation jobs in SQL and PySpark on AWS EMR cluster. 
• Worked extensively on plotting and visualizing the data using python and libraries like matplotlib, 
seaborn, pandas, Numpy, etc. 
• Have worked with more than 4 clients of FinTech, educational and health care IT domains 
throughout my tenure with excellent feedback and appreciations. 
• Designed and developed BI solutions, including data modeling, ETL processes, and report 
generation. 
• Collaborated with business analysts to understand requirements and transform them into actionable 
reports. 
• Created and optimized complex DAX calculations in Power BI for in-depth insights. 
• Conducted performance tuning and optimization of BI reports and data models. 
• Implemented security measures and user access controls to protect sensitive data. 
• Participated in Agile development methodologies for timely project delivery.",,,,,,,,,
49. Poojitha A.,"English, Tamil",,Business Intelligence Developer,GrammaTech,"Established indexes on strategic columns to enhance query and analysis speeds in SQL Server Management Studio. Assessed tables with identified Columns and pinpointed tables lacking primary keys by authoring advanced SQL scripts. Restricted unauthorized access to sensitive table data for enhancing data security while designing and implementing views. Published intuitive and interactive reports and dashboards using Power BI to elevate data visualization and decision-making. Enhanced cubes and reports using SQLSERVER 2008 R2 Reporting Services by
examining and optimizing database performance. Liaised with developers to track defects and validate databases preand post-deployment.
 Deployed and delivered BI platform solutions by developing and deploying ETL, analytics, reporting, and
dashboarding using SQL Server 2012, leveraging tools like SSAS, SSIS, and SSRS.
 Deployed triggers and stored procedures and enforced business rules through checks and constraints by crafting intricate business queries involving multiple tables from diverse databases using Joins and correlated and noncorrelated sub-queries.
 Optimized Power BI Services by proficiently installing and configuring Enterprise and Personal Gateways,
resulting in streamlined data management and improved performance.
 Ensured more accurate and timely data extraction, transformation, and loading to improve ETL process efficiency while defining and capturing critical metadata and rules.",University of Madras,MS CS,8 years,all in us,Software,Software,DFW,Madras,
,,,Business Intelligence Developer,DSS Inc,"Devised and executed SSIS Packages for seamless data transfer between MS Excel, SQL Server2008 R2, and flat files. Generated ad hoc reports in compliance with client needs by crafting drill-down, Drill through, and cross-reports while tailoring Parameterized Reports and Report Models. Engineered SSIS packages optimizing data conversion through Data Conversion Transformation. Wrote and executed SQL scripts to improve database performance and scheduling efficiency. Alleviated report repetition and enhanced data consistency by implementing Report Server for Linked reports.
 Designed and created a comprehensive database in liaison with Business Analysts to gather and analyze business requirements.
 Streamlined and optimized report scheduling processes to accelerate efficiency while creating and managing snapshots and subscriptions using SSRS 2012.
 Improved data accessibility and decision-making by designing and developing Linked and Ad-hoc reports tailored to specific requirements.
 Maximized data visualization efficiency and user engagement by enhancing Power BI dashboards.
 Introduced dynamic connection string package configurations to streamline package deployment and incorporated event handlers and error-handling mechanisms within SSIS packages.",,,,,,,,,
50. Srinath Konduri,"English, Telugu",Yes,Sr. BI Developer,HTC Global Services ,"• Designed and developed Power BI graphical and visualization solutions with business requirement documents and plans for creating interactive dashboards.
• Generated ad-hoc reports in Excel Power Pivot and shared them using Power BI to the decision makers for strategic planning.
• Implemented several DAX functions for various fact calculations for efficient data visualization in Power BI.
• Designed complex data intensive reports in Power BI utilizing various graph features such as gauge, funnel for better business analysis.
• Extensive use of DAX (Data Analysis Expressions) functions for the reports and for the tabular models.
• Designed/Developed table driven ETL process with Perl and shell scripts, which in turn calls OWB mappings, Informatica oracle code to load EDW.
• Created Power BI reports by using Joins in multiple tables from multiples database using complex SQL queries.",Trine University,,8 years,2 years,Software,Software,"Irving, Tx",,
,,,QilkView Developer,HTC Global Services ,"• Understanding source systems and customer requirements.
• Gathering data sources like QVD files, Excel, Oracle, QVW files, Inline and text files in developing QlikView models.
• Implemented multi-tier architecture to create QVD’s, Data models and reports.
• Used SQL queries extensively extract the required data from SQL server.
• Involved in converting existing QlikView applications to QlikSense environment.
• Eliminated synthetic keys, ambiguous relationships.
• Created a data model by using various QlikView functions.",,,,,,,,,
,,,QilkView Developer,AstraZeneca,"• Gathering requirements from Business Users as well as Handling client communications.
• Developed Proof of concepts (POC) for various projects using QlikView.
• Developed dashboards using different objects List boxes, Multi Box, Straight table, Pivot tables, Bar charts, Scatter charts, Box plot charts, Stacked bar charts, Text objects, Containers etc.
• Involved in analysing the data and defining Key Performance Indicators (KPI’s).
• Involved in validating the QlikView data against the data in the database tables and views.
• Building QVD’s, QVW’s and QVF’s using source systems like Oracle, SAP, Sales force, Excel, SQL and flat files.
• Simplifying complex expressions in the dashboards and improving front-end.
• Design, build, test and debug QlikView solutions based upon specified requirements.",,,,,,,,,